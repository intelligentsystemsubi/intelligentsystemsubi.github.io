
- id: "VisibleWavelengthFeasibility"
  title: "On the Feasibility of the Visible Wavelength, At-A-Distance and On-The-Move Iris Recognition"
  authors: "Hugo Proença"
  venue: "IEEE Symposium Series on Computational Intelligence in Biometrics: Theory, Algorithms, and Applications - CIBIM SSCI 2009"
  year: 2009
  status: "published"
  publication_type: "conference"
  doi: "10.1109/CIB.2009.4925680"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/CIBIM09.pdf"
  thumbnail: "/assets/publications/paper-20.png"
  tags:
    - "Iris Recognition"
    - "Visible Wavelength"
    - "Unconstrained Recognition"
  abstract: "The dramatic growth in practical applications for iris biometrics has been accompanied by relevant developments in the underlying algorithms and techniques. Among others, one active research area concerns about the development of iris recognition systems less constrained to users, either increasing the imaging distances, simplifying the acquisition protocols or the required lighting conditions. In this paper we address the possibility of perform reliable recognition using visible wavelength images captured under high heterogeneous lighting conditions, with subjects at-a-distance (between 4 and 8 meters) and on-the-move. The feasibility of this extremely ambitious type of recognition is analyzed, its major obstacles and challenges discussed and some directions for forthcoming work pointed."

- id: "SegmentVisibleWavelength"
  title: "Iris Recognition: A Method To Segment Visible Wavelength Iris Images Acquired On-The-Move and At-A-Distance"
  authors: "Hugo Proença"
  venue: "Springer Lecture Notes in Computer Science – ISVC 2008: 4th International Symposium on Visual Computing"
  year: 2008
  status: "published"
  publication_type: "conference"
  doi: "10.1007/978-3-540-89639-5_70"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ISVC08.pdf"
  thumbnail: "/assets/publications/paper-19.png"
  tags:
    - "Iris Recognition"
    - "Image Segmentation"
    - "Visible Wavelength"
  abstract: "The dramatic growth in practical applications for iris biometrics has been accompanied by many important developments in the underlying algorithms and techniques. Among others, one of the most active research areas concerns about the development of iris recognition systems less constrained to users, either increasing the image acquisition distances or the required lighting conditions. The main point of this paper is to give a process suitable for the automatic segmentation of iris images captured at the visible wavelength, on-the-move and within a large range of image acquisition distances (between 4 and 8 meters). Our experiments were performed on images of the UBIRIS.v2 database and show the robustness of the proposed method to handle the types of non-ideal images resultant of the aforementioned less constrained image acquisition conditions."

- id: "FaceDetectionTriangular"
  title: "Combining Rectangular and Triangular Image Regions to Perform Real-Time Face Detection"
  authors: "Hugo Proença, Sílvio Filipe"
  venue: "IEEE Proceedings of the International Conference on Signal Processing - ICSP'08"
  year: 2008
  status: "published"
  publication_type: "conference"
  doi: "10.1109/ICOSP.2008.4697274"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ICSP08.pdf"
  thumbnail: "/assets/publications/paper-18.png"
  tags:
    - "Face Detection"
    - "Computer Vision"
    - "Real-Time Processing"
  abstract: "Nowadays, face detection techniques assume growing relevance in a wide range of applications (e.g., bio- metrics and automatic surveillance)and constitute a pre- requisite of many image processing stages. Among a large number of published approaches, one of the most relevant is the method proposed by Viola and Jones [18] to perform real-time face detection through a cascade schema of weak classifiers that act together to com- pose a strong and robust classifier. This method was the basis of our work and motivated the key contributions given in this paper. At first, based on the computer graphics concept of \"triangle mesh\" we propose the notion of \"triangular integral feature\" to describe and model face properties. Also, we show results of our face detection experiments that point to an increase of the detection accuracy when the triangular features are mixed with the rectangular in the candidate feature set, which is considered an achievement. Also, it should be stressed that this optimization is obtained without any relevant in- crease in the computational requirements, either spacial or temporal, of the detection method."

- id: "RobustnessNoisyEnvironments"
  title: "Iris Recognition: A Method to Increase the Robustness to Noisy Imaging Environments Through the Selection of the Higher Discriminating Features"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEEE Proceedings of the International Conference on Computational Intelligence and Multimedia Applications - ICCIMA'07"
  year: 2007
  status: "published"
  publication_type: "conference"
  doi: "10.1109/ICCIMA.2007.119"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/iccima15.pdf"
  thumbnail: "/assets/publications/paper-17.png"
  tags:
    - "Iris Recognition"
    - "Feature Selection"
    - "Noisy Environments"
  abstract: "Continuous efforts have been made in searching for robust and effective iris coding methods, since Daugman's pioneering work on iris recognition was published. However, due to lack of robustness, the error rates of iris recognition systems significantly increase when images contain large portions of noise (reflections and iris obstructions), resultant from less constrained imaging conditions. Current iris encoding and matching proposals do not take into account the specific lighting conditions of the imaging environment, decreasing their adaptability to such dynamics conditions. In this paper we propose a method that, through a learning stage, takes into account the typical noisy regions propitiated by the imaging environment to select the higher discriminating features. Our experiments were performed on two well known iris image databases (CASIA and UBIRIS) and show a significant decrease of the error rates in the recognition of iris images corrupted by noise."

- id: "EntropyBasedCoding"
  title: "Iris Recognition: An Entropy-Based Coding Strategy Robust to Noisy Imaging Environments"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "Springer Lecture Notes in Computer Science – ISVC 2007: 3rd International Symposium on Visual Computing"
  year: 2007
  status: "published"
  publication_type: "conference"
  doi: "10.1007/978-3-540-76858-6_60"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ISVC07.pdf"
  thumbnail: "/assets/publications/paper-16.png"
  tags:
    - "Iris Recognition"
    - "Entropy-Based Coding"
    - "Noisy Environments"
  abstract: "The iris is currently accepted as one of the most accurate traits for biometric purposes. However, for the sake of accuracy, iris recognition systems rely on good quality images and significantly deteriorate their results when images contain large noisy regions, either due to iris obstructions (eyelids or eyelashes) or reflections (specular or lighting). In this paper we propose an entropy-based iris coding strategy that constructs an unidimensional signal from overlapped angular patches of normalized iris images. Further, in the comparison between biometric signatures we exclusively take into account signatures' segments of varying dimension. The hope is to avoid the comparison between components corrupted by noise and achieve accurate recognition, even on highly noisy images. Our experiments were performed in three widely used iris image databases (third version of CASIA, ICE and UBIRIS) and led us to observe that our proposal significantly decreases the error rates in the recognition of noisy iris images."

- id: "StructuralPatternAnalysis"
  title: "A Structural Pattern Analysis Approach to Iris Recognition"
  authors: "Hugo Proença"
  venue: "Springer Lecture Notes in Computer Science, Advances in Soft Computing – CORES 2007: 5th International Conference on Computer Recognition Systems"
  year: 2007
  status: "published"
  publication_type: "conference"
  doi: "10.1007/978-3-540-75175-5_90"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/CORES07.pdf"
  thumbnail: "/assets/publications/paper-15.png"
  tags:
    - "Iris Recognition"
    - "Structural Pattern Analysis"
    - "Pattern Recognition"
  abstract: "Continuous efforts have been made in searching for robust and effective iris coding methods, since Daugman's pioneering work on iris recognition was published. Proposed algorithms follow the statistical pattern recognition paradigm and encode the iris texture in- formation through phase, zero-crossing or texture-analysis based methods. In this paper we propose an iris recognition algorithm that follows the structural (syntactic) pattern recognition paradigm, which can be advantageous essentially for the purposes of description and of the human-perception of the system's functioning. Our experiments, that were performed on two widely used iris image databases (CASIA.v3 and ICE), show that the proposed iris structure provides enough discriminating information to enable accurate biometric recognition, while maintains the advantages intrinsic to structural pattern recognition systems."

- id: "NICE"
  title: "The NICE.I: Noisy Iris Challenge Evaluation – Part I"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEEE First International Conference on Biometrics: Theory, Applications and Systems – BTAS 2007"
  year: 2007
  status: "published"
  publication_type: "conference"
  doi: "10.1109/BTAS.2007.4401910"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BTAS07.pdf"
  thumbnail: "/assets/publications/paper-14.png"
  tags:
    - "Iris Recognition"
    - "Image Segmentation"
    - "NICE Challenge"
  abstract: "This paper gives an overview of the NICE.I : Noisy Iris Challenge Evaluation - Part I contest. This contest differs from others in two fundamental points. First, instead of the complete iris recognition process, it exclusively evaluates the iris segmentation and noise detection stages, allowing the independent evaluation of one of the main recognition error sources. Second, it operates on highly noisy images that were captured to simulate less constrained imaging environments and constitute the second version of the UBIRIS database (UBIRIS.v2). Further details can be seen at the contest web site (http://nice1.di.ubi.pt)."

- id: "NonCooperativeIris"
  title: "Toward Non-Cooperative Iris Recognition: A Classification Approach Using Multiple Signatures"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEEE Transactions on Pattern Analysis and Machine Intelligence"
  year: 2007
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TPAMI.2007.1016"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ProencaAlexandreMultipleSignaturesPAMI2007.pdf"
  thumbnail: "/assets/publications/paper-58.png"
  tags:
    - "Iris Recognition"
    - "Non-Cooperative Recognition"
    - "Multiple Signatures"
  abstract: "This paper focus on noncooperative iris recognition, i.e., the capture of iris images at large distances, under less controlled lighting conditions, and without active participation of the subjects. This increases the probability of capturing very heterogeneous images (regarding focus, contrast, or brightness) and with several noise factors (iris obstructions and reflections). Current iris recognition systems are unable to deal with noisy data and substantially increase their error rates, especially the false rejections, in these conditions. We propose an iris classification method that divides the segmented and normalized iris image into six regions, makes an independent feature extraction and comparison for each region, and combines each of the dissimilarity values through a classification rule. Experiments show a substantial decrease, higher than 40 percent, of the false rejection rates in the recognition of noisy iris images."

- id: "SegmentationVisibleWavelength"
  title: "On the Segmentation of Visible Wavelength Iris Images Acquired At-a-Distance and On-the-Move"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "Elsevier Image and Vision Computing"
  year: 2010
  status: "published"
  publication_type: "special_issue"
  pdf: "http://www.sciencedirect.com/science/publication?issn=02628856&volume=28&issue=2"
  thumbnail: "/assets/publications/paper-127.png"
  tags:
    - "Iris Recognition"
    - "Image Segmentation"
    - "Visible Wavelength"
    - "Non-Cooperative Recognition"

- id: "CariesDetection"
  title: "Caries Detection in Panoramic Dental X-ray Images"
  authors: "João Oliveira, Hugo Proença"
  venue: "Computational Vision and Medical Image Processing - Recent Trends, Springer Verlag book series: Computational Methods in Applied Sciences"
  year: 2010
  status: "published"
  publication_type: "book_chapter"
  doi: "10.1007/978-94-007-0011-6_10"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BC_Caries.pdf"
  thumbnail: "/assets/publications/paper-1.png"
  tags:
    - "Dental X-Ray"
    - "Caries Detection"
    - "Medical Imaging"
  abstract: "Dental Caries, also known as dental decay or tooth decay, is defined as a disease of the hard tissues of the teeth caused by the action of microorganisms found in plaque on fermentable carbohydrates (principally sugars). Therefore, the detection of dental caries in a preliminary stage is an important task. This chapter has two major purposes, firstly to announce the availability of a new data set of panoramic dental X-ray images. This data set contains 1392 images with varying types of noise, usually inherent to this kind of images. Secondly, we present a complete case study for the detection of dental caries in panoramic dental X-ray images."

- id: "ErrorRatesSegmentation"
  title: "Analysis of the Error Rates Regarding the Accuracy of the Segmentation Stage"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "Elsevier Image and Vision Computing"
  year: 2010
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.imavis.2009.03.003"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/IVC_SegmentInnaccuracies.pdf"
  thumbnail: "/assets/publications/paper-59.png"
  tags:
    - "Iris Recognition"
    - "Image Segmentation"
    - "Error Analysis"
  abstract: "Iris recognition has been widely used in several scenarios with very satisfactory results. As it is one of the earliest stages, the image segmentation is in the basis of the process and plays a crucial role in the success of the recognition task. In this paper we analyze the relationship between the accuracy of the iris segmentation process and the error rates of three typical iris recognition methods. We selected 5000 images of the UBIRIS, CASIA and ICE databases that the used segmentation algorithm can accurately segment and artificially simulated four types of segmentation inaccuracies. The obtained results allowed us to con- clude about a strong relationship between translational segmentation inaccuracies – that lead to errors in phase – and the recognition error rates."

- id: "StructuralPatternAnalysis"
  title: "An Iris Recognition Approach Through Structural Pattern Analysis Methods"
  authors: "Hugo Proença"
  venue: "Wiley Expert Systems, Special issue on Computer Recognition Systems"
  year: 2010
  status: "published"
  publication_type: "journal"
  doi: "10.1111/j.1468-0394.2009.00534.x"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ES_Structural.pdf"
  thumbnail: "/assets/publications/paper-60.png"
  tags:
    - "Iris Recognition"
    - "Structural Pattern Analysis"
    - "Biometrics"
  abstract: "Continuous efforts have been made in searching for robust and effective iris cod- ing methods, since Daugman's pioneering work on iris recognition was published. Proposed algorithms follow the statistical pattern recognition paradigm and encode the iris texture in- formation through phase, zero-crossing or texture-analysis based methods. In this paper we propose an iris recognition algorithm that follows the structural (syntactic) pattern recognition paradigm, which can be advantageous essentially for the purposes of description and of the human-perception of the system's functioning. Our experiments, that were performed on two widely used iris image databases (CASIA.v3 and ICE), show that the proposed iris structure provides enough discriminating information to enable accurate biometric recognition, while maintains the advantages intrinsic to structural pattern recognition systems."

- id: "IntroductionSegmentation"
  title: "Introduction to the Special Issue on the Segmentation of Visible Wavelength Iris Images Captured At-a-distance and On-the-move"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "Elsevier Image and Vision Computing"
  year: 2010
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.imavis.2009.09.004"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Introd_NICE1.pdf"
  thumbnail: "/assets/publications/paper-61.png"
  tags:
    - "Iris Recognition"
    - "Image Segmentation"
    - "Visible Wavelength"
    - "NICE Challenge"
  abstract: "Deployed iris recognition systems are mainly based on Daugman's pioneering approach, and have proven their effectiveness in relatively constrained scenarios: operating in the near infra-red spectrum (NIR, 700-900 nm), at close acquisition distances and with stop-and-stare interfaces. However, the human iris supports contactless data acquisition, and it can — at least theoretically — be imaged covertly. The feasibility of covert iris recognition receives increasing attention and is of particular interest for forensic and security purposes. In this scope, one possibility is the use of visible wavelength light (VW) to perform image acquisition, although the use of this type of light can severely degrade the quality of the captured data. This is mainly due to the optical properties of the two molecules that constitute the pigment of the human iris: brown-black Eumelanin (over 90%) and yellow-reddish Pheomelanin. Eumelanin has most of its radiative fluorescence under VW, which enables the capturing of a much higher level of detail, but also of many more noisy artefacts, including specular and diffuse reflections and shadows. Also, the spectral reflectance of the sclera is significantly higher in the VW than in the NIR and the spectral radiance of the iris in respect to the levels of its pigmentation varies much more significantly in the VW than in the NIR. Furthermore, traditional template- and boundary-based iris segmentation approaches will probably fail, due to difficulties in detecting edges or in fitting rigid shapes. All these reasons justify the need of specialized segmentation strategies and were the major motivations behind the NICE.I contest (http://nice1.di.ubi.pt) that gave birth to this issue of the Image and Vision Computing Journal."

- id: "InterpolationNormalization"
  title: "On the Role of Interpolation in the Normalization of Non-Ideal Visible Wavelength Iris Images"
  authors: "Gil Santos, Hugo Proença"
  venue: "International Conference on Computational Intelligence and Security - CIS'09"
  year: 2009
  status: "published"
  publication_type: "conference"
  doi: "10.1109/CIS.2009.113"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/cis09.pdf"
  thumbnail: "/assets/publications/paper-22.png"
  tags:
    - "Iris Recognition"
    - "Image Interpolation"
    - "Visible Wavelength"
  abstract: "The growth in practical applications for iris bio- metrics has been accompanied by relevant developments in the underlying algorithms and techniques. Along with the research focused on near-infrared (NIR) cooperatively captured images, efforts are being made to minimize the trade-off between the quality of the captured data and the recognition accuracy on less constrained environments, where images are obtained at the visible wavelength, at increased distances, over simplified protocols and adverse lightning. This paper addresses the effect of the interpolation method, used in the iris normalization stage, in the overall recognition error rates. This effect is stressed for systems operating under less constrained image acquisition setups and protocols, due to higher variations in the amounts of captured data. Our experiments led us to conclude that the utility of the image interpolating methods is directly corresponding to the levels of noise that images contain."

- id: "BiometricEvidenceFusion"
  title: "Biometric Recognition: When Is Evidence Fusion Advantageous?"
  authors: "Hugo Proença"
  venue: "Springer Lecture Notes in Computer Science – ISVC 2009: 5th International Symposium on Visual Computing"
  year: 2009
  status: "published"
  publication_type: "conference"
  doi: "10.1007/978-3-642-10520-3_66"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ISVC09.pdf"
  thumbnail: "/assets/publications/paper-23.png"
  tags:
    - "Biometric Recognition"
    - "Evidence Fusion"
    - "Performance Analysis"
  abstract: "Having assessed the performance gains due to evidence fusion, previous works reported contradictory conclusions. For some, a consistent improvement is achieved, while others state that the fusion of a stronger and a weaker biometric expert tends to produce worst results than if the best expert was used individually. The main contribution of this paper is to assess when improvements in performance are actually achieved, regarding the individual performance of each expert. Starting from readily satisfied assumptions about the score distributions generated by a biometric system, we predict the performance of each of the individual experts and of the fused system. Then, we conclude about the performance gains in fusing evidence from multiple sources. Also, we parameterize an empirically obtained relationship between the individual performance of the fused experts that contributes to decide whether evidence fusion techniques are advantageous or not."

- id: "DentalXRayDataset"
  title: "Dental X-Ray: A Data Set of Panoramic Dental Radiographs for Stomatologic Image Processing Purposes"
  authors: "João Oliveira, Hugo Proença"
  venue: "Taylor & Francis Proceedings of the II ECCOMAS Thematic Conference on Computational Vision and Medical Image Processing - VIPIMAGE'09"
  year: 2009
  status: "published"
  publication_type: "conference"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ECCOMAS09.pdf"
  thumbnail: "/assets/publications/paper-21.png"
  tags:
    - "Dental X-Ray"
    - "Dataset"
    - "Medical Imaging"
  abstract: "This paper has two major purposes: at firstly, to announce the availability of a new data set of panoramic dental X-ray images. This data set contains 1392 images with varying types of noise, usually inherent to this kind of images. Furthermore, the number of teeth per image and their dental morphology were not constant. Secondly, we propose a method to approximate the panoramic images in bitewing images, which are the most common type of images used in the human identification and in the tooth segmentation for the diagnosis of dental diseases."

- id: "NonCooperativeIris"
  title: "Non-Cooperative Iris Recognition: Issues and trends"
  authors: "Hugo Proença"
  venue: "EUSIPCO'11 - Nineteenth European Signal Processing Conference"
  year: 2011
  status: "published"
  publication_type: "conference"
  pdf: "http://di.ubi.pt/~hugomcp/doc/EUSIPCO11.pdf"
  thumbnail: "/assets/publications/paper-27.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Non-Cooperative Recognition"
  abstract: "To date, no research effort has produced a machine able to covertly recognize human beings. Contrary to popular belief, such automata are confined to science fiction, although it's not hard to anticipate the potential impact that they would have in the security and safety of modern societies (forensics and surveillance). Among the research programs that pursuit such type of biometric recognition, previous initiatives sought to acquire data from moving subjects, at long distances and under uncontrolled lighting conditions. This real-world scenario brings many challenges to the Pattern Recognition process, essentially due to poor quality of the acquired data. Several programs now seek to increase the robustness to noise of each phase of the recognition process (detection, segmentation, normalization, encoding and matching). This paper addresses the feasibility of such extremely ambitious type of biometric recognition, discusses the major issues behind the development of this technology and points some directions for further improvements."

- id: "QualityAssessmentIris"
  title: "Quality Assessment of Degraded Iris Images Acquired in the Visible Wavelength"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2011
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2010.2086446"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/VWIQ_IEEETIFS.pdf"
  thumbnail: "/assets/publications/paper-64.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Image Quality"
    - "Visible Wavelength"
  abstract: "Data quality assessment is a key issue, in order to broad the applicability of iris biometrics to unconstrained imaging conditions. Previous research efforts sought to use visible wavelength (VW) light imagery to acquire data at significantly larger distances than usual and on moving subjects, which makes this real world data notoriously different from the acquired in the near infra-red (NIR) setup. Having empirically observed that published strategies to assess iris image quality do not handle the specificity of such data, this paper proposes a method to assess the quality of VW iris samples captured in unconstrained conditions, according to the factors that are known to determine the quality of iris biometric data: focus, motion, angle, occlusions, area, pupillary dilation and levels of iris pigmentation. The key insight is to use the output of the segmentation phase in each assessment, which permits to handle severely degraded samples that are likely to result of such imaging setup. Also, our experiments point that the given method improves the effectiveness of VW iris recognition, by avoiding that poor quality samples are considered in the recognition process."

- id: "IntroductionUnconstrainedBiometrics"
  title: "Introduction to the Special Issue on Unconstrained Biometrics: Advances and Trends"
  authors: "Hugo Proença, Eliza Yingzi Du, Jacob Scharcanski"
  venue: "Springer Signal, Image and Video Processing"
  year: 2011
  status: "published"
  publication_type: "journal"
  doi: "10.1007/s11760-011-0243-7"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Introd_SIVP.pdf"
  thumbnail: "/assets/publications/paper-65.png"
  tags:
    - "Unconstrained Biometrics"
    - "Signal Processing"
    - "Image Processing"
  abstract: "To date, no research effort has produced a machine able to autonomously and covertly perform reliable recognition of human beings. Perhaps, contrary to popular belief, such automata are confined to science fiction, although it is not hard to anticipate the potential impact that they would have in modern societies (e.g., forensics and surveillance). Some of the biological traits used to perform biometric recognition support contactless data acquisition and can be imaged covertly. Thus, at least theoretically, the subsequent biometric recognition procedure can be performed without subjects' knowledge and in uncontrolled scenarios. This real-world scenario brings many challenges to the Pattern Recognition process, essentially due to poor quality of the acquired data. The feasibility of this type of recognition has received increasing attention and is of particular interest in visual surveillance, computer forensics, threat assessment, and other security areas. Though a growing number of researchers are concerned about the development of biometric recognition systems that operate in unconstrained conditions, many problems remain to be solved: how to deal with varying illumination sources, variations in poses and distances or blurred and low-quality data resultant of such acquisition conditions. This special issue is particularly devoted to emerging strategies to perform biometric recognition under uncontrolled data acquisition conditions, ideally fully covert ones. Topics of interest include the following: less controlled/covert data acquisition frameworks; biometric data quality assessment; normalization of poor-quality biometric data; contactless biometric recognition; analysis of recognition robustness; multimodal and multispectral biometrics."

- id: "UBEAR"
  title: "UBEAR: A Dataset of Ear Images Captured On-the-move in Uncontrolled Conditions"
  authors: "Rui Raposo, Edmundo Hoyle, Adolfo Peixinho, Hugo Proença"
  venue: "IEEE Workshop on Computational Intelligence in Biometrics and Identity Management - SSCI 2011 CIBIM"
  year: 2011
  status: "published"
  publication_type: "conference"
  doi: "10.1109/CIBIM.2011.5949208"
  pdf: "http://di.ubi.pt/~hugomcp/doc/UBEAR_SSCI10.pdf"
  thumbnail: "/assets/publications/paper-26.png"
  tags:
    - "Ear Biometrics"
    - "Dataset"
    - "Unconstrained Recognition"
  abstract: "In order to broad the applicability of biometric systems, the data acquisition constraints required for reliable recognition are receiving increasing attention. For some of the traits (e.g., face and iris) significant research efforts were already made toward the development of systems able to operate in completely unconstrained conditions. For other traits (e.g., the ear) no similar efforts are known. The main purpose of this paper is to announce the availability of a new data set of ear images, which main distinguishing feature is that its images were acquired from on-the-move subjects, under varying lighting conditions and without demanding to subjects any particular care regarding ear occlusions and poses. The data set is freely available to the research community and should constitute a valuable tool in assessing the possibility of performing reliable ear biometric recognition in such d challenging conditions."

- id: "IrisPreliminaryAssessment"
  title: "Iris Recognition: Preliminary Assessment about the Discriminating Capacity of Visible Wavelength Data"
  authors: "Gil Santos, Marco Bernardo, Paulo Fiadeiro, Hugo Proença"
  venue: "Sixth IEEE International Workshop on Multimedia Information Processing and Retrieval - MIPR 2010"
  year: 2010
  status: "published"
  publication_type: "conference"
  doi: "10.1109/ISM.2010.56"
  pdf: "http://di.ubi.pt/~hugomcp/doc/MIPR2010.pdf"
  thumbnail: "/assets/publications/paper-25.png"
  tags:
    - "Iris Recognition"
    - "Visible Wavelength"
    - "Biometrics"
  abstract: "The human iris supports contactless data acquisition and can be imaged covertly. These factors give raise to the possibility of performing biometric recognition procedure with- out subjects' knowledge and in uncontrolled data acquisition scenarios. The feasibility of this type of recognition has been receiving increasing attention, as is of particular interest in visual surveillance, computer forensics, threat assessment, and other security areas. In this paper we stress the role played by the spectrum of the visible light used in the acquisition process and assess the discriminating iris patterns that are likely to be acquired according to three factors: type of illuminant, it's luminance, and levels of iris pigmentation. Our goal is to perceive and quantify the conditions that appear to enable the biometric recognition process with enough confidence."

- id: "IrisDistributionBits"
  title: "Iris Recognition: Analysing the Distribution of the Iriscodes Concordant Bits"
  authors: "Gil Santos, Hugo Proença"
  venue: "IEEE Proceedings of the 3rd International Congress on Image and Signal Processing - CISP 2010"
  year: 2010
  status: "published"
  publication_type: "conference"
  doi: "10.1109/CISP.2010.5647404"
  pdf: "http://di.ubi.pt/~hugomcp/doc/CISP2010.pdf"
  thumbnail: "/assets/publications/paper-24.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Pattern Matching"
  abstract: "The growth in practical applications for iris bio- metrics has been accompanied by relevant developments in the underlying algorithms and techniques. Efforts are being made to minimize the tradeoff between the recognition error rates and data quality, acquired in the visible wavelength, in less controlled environments, over simplified acquisition protocols and varying lighting conditions. This paper presents an approach that can be regarded as an extension to the widely known Daugman's method. Its basis is the analysis of the distribution of the concordant bits when matching iriscodes on both the spatial and frequency domains. Our experiments show that this method is able to improve the recognition performance over images captured in less constrained acquisition setups and protocols. Such conclusion was drawn upon trials conducted for multiple datasets."

- id: "UBIRISv2"
  title: "The UBIRIS.v2: A Database of Visible Wavelength Iris Images Captured On-The-Move and At-A-Distance"
  authors: "Hugo Proença, Sílvio Filipe, Ricardo Santos, João Oliveira, Luís A. Alexandre"
  venue: "IEEE Transactions on Pattern Analysis and Machine Intelligence"
  year: 2010
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TPAMI.2009.66"
  pdf: "http://di.ubi.pt/~hugomcp/doc/UBIRISv2_IEEETPAMI.pdf"
  thumbnail: "/assets/publications/paper-62.png"
  tags:
    - "Iris Recognition"
    - "Dataset"
    - "Visible Wavelength"
  abstract: "The iris is regarded as one of the most useful traits for biometric recognition and the dissemination of nationwide iris-based recognition systems is imminent. However, currently deployed systems rely on heavy imaging constraints to capture near infrared images with enough quality. Also, all of the publicly available iris image databases contain data correspondent to such imaging constraints and therefore are exclusively suitable to evaluate methods thought to operate on these type of environments. The main purpose of this paper is to announce the availability of the UBIRIS.v2 database, a multisession iris images database which singularly contains data captured in the visible wavelength, at-a-distance (between four and eight meters) and on on-the-move. This database is freely available for researchers concerned about visible wavelength iris recognition and will be useful in accessing the feasibility and specifying the constraints of this type of biometric recognition."

- id: "IrisSegmentation"
  title: "Iris Recognition: On the Segmentation of Degraded Images Acquired in the Visible Wavelength"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Pattern Analysis and Machine Intelligence"
  year: 2010
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TPAMI.2009.140"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/VWIS_IEEETPAMI.pdf"
  thumbnail: "/assets/publications/paper-63.png"
  tags:
    - "Iris Recognition"
    - "Image Segmentation"
    - "Visible Wavelength"
  abstract: "Iris recognition imaging constraints are receiving increasing attention. There are several proposals to develop systems that operate in the visible wavelength and in less constrained environments. These imaging conditions engender acquired noisy artefacts that lead to severely degraded images, making iris segmentation a major issue. Having observed that existing iris segmentation methods tend to fail in these challenging conditions, we present a segmentation method that can handle degraded images acquired in less constrained conditions. We offer the following contributions: 1) to consider the sclera the most easily distinguishable part of the eye in degraded images, 2) to propose a new type of feature that measures the proportion of sclera in each direction and is fundamental in segmenting the iris, and 3) to run the entire procedure in deterministically linear time in respect to the size of the image, making the procedure suitable for real-time applications."

- id: "MultimodalOcularBiometrics"
  title: "Multimodal Ocular Biometrics Approach: A Feasibility Study"
  authors: "Oleg V. Komogortsev, Alex Karpov, Corey Holland, Hugo Proença"
  venue: "IEEE Fifth International Conference on Biometrics: Theory, Applications and Systems (BTAS)"
  year: 2012
  status: "published"
  publication_type: "conference"
  doi: "10.1109/BTAS.2012.6374579"
  pdf: "http://di.ubi.pt/~hugomcp/doc/BTAS12.pdf"
  thumbnail: "/assets/publications/paper-30.png"
  tags:
    - "Ocular Biometrics"
    - "Multimodal Biometrics"
    - "Oculomotor Plant Characteristics"
  abstract: "Growing efforts have been concentrated on the development of alternative biometric recognition strategies, the intended goal to increase the accuracy and counterfeit-resistance of existing systems without increased cost. In this paper, we propose and evaluate a novel biometric approach using three fundamentally different traits captured by the same camera sensor. Considered traits include: 1) the internal, non-visible, anatomical properties of the human eye, represented by Oculomotor Plant Characteristics (OPC); 2) the visual attention strategies employed by the brain, represented by Complex Eye Movement pat- terns (CEM); and, 3) the unique physical structure of the iris. Our experiments, performed using a low-cost web camera, indicate that the combined ocular traits improve the accuracy of the resulting system. As a result, the combined ocular traits have the potential to enhance the ac- curacy and counterfeit-resistance of existing and future biometric systems."

- id: "EditorialVisibleWavelength"
  title: "Editorial of the Special Issue On the Recognition of Visible Wavelength Iris Images Captured At-a-distance and On-the-move"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "Elsevier Pattern Recognition Letters"
  year: 2012
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.patrec.2012.03.003"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Introd_PRL.pdf"
  thumbnail: "/assets/publications/paper-68.png"
  tags:
    - "Iris Recognition"
    - "Visible Wavelength"
    - "NICE Challenge"
  abstract: "This special issue regards the recognition of degraded iris images acquired in visible wavelengths. During 2009 and 2010, the University of Beira Interior (Portugal) promoted two International evaluation initiatives about this subject, named Noisy Iris Challenge Evaluation (NICE) I and II. The first one focussed on the evaluation of iris segmentation strategies, considering that iris data acquired in visible wavelengths (VW) usually has much higher level of detail than traditionally used near infra-red data (NIR), but also has many more noise artefacts, including specular and diffuse reflections and shadows. Also, the spectral reflectance of the sclera is significantly higher in the VW than in the NIR and the spectral radiance of the iris with respect to the levels of its pigmentation varies much more significantly in the VW than in the NIR.The NICE:II contest complemented its predecessor in terms of the traditional pattern recognition stages, evaluating different signature encoding and matching strategies. In order to guarantee that unbiased performance measures were obtained, all the participants used the exact same segmented data, which were automatically obtained according to the highest performing method in the NICE:I. Again, participation in NICE:II was free of charge and opened to all research and academic institutions. Sixty-seven participants from thirty countries registered in the contest 1 and received a training set composed of 1000 images and the corresponding binary iris segmentation masks."

- id: "SpecialIssueVisibleWavelength"
  title: "Special Issue On the Recognition of Visible Wavelength Iris Images Captured At-a-distance and On-the-move"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "Elsevier Pattern Recognition Letters"
  year: 2012
  status: "published"
  publication_type: "special_issue"
  pdf: "http://www.journals.elsevier.com/pattern-recognition-letters/"
  thumbnail: "/assets/publications/paper-126.png"
  tags:
    - "Iris Recognition"
    - "Visible Wavelength"
    - "NICE Challenge"

- id: "TowardCovertIris"
  title: "Toward Covert Iris Biometric Recognition: Experimental Results From the NICE Contests"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2012
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2011.2177659"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/NICE_TIFS.pdf"
  thumbnail: "/assets/publications/paper-67.png"
  tags:
    - "Iris Recognition"
    - "Visible Wavelength"
    - "NICE Contest"
  abstract: "This paper announces and discusses the experimental results from the Noisy Iris Challenge Evaluation (NICE), an iris biometric evaluation initiative that received worldwide partici- pation and whose main innovation is the use of heavily degraded data acquired in the visible wavelength and uncontrolled setups, with subjects moving and at widely varying distances. The NICE contest included two separate phases: 1) the NICE.I evaluated iris segmentation and noise detection techniques and 2) the NICE:II evaluated encoding and matching strategies for biometric signatures. Further, we give the performance values observed when fusing recognition methods at the score level, which was observed to outperform any isolated recognition strategy. These results provide an objective estimate of the potential of such recognition systems and should be regarded as reference values for further improvements of this technology, which—if successful—may significantly broaden the applicability of iris biometric systems to domains where the subjects cannot be expected to cooperate."

- id: "PeriocularRecognition"
  title: "Periocular Recognition: Analysis of Performance Degradation Factors"
  authors: "Chandrashekhar Padole, Hugo Proença"
  venue: "Fifth IAPR/IEEE International Conference on Biometrics (ICB)"
  year: 2012
  status: "published"
  publication_type: "conference"
  doi: "10.1109/ICB.2012.6199790"
  pdf: "http://di.ubi.pt/~hugomcp/doc/ICB12.pdf"
  thumbnail: "/assets/publications/paper-29.png"
  tags:
    - "Periocular Recognition"
    - "Biometrics"
    - "Performance Analysis"
  abstract: "Among the available biometric traits such as face, iris and fingerprint, there is an active research being carried out in the direction of unconstrained biometrics. Periocular recognition has proved its effectiveness and is regarded as complementary to iris recognition. The main objectives of this paper are three-fold: 1) to announce the availability of periocular dataset, which has a variability in terms of scale change (due to camera-subject distance), pose variation and non-uniform illumination; 2) to investigate the perfor- mance of periocular recognition methods with the presence of various degradation factors; 3) propose a new initialization strategy for the definition of the periocular region-of-interest (ROI), based on the geometric mean of eye corners. Our experiments confirm that performance can be consistently improved by this initialization method, when compared to the classical technique."

- id: "FusingColorShape"
  title: "Fusing Color and Shape Descriptors in the Recognition of Degraded Iris Images Acquired at Visible Wavelength"
  authors: "Hugo Proença, Gil Santos"
  venue: "Elsevier Computer Vision and Image Understanding"
  year: 2012
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.cviu.2011.10.008"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/VWIR_CVIU.pdf"
  thumbnail: "/assets/publications/paper-66.png"
  tags:
    - "Iris Recognition"
    - "Visible Wavelength"
    - "Color Features"
    - "Shape Features"
  abstract: "Despite the substantial research into the development of covert iris recognition technologies, no machine to date has been able to reliably perform recognition of human beings in real-world data. This limitation is especially evident in the application of such technology to large-scale identification scenarios, which demand extremely low error rates to avoid frequent false alarms. Most previously published works have used intensity data and performed multi-scale analysis to achieve recognition, obtaining encouraging performance values that are nevertheless far from desirable. This paper presents two key innovations. (1) A recognition scheme is proposed based on techniques that are substantially different from those traditionally used, starting with the dynamic partition of the noise-free iris into disjoint regions from which MPEG-7 color and shape descriptors are extracted. (2) The minimal levels of linear correlation between the outputs produced by the proposed strategy and other state-of-the-art techniques suggest that the fusion of both recognition techniques significantly improve performance, which is regarded as a positive step towards the development of extremely ambitious types of biometric recognition."

- id: "RobustEyeCorner"
  title: "A Robust Eye-Corner Detection Method for Real-World Data"
  authors: "Gil Santos, Hugo Proença"
  venue: "IEEE International Joint Conference on Biometrics (IJCB)"
  year: 2011
  status: "published"
  publication_type: "conference"
  doi: "10.1109/IJCB.2011.6117596"
  pdf: "http://di.ubi.pt/~hugomcp/doc/IJCB11.pdf"
  thumbnail: "/assets/publications/paper-28.png"
  tags:
    - "Eye Corner Detection"
    - "Computer Vision"
    - "Biometrics"
  abstract: "Corner detection has been motivating several research works and is particularly important in different computer vision tasks, acting as basis for further image understanding stages. Particularly, the detection of eye-corners in facial images is relevant for domains such as biometric systems and assisted-driving systems. Having empirically evaluated the state-of-the-art of eye-corner detection proposals, we observed that they only achieve satisfactory results when dealing with good quality data. Hence, in this paper we describe an eye- corner detection method with particular focus on robustness, i.e., the suitability to deal with degraded data, toward the applicability in real-world conditions. Our experiments show that the proposed method outperforms others either in noise- free and degraded data (blurred, rotated and with significant variations in scale), which is regarded as the main achievement."

- id: "SpecialIssueBiometrics"
  title: "Special Issue On Unconstrained Biometrics: Advances and Trends"
  authors: "Hugo Proença, Eliza Yingzi Du, Jacob Scharcanski"
  venue: "Springer Signal, Image and Video Processing"
  year: 2011
  status: "published"
  publication_type: "special_issue"
  pdf: "http://www.springer.com/engineering/signals/journal/11760"
  thumbnail: "/assets/publications/paper-125.png"
  tags:
    - "Unconstrained Biometrics"
    - "Signal Processing"
    - "Image Processing"

- id: "KeypointsEvaluation"
  title: "Performance Evaluation of Image Local Keypoints Detection and Matching Techniques"
  authors: "Hugo Proença"
  venue: "Springer Signal, Image and Video Processing"
  year: 2013
  status: "published"
  publication_type: "journal"
  doi: "10.1007/s11760-013-0535-1"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/keypoints_SIVP.pdf"
  thumbnail: "/assets/publications/paper-71.png"
  tags:
    - "Keypoint Detection"
    - "Keypoint Matching"
    - "Image Processing"
    - "Performance Evaluation"
  abstract: "The extraction of local photometric descriptors from images has been extensively reported in the computer vision literature. The main purpose of this paper is to provide an objective comparison between the performance of four of the most popular algorithms of this kind: SIFT, SURF, BRIEF and DAISY. Constraining our analysis to grayscale data, several major points distinguish this work from the previous evaluation initiatives: (1) A large amount of data were used, representing a broad range of real-world scenes; (2) an automated evaluation procedure was devised, in order to minimize subjectivity; and (3) we analyze the reliability of each algorithm not only in terms of the distances between corresponding feature descriptors but also of their order statistics. Also, the public availability of a new annotated data set is reported, which is suitable for the automated and statistically significant evaluation of keypoint detection and match- ing strategies."

- id: "DegradedOcularImages"
  title: "Iris Biometrics: Synthesis of Degraded Ocular Images"
  authors: "Luís Cardoso, André Barbosa, Frutuoso G. Silva, António Pinheiro, Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2013
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2013.2262942"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/NOISYRIS_TIFS.pdf"
  thumbnail: "/assets/publications/paper-69.png"
  tags:
    - "Iris Recognition"
    - "Synthetic Data"
    - "Degraded Images"
    - "Biometric Experiments"
  abstract: "Iris recognition is a popular technique for recognizing humans. However, as is the case with most biometric traits, it is difficult to collect data that are suitable for use in experiments due to three factors: 1) the substantial amount of data that is required; 2) the time that is spent in the acquisition process; and 3) the security and privacy concerns of potential volunteers. This paper de- scribes a stochastic method for synthesizing ocular data to support experiments on iris recognition. Specifically, synthetic data are in- tended for use in the most important phases of those experiments: segmentation and signature encoding/matching. The resulting data have an important characteristic: they simulate image acquisition under uncontrolled conditions. We have experimentally confirmed that the proposed strategy can mimic the data degradation factors that usually result from such conditions. Finally, we announce the availability of an online platform for generating degraded synthetic ocular data. This platform is freely accessible worldwide."

- id: "IndexingRetrieving"
  title: "Iris Biometrics: Indexing and Retrieving Heavily Degraded Data"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2013
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2013.2283458"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/VWII_TIFS.pdf"
  thumbnail: "/assets/publications/paper-73.png"
  tags:
    - "Iris Biometrics"
    - "Indexing"
    - "Retrieval"
    - "Degraded Data"
  abstract: "Most of the methods to index iris biometric signa- tures were designed for decision environments with a clear sepa- ration between genuine and impostor matching scores. However, in case of less controlled data acquisition, images will be degraded and the decision environments poorly separated. This paper proposes an indexing / retrieval method for degraded images and operates at the code level, making it compatible with different feature encoding strategies. Gallery codes are decomposed at multiple scales, and according to their most reliable components at each scale, the position in an n-ary tree determined. In retrieval, the probe is decomposed similarly, and the distances to multi-scale centroids are used to penalize paths in the tree. At the end, only a subset of the branches is traversed up to the last level. When compared to related strategies, the proposed method outperforms them on degraded data, particularly in the performance range most important for biometrics (hit rates above 0.95). Finally, according to the computational cost of the retrieval phase, the number of enrolled identities above which indexing is computationally cheaper than an exhaustive search is determined."

- id: "LeishmaniaAnnotation"
  title: "Automatic annotation of Leishmania infections in fluorescence microscopy images"
  authors: "João C. Neves, Helena Castro, Hugo Proença, Miguel Coimbra"
  venue: "Proceedings of the International Conference on Image Analysis and Recognition - ICIAR 2013"
  year: 2013
  status: "published"
  publication_type: "conference"
  doi: "10.1007/978-3-642-39094-4_70"
  pdf: "http://di.ubi.pt/~hugomcp/doc/ICIAR13.pdf"
  thumbnail: "/assets/publications/paper-33.png"
  tags:
    - "Fluorescence Microscopy"
    - "Leishmania"
    - "Image Analysis"
    - "Automatic Annotation"
  abstract: "Leishmania is a unicellular parasite that infects mammals and biologists are interested in determining the effect of drugs in Leishmania infections. This requires the manual annotation of the number of macrophages and parasites in images, in order to obtain the percentage of infection (IP), the average number of parasites per infected cell (NPI) and the infection index (IX). Considering that manual annotation is tedious, time-consuming and often erroneous, in this paper we propose an automatic method for automatic annotation of Leishmania infections us- ing fluorescent microscopy. Moreover, when compared to related works, the proposed method is able to get superior performance under most perspectives."

- id: "CompensatingPoseIllumination"
  title: "Compensating for Pose and Illumination in Unconstrained Periocular Biometrics"
  authors: "Chandrashekhar Padole, Hugo Proença"
  venue: "International Journal of Biometrics"
  year: 2013
  status: "published"
  publication_type: "journal"
  doi: "10.1504/IJBM.2013.055971"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Chandra_IJB.pdf"
  thumbnail: "/assets/publications/paper-70.png"
  tags:
    - "Periocular Biometrics"
    - "Pose Compensation"
    - "Illumination Compensation"
    - "Unconstrained Biometrics"
  abstract: "In the context of less constrained biometrics recognition, the use of information from the vicinity of the eyes (periocular) is considered with high potential and motivated several recent proposals. In this paper, we focus on two factors that are known to degrade the performance of periocular recognition: varying illumination conditions and subjects pose. Hence, this paper has three major purposes: 1) describe the decreases in performance due to varying illumination and subjects poses; 2) propose two techniques to improve the robustness to these factors; 3) announce the availability of an annotated dataset of periocular data (UBIPosePr), where poses vary in regular intervals, turning it especially suitable to assess the effects of misalignments between camera and subjects in periocular recognition."

- id: "PeriocularEmergingTechnology"
  title: "Periocular Biometrics: An Emerging technology for Unconstrained Scenarios"
  authors: "Gil Santos, Hugo Proença"
  venue: "Proceedings of the IEEE Symposium on Computational Intelligence in Biometrics and Identity Management - CIBIM 2013"
  year: 2013
  status: "published"
  publication_type: "conference"
  doi: "10.1109/CIBIM.2013.6607908"
  pdf: "http://di.ubi.pt/~hugomcp/doc/CIBIM13.pdf"
  thumbnail: "/assets/publications/paper-31.png"
  tags:
    - "Periocular Biometrics"
    - "Unconstrained Scenarios"
    - "Biometric Recognition"
  abstract: "The periocular region has recently emerged as a promising trait for unconstrained biometric recognition, specially on cases where neither the iris and a full facial picture can be obtained. Previous studies concluded that the regions in the vicinity of the human eye - the periocular region- have surprisingly high discriminating ability between individuals, are relatively permanent and easily acquired at large distances. Hence, growing attention has been paid to periocular recognition methods, on the performance levels they are able to achieve, and on the correlation of the responses given by other. This work overviews the most relevant research works in the scope of periocular recognition: summarizes the developed methods, and enumerates the current issues, providing a comparative overview. For contextualization, a brief overview of the biometric field is also given."

- id: "FacialExpressions"
  title: "Facial Expressions: Discriminability of Facial Regions and Relationship to Biometrics Recognition"
  authors: "Elisa Barroso, Gil Santos, Hugo Proença"
  venue: "Proceedings of the IEEE Symposium on Computational Intelligence in Biometrics and Identity Management - CIBIM 2013"
  year: 2013
  status: "published"
  publication_type: "conference"
  doi: "10.1109/CIBIM.2013.6607918"
  pdf: "http://di.ubi.pt/~hugomcp/doc/CIBIM13_01.pdf"
  thumbnail: "/assets/publications/paper-32.png"
  tags:
    - "Facial Expressions"
    - "Biometric Recognition"
    - "Facial Regions"
    - "Discriminability"
  abstract: "Facial expressions result from movements of muscular action units, in response to internal emotion states or perceptions, and it has been shown that they decrease the performance of face-based biometric recognition techniques. This paper focuses in the recognition of facial expressions and has the following purposes: 1) confirm the suitability of using dense image descriptors widely known in biometrics research (e.g., local binary patterns and histograms of oriented gradients) to recognize facial expressions; 2) compare the effectiveness attained when using different regions of the face to recognize expressions; 3) compare the effectiveness attained when the identity of subjects is known / unknown, before attempting to recognize their facial expressions."

- id: "PeriocularEGM"
  title: "Periocular Biometrics: Constraining the EGM Algorithm to Biologically Plausible Distortions"
  authors: "Hugo Proença, Juan C. Moreno"
  venue: "IET Biometrics"
  year: 2013
  status: "published"
  publication_type: "journal"
  doi: "10.1049/iet-bmt.2013.0039"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/EGM_IETB.pdf"
  thumbnail: "/assets/publications/paper-72.png"
  tags:
    - "Periocular Biometrics"
    - "Elastic Graph Matching"
    - "Biologically Plausible Distortions"
  abstract: "In biometrics research, the periocular region has been regarded as an interesting trade-off between the face and the iris, particularly in unconstrained data acquisition setups. As in other biometric traits, the current challenge is the development of more robust recognition algorithms. Having investigated the suitability of the 'elastic graph matching' (EGM) algorithm to handle non- linear distortions in the periocular region because of facial expressions, the authors observed that vertices locations often not correspond to displacements in the biological tissue. Hence, they propose a 'globally coherent' variant of EGM (GC-EGM) that avoids sudden local angular movements of vertices while maintains the ability to faithfully model non-linear distortions. Two main adaptations were carried out: (i) a new term for measuring vertices similarity and (ii) a new term in the edges-cost function penalises changes in orientation between the model and test graphs. Experiments were carried out both in synthetic and real data and point for the advantages of the proposed algorithm. Also, the recognition performance when using the EGM and GC-EGM was compared, and statistically significant improvements in the error rates were observed when using the GC-EGM variant."

- id: "IrisVisibleWavelength"
  title: "Iris Recognition in the Visible Wavelength: Issues and Trends"
  authors: "Hugo Proença"
  venue: "Handbook of Iris Recognition, Mark J. Burge and K. Bowyer (Eds.), Springer Verlag book series"
  year: 2013
  status: "published"
  publication_type: "book_chapter"
  isbn: "978-1-4471-4401-4"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BC_Handbook.pdf"
  thumbnail: "/assets/publications/paper-2.png"
  tags:
    - "Iris Recognition"
    - "Visible Wavelength"
    - "Unconstrained Recognition"
  abstract: "The human iris supports contactless data acquisition and can be imaged covertly. Thus, at least theoretically, the subsequent biometric recognition procedure can be performed without subjects' knowledge. The feasibility of this type of recognition has received increasing attention and is of particular interest for forensic and security purposes, such as the pursuit of criminals and terrorists and the search for missing children. Among others, one active research area sought to use visible wavelength (VW) light imagery to acquire data at significantly larger distances than usual and on moving subjects, which is a difficult task because this real-world data is notoriously different from the one used in the near infra-red (NIR) setup. This chapter addresses the feasibility of performing reliable biometric recognition using VW data acquired under dynamic lighting conditions and unconstrained acquisition protocols: with subjects at large distances (between 4 and 8 meters) and on-the-move."

- id: "BiometricRecognitionInTheWild"
  title: "Biometric Recognition In-The-Wild"
  authors: "Hugo Proença"
  venue: "MDPI Symmetry"
  year: 2014
  status: "published"
  publication_type: "special_issue"
  issn: "2073-899"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Symmetry_SI.pdf"
  thumbnail: "/assets/publications/paper-122.png"
  tags:
    - "Biometric Recognition"
    - "In-The-Wild"
    - "Unconstrained Environments"
  abstract: ""

- id: "MobileIrisChallenge"
  title: "Mobile Iris Challenge Evaluation"
  authors: "Maria De Marsico, Michele Nappi, Hugo Proença"
  venue: "Elsevier Pattern Recognition Letters"
  year: 2014
  status: "published"
  publication_type: "special_issue"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/MICHE_SI.pdf"
  thumbnail: "/assets/publications/paper-123.png"
  tags:
    - "Iris Recognition"
    - "Mobile Biometrics"
    - "Challenge Evaluation"
  abstract: ""

- id: "SignalImageProcessing"
  title: "Signal and Image Processing for Biometrics: State of the Art and Recent Advances"
  authors: "Jacob Scharcanski, Hugo Proença, Eliza Yingzi Du"
  venue: "Springer-Verlag book series, Lecture Notes on Electrical Engineering"
  year: 2014
  status: "published"
  publication_type: "book"
  isbn: "978-3-642-54079-0"
  thumbnail: "/assets/publications/paper-129.png"
  tags:
    - "Signal Processing"
    - "Image Processing"
    - "Biometrics"
  abstract: ""

- id: "RobustPeriocularFusion"
  title: "Robust Periocular Recognition by Fusing Local to Holistic Sparse Representations"
  authors: "Juan C. Moreno, V. B. Surya Prasath, Hugo Proença"
  venue: "Proceedings of the 6th International Conference on Security of Information and Networks - SIN 2013"
  year: 2013
  status: "published"
  publication_type: "conference"
  doi: "10.1145/2523514.2523540"
  pdf: "http://di.ubi.pt/~hugomcp/doc/SIN13.pdf"
  thumbnail: "/assets/publications/paper-35.png"
  tags:
    - "Periocular Recognition"
    - "Sparse Representations"
    - "Data Fusion"
  abstract: "Sparse representations have been advocated as a relevant advance in biometrics research. In this paper we propose a new algorithm for fusion at the data level of sparse representations, each one obtained from image patches. The main novelties are two-fold: 1) a dictionary fusion scheme is formalised, using the l1−minimization with the gradient projection method; 2) the proposed representation and classification method does not require the non-overlapping condition of image patches from where individual dictionaries are obtained. In the experiments, we focused in the recognition of periocular images and obtained independent dictionaries for the eye, eyebrow and skin regions, that were subsequently fused. Results obtained in the publicly available UBIRIS.v2 data set show consistent improvements in the recognition effectiveness when compared to state-of- the-art related representation and classification techniques."

- id: "SyntheticIrisCodes"
  title: "Creating Synthetic IrisCodes to Feed Biometrics Experiments"
  authors: "Hugo Proença, João C. Neves"
  venue: "Proceedings of the 2013 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications - BioMS 2013"
  year: 2013
  status: "published"
  publication_type: "conference"
  doi: "10.1109/BIOMS.2013.6656141"
  pdf: "http://di.ubi.pt/~hugomcp/doc/BioMS13.pdf"
  thumbnail: "/assets/publications/paper-34.png"
  tags:
    - "Iris Recognition"
    - "Synthetic Data"
    - "IrisCodes"
    - "Biometric Experiments"
  abstract: "The collection of iris data suitable to be used in experiments is difficult, mainly due to two factors: 1) the time spent by volunteers in the acquisition process; and 2) security / privacy concerns of volunteers. Even though there are methods to create images of artificial irises, there is no method exclusively focused in the synthesis of the iris biometric signatures (IrisCodes). In experiments related with some phases of the biometric recognition process (e.g., indexing / retrieval), a large number of signatures is required for proper evaluation, which, in case of real data, is extremely hard to obtain. Hence, this paper describes a stochastic method to synthesize IrisCodes, based on the notion of data correlation. These artificial signatures can be used to feed experiments on iris recognition, namely on the iris matching, indexing and retrieval phases. We experimentally confirmed that both the genuine and impostor distributions obtained on the artificial data closely resemble the values obtained in data sets of real irises. Finally, another interesting feature is that the method is easily parametrized to mimic IrisCodes extracted from data of varying levels of quality, i.e., ranging from data acquired in high controlled to unconstrained environments."

- id: "ReigSAC"
  title: "ReigSAC: Fast Discrimination of Spurious Keypoint Correspondences on Planar Surfaces"
  authors: "Hugo Proença"
  venue: "Springer Machine Vision and Applications"
  year: 2014
  status: "published"
  publication_type: "journal"
  doi: "10.1007/s00138-014-0593-6"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Keypoints_MVA.pdf"
  thumbnail: "/assets/publications/paper-74.png"
  tags:
    - "Keypoint Correspondences"
    - "Computer Vision"
    - "RANSAC"
    - "Planar Surfaces"
  abstract: "Various methods were proposed to detect/match special interest points (keypoints) in images and some of them (e.g., SIFT and SURF) are among the most cited tech- niques in computer vision research. This paper describes an algorithm to discriminate between genuine and spurious key- point correspondences on planar surfaces. We draw random samples of the set of correspondences, from which homogra- phies are obtained and their principal eigenvectors extracted. Density estimation on that feature space determines the most likely true transform. Such homography feeds a cost func- tion that gives the goodness of each keypoint correspondence. Being similar to the well-known RANSAC strategy, the key finding is that the main eigenvector of the most (genuine) homographies tends to represent a similar direction. Hence, density estimation in the eigenspace dramatically reduces the number of transforms actually evaluated to obtain reli- able estimations. Our experiments were performed on hard image data sets, and pointed that the proposed approach yields effectiveness similar to the RANSAC strategy, at sig- nificantly lower computational burden, in terms of the pro- portion between the number of homographies generated and those that are actually evaluated."

- id: "UsingOcularData"
  title: "Using Ocular Data for Unconstrained Biometric Recognition"
  authors: "Hugo Proença, Gil Santos, João C. Neves"
  venue: "Face Recognition in Adverse Conditions, Maria De Marsico, Michele Nappi, Massimo Tistarelli (Eds.), Advances in Computational Intelligence and Robotics Book Series"
  year: 2014
  status: "published"
  publication_type: "book_chapter"
  issn: "2327-0411"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BC_UOD.pdf"
  thumbnail: "/assets/publications/paper-3.png"
  tags:
    - "Ocular Biometrics"
    - "Periocular Recognition"
    - "Unconstrained Biometrics"
  abstract: "There are several scenarios where a full facial picture cannot be obtained nor the iris properly imaged. For such cases, a good possibility might be to use the ocular region for recognition, which is a relatively new idea and is regarded as a good trade-off between using the whole face or the iris alone. The area in the vicinity of the eyes is designated as periocular and is particularly useful on less constrained conditions, when image acquisition is unreliable, or to avoid iris pattern spoofing. This chapter provides a comprehensive summary of the most relevant research conducted in the scope of ocular (periocular) recognition methods. We compare the main features of the publicly available data sets and summarize the techniques most frequently used in the recognition algorithms. Also, we present the state-of-the-art results in terms of recognition accuracy and discuss the current issues on this topic, together with some directions for further work."

- id: "FacialSketches"
  title: "Biometric Identification from Facial Sketches of Poor Fidelity: Comparison of Human and Machine Performance"
  authors: "Hugo Proença, João C. Neves, João Sequeiros, Nuno Carapito, Nuno C. Garcia"
  venue: "Signal and Image Processing for Biometrics : State of the Art and Recent Advances, Jacob Scharcanski, Hugo Proença, Eliza Yingzi Du (Eds.), Springer Verlag book series"
  year: 2014
  status: "published"
  publication_type: "book_chapter"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BC_Sketches.pdf"
  thumbnail: "/assets/publications/paper-4.png"
  tags:
    - "Facial Sketches"
    - "Biometric Identification"
    - "Human vs Machine Performance"
  abstract: "Facial sketch recognition refers to the establishment of a link between a drew representation of a human face and an identity, based on information given by a eyewitness of some illegal act. It is a topic of growing interest, and various software frameworks to synthesize sketches are available nowadays. When com- pared to the traditional hand-made sketches, such sketches resemble more closely the appearance of real mugshots, and led to the possibility of using automated face recognition methods in the identification task. However, there are often deficiencies of witnesses in describing the subjects' appearance, which might bias the main features of sketches with respect to the corresponding identity. This chapter com- pares the human and machine performance in the task of sketch identification (rank- 1 identification). One hundred subjects were considered as gallery data, and five images from each stored in a database. Also, one hundred sketches were drew by non-professionals and used as probe data, each of these resembling an identity in the gallery set. Next, a set of volunteers was asked to identify each sketch, and their answers compared to the rank-1 identification responses given by automated face recognition techniques. Three appearance-based face recognition algorithms were used: 1) Gabor-based description, with l2 norm distance ; 2) sparse representation for classification; and 3) eigenfaces. The sparse representation for classification algorithm yielded the best results, whereas the responses given by the Gabor-based description algorithm were the most correlated to human responses."

- id: "BrainMRISegmentation"
  title: "Fast and Globally Convex Multiphase Active Contours for Brain MRI Segmentation"
  authors: "Juan C. Moreno, V. B. Surya Prasath, Hugo Proença, K. Palaniappan"
  venue: "Elsevier Computer Vision and Image Understanding"
  year: 2014
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.cviu.2014.04.010"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/MRI_Segmentation.pdf"
  thumbnail: "/assets/publications/paper-76.png"
  tags:
    - "Brain MRI Segmentation"
    - "Active Contours"
    - "Image Segmentation"
    - "Medical Imaging"
  abstract: "Multiphase active contour based models are useful in identifying multiple regions with spatial consistency but varying characteristics such as the mean intensities of regions. Segmenting brain magnetic resonance images (MRIs) using a multiphase approach is useful to differentiate white and gray matter tissue for anatomical, functional and disease studies. Multiphase active contour methods are superior to other approaches due to their topological flexibility, accurate boundaries, robustness to image variations and adaptive energy functionals. Globally convex methods are furthermore initialization independent. We extend the relaxed globally convex Chan and Vese two-phase piecewise constant energy minimization formulation of Chan et al. (2006) [1] to the multiphase domain and prove the existence of a global minimizer in a specific space which is one of the novel contributions of the paper. An efficient dual minimization implementation of our binary partitioning function model accurately describes disjoint regions using stable segmentations by avoiding local minima solutions. Experimental results indicate that the proposed approach provides consistently better accuracy than other related multiphase active contour algorithms using four different error metrics (Dice, Rand Index, Global Consistency Error and Variation of Information) even under severe noise, intensity inhomogeneities, and partial volume effects in MRI imagery."

- id: "FaceRecognitionMisalignments"
  title: "Face Recognition: Handling Data Misalignments Implicitly by Fusion of Sparse Representations"
  authors: "Hugo Proença, João C. Neves, Juan C. Moreno"
  venue: "IET Computer Vision"
  year: 2014
  status: "published"
  publication_type: "journal"
  doi: "10.1049/iet-cvi.2014.0039"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/FaceSparse_IETCV.pdf"
  thumbnail: "/assets/publications/paper-77.png"
  tags:
    - "Face Recognition"
    - "Sparse Representations"
    - "Data Misalignments"
    - "Fusion"
  abstract: "Sparse representations for classification (SRC) are considered a relevant advance to the biometrics field, but are particularly sensitive to data misalignments. In previous studies, such misalignments were compensated for by finding appropriate geometric transforms between the elements in the dictionary and the query image, which is costly in terms of computational burden. This study describes an algorithm that compensates for data misalignments in SRC in an implicit way, that is, without finding/applying any geometric transform at every recognition attempt. The authors' study is based on three concepts: (i) sparse representations; (ii) projections on orthogonal subspaces; and (iii) discriminant locality preserving with maximum margin projections. When compared with the classical SRC algorithm, apart from providing slightly better performance, the proposed method is much more robust against global/local data misalignments. In addition, it attains performance close to the state-of-the-art algorithms at a much lower computational cost, offering a potential solution for real- time scenarios and large-scale applications."

- id: "MasterSlaveCalibration"
  title: "A Master-slave Calibration Algorithm with Fish-eye Correction"
  authors: "João C. Neves, Juan C. Moreno, Hugo Proença"
  venue: "Hindawi Mathematical Problems in Engineering"
  year: 2015
  status: "published"
  publication_type: "journal"
  doi: "10.1155/2015/427270"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/MasterSlaveCalibration_MPE.pdf"
  thumbnail: "/assets/publications/paper-85.png"
  tags:
    - "Master-slave System"
    - "Calibration"
    - "Fish-eye Correction"
    - "Surveillance"
  abstract: "Surveillance systems capable of autonomously monitoring vast areas are an emerging trend, particularly when wide-angle cameras are combined with pan-tilt-zoom (PTZ) cameras in a master-slave configuration. The use of fish-eye lenses allows the master camera to maximize the coverage area while the PTZ acts as a foveal sensor, providing high-resolution images of regions of interest. Despite the advantages of this architecture, the mapping between image coordinates and pan-tilt values is the major bottleneck in such systems, since it depends on depth information and fish-eye effect correction. In this paper, we address these problems by exploiting geometric cues to perform height estimation. This information is used both for inferring 3D information from a single static camera deployed on an arbitrary position and for determining lens parameters to remove fish-eye distortion. When compared with the previous approaches, our method has the following advantages: (1) fish-eye distortion is corrected without relying on calibration patterns; (2) 3D information is inferred from a single static camera disposed on an arbitrary location of the scene."

- id: "OcularBiometrics"
  title: "Ocular Biometrics by Score-Level Fusion of Disparate Experts"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Image Processing"
  year: 2014
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIP.2014.2361285"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Atomistic_TIP.pdf"
  thumbnail: "/assets/publications/paper-78.png"
  tags:
    - "Ocular Biometrics"
    - "Score-Level Fusion"
    - "Periocular Recognition"
    - "Iris Recognition"
  abstract: "The concept of periocular biometrics emerged to improve the robustness of iris recognition to degraded data. Being a relatively recent topic, most of the periocular recognition algorithms work in a holistic way, and apply a feature encoding / matching strategy without considering each biological component in the periocular area. This not only augments the correlation between the components in the resulting biometric signature, but also increases the sensitivity to particular data covariates. The main novelty in this paper is to propose a periocular recognition ensemble made of two disparate components: 1) one expert analyses the iris texture and exhaustively exploits the multi-spectral information in visible-light data; 2) another expert parameterises the shape of eyelids and defines a surrounding dimensionless region-of-interest, from where statistics of the eyelids, eyelashes and skin wrinkles / furrows are encoded. Both experts work on disjoint regions of the periocular area and meet three important properties: 1) they produce practically independent responses, which is behind the better performance of the ensemble when compared to the best individual recogniser; 2) they don't share particularly sensitivity to any image covariate, which accounts for augmenting the robustness against degraded data. Finally, it should be stressed that we disregard information in the periocular region that can be easily forged (e.g., shape of eyebrows), which constitutes an active anti-counterfeit measure. An empirical evaluation was conducted on two public data sets (FRGC and UBIRIS.v2), and points for consistent improvements in performance of the proposed ensemble over the state-of-the-art periocular recognition algorithms."

- id: "SegmentingPeriocular"
  title: "Segmenting the Periocular Region using a Hierarchical Graphical Model Fed by Texture / Shape Information and Geometrical Constraints"
  authors: "Hugo Proença, João C. Neves, Gil Santos"
  venue: "Proceedings of the International Joint Conference on Biometrics - IJCB 2014"
  year: 2014
  status: "published"
  publication_type: "conference"
  doi: "10.1109/BTAS.2014.6996228"
  pdf: "http://di.ubi.pt/~hugomcp/doc/IJCB14.pdf"
  thumbnail: "/assets/publications/paper-36.png"
  tags:
    - "Periocular Region"
    - "Segmentation"
    - "Graphical Model"
    - "Markov Random Field"
  abstract: "Using the periocular region for biometric recognition is an interesting possibility: this area of the human body is highly discriminative among subjects and relatively stable in appearance. In this paper, the main idea is that improved solutions for defining the periocular region-of-interest and better pose / gaze estimates can be obtained by segment- ing (labelling) all the components in the periocular vicinity. Accordingly, we describe an integrated algorithm for labelling the periocular region, that uses a unique model to discriminate between seven components in a single-shot: iris, sclera, eyelashes, eyebrows, hair, skin and glasses. Our solution fuses texture / shape descriptors and geometrical constraints to feed a two-layered graphical model (Markov Random Field), which energy minimization provides a robust solution against uncontrolled lighting conditions and variations in subjects pose and gaze."

- id: "LeishmaniaImages"
  title: "Detection and Separation of Overlapping Cells Based on Contour Concavity for Leishmania images"
  authors: "João C. Neves, Helena Castro, Ana Tomás, Miguel Coimbra, Hugo Proença"
  venue: "Wiley Cytometry: Part A"
  year: 2014
  status: "published"
  publication_type: "journal"
  doi: "10.1002/cyto.a.22465"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Leishmania_CytometryA.pdf"
  thumbnail: "/assets/publications/paper-75.png"
  tags:
    - "Cell Detection"
    - "Image Processing"
    - "Contour Concavity"
    - "Leishmania"
  abstract: "Life scientists often must count cells in microscopy images, which is a tedious and time-consuming task. Automatic approaches present a solution to this problem. Several procedures have been devised for this task, but the majority suffer from performance degradation in the case of cell overlap. In this article, we propose a method to deter- mine the positions of macrophages and parasites in fluorescence images of Leishmania- infected macrophages. The proposed strategy is primarily based on blob detection, clustering, and separation using concave regions of the cells' contours. In comparison with the approaches of Nogueira (Master's thesis, Department of University of Porto Computer Science, 2011) and Leal et al. (Proceedings of the 9th international conference on Image Analysis and Recognition, Vol. II, ICIAR'12. Berlin, Heidelberg: Springer-Verlag; 2012. pp. 432–439), which also addressed this type of image, we conclude that the proposed methodology achieves better performance in the automatic annotation of Leishmania infections."

- id: "FaceRecognitionHDR"
  title: "Automatic face recognition in HDR imaging"
  authors: "Manuela Pereira, Juan C. Moreno, Hugo Proença, António Pinheiro"
  venue: "Proceedings of the SPIE Photonics Europe Conference"
  year: 2014
  status: "published"
  publication_type: "conference"
  doi: "10.1117/12.2054539"
  pdf: "https://www.spiedigitallibrary.org/conference-proceedings-of-spie/9138/913804/Automatic-face-recognition-in-HDR-imaging/10.1117/12.2054539.short"
  thumbnail: "/assets/publications/paper-131.png"
  tags:
    - "Face Recognition"
    - "HDR Imaging"
    - "Tone Mapping"
    - "Privacy"
  abstract: "The gaining popularity of the new High Dynamic Range (HDR) imaging systems is raising new privacy issues caused by the methods used for visualization. HDR images require tone mapping methods for an appropriate visualization on conventional and non-expensive LDR displays. These visualization methods might result in completely different visualization raising several issues on privacy intrusion. In fact, some visualization methods result in a perceptual recognition of the individuals, while others do not even show any identity. Although perceptual recognition might be possible, a natural question that can rise is how computer based recognition will perform using tone mapping generated images? In this paper, a study where automatic face recognition using sparse representation is tested with images that result from common tone mapping operators applied to HDR images. Its ability for the face identity recognition is described. Furthermore, typical LDR images are used for the face recognition training."

- id: "DynamicCameraScheduling"
  title: "Dynamic Camera Scheduling for Visual Surveillance in Crowded Scenes using Markov Random Fields"
  authors: "João C. Neves, Hugo Proença"
  venue: "Proceedings of the 12th IEEE International Conference on Advanced Video and Signal based Surveillance - AVSS 2015"
  year: 2015
  status: "published"
  publication_type: "conference"
  doi: "10.1109/AVSS.2015.7301790"
  pdf: ""
  thumbnail: "/assets/publications/paper-38.png"
  tags:
    - "Camera Scheduling"
    - "PTZ Camera"
    - "Visual Surveillance"
    - "Markov Random Fields"
  abstract: "The use of pan-tilt-zoom (PTZ) cameras for capturing high-resolution data of human-beings is an emerging trend in surveillance systems. However, this new paradigm en- tails additional challenges, such as camera scheduling, that can dramatically affect the performance of the system. In this paper, we present a camera scheduling approach capable of determining - in real-time - the sequence of acquisitions that maximizes the number of different targets obtained, while minimizing the cumulative transition time. Our approach models the problem as an undirected graphical model (Markov random field, MRF), which energy minimization can approximate the shortest tour to visit the maximum number of targets. A comparative analysis with the state-of-the-art camera scheduling methods evidences that our approach is able to improve the observation rate while maintaining a competitive tour time."

- id: "CalibrationAlgorithm"
  title: "A Calibration Algorithm for Multi-camera Visual Surveillance Systems Based on Single-View Metrology"
  authors: "João C. Neves, Juan C. Moreno, Silvio Barra, Hugo Proença"
  venue: "Proceedings of the 7th Iberian Conference on Pattern Recognition and Image Analysis - IbPRIA 2015"
  year: 2015
  status: "published"
  publication_type: "conference"
  doi: "10.1007/978-3-319-19390-8_62"
  pdf: "http://di.ubi.pt/~hugomcp/doc/ibpria15.pdf"
  thumbnail: "/assets/publications/paper-37.png"
  tags:
    - "Camera Calibration"
    - "Visual Surveillance"
    - "Single-View Metrology"
    - "Master-slave System"
  abstract: "The growing concerns about persons security and the increasing popularity of pan-tilt-zoom (PTZ) cameras, have been raising the interest on automated master-slave surveillance systems. Such systems are typically composed by (1) a fixed wide-angle camera that covers a large area, detects and tracks moving objects in the scene; and (2) a PTZ camera, that provides a close-up view of an object of interest. Previously published approaches attempted to establish 2D correspondences between the video streams of both cameras, which is a ill-posed formulation due to the absence of depth information. On the other side, 3D-based approaches are more accurate but require more than one fixed camera to estimate depth information. In this paper, we describe a novel method for easy and precise calibration of a master-slave surveillance sys- tem, composed by a single fixed wide-angle camera. Our method exploits single view metrology to infer 3D data of the tracked humans and to self- perform the transformation between camera views. Experimental results in both simulated and realistic scenes point for the effectiveness of the proposed model in comparison with the state-of-the-art."

- id: "BioHDD"
  title: "BioHDD: A Dataset for Studying Biometric Identification on Heavily Degraded Data"
  authors: "Gil Santos, Paulo Fiadeiro, Hugo Proença"
  venue: "IET Biometrics"
  year: 2015
  status: "published"
  publication_type: "journal"
  doi: "10.1049/iet-bmt.2014.0045"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BioHDD_IET-Biom.pdf"
  thumbnail: "/assets/publications/paper-79.png"
  tags:
    - "Biometric Identification"
    - "Degraded Data"
    - "Dataset"
    - "Human Recognition"
  abstract: "Substantial efforts have been put into bridging the gap between biometrics and visual surveillance, in order to developautomata able to recognise human beings 'in the wild'. This study focuses on biometric recognition in extremely degraded data, and its main contributions are three-fold: (1) announce the availability of an annotated dataset that contains high quality mugshots of 101 subjects, and large sets of probes degraded extremely by 10 different noise factors; (2) report the results of a mimicked watchlist identification scheme: an online survey was conducted, where participants were asked to perform positive and negative identification of probes against the enrolled identities. Along with their answers, volunteers had to provide the major reasons that sustained their responses, which enabled the authors to perceive the kind of features that are most frequently associated with 30 successful/failed human identification processes. As main conclusions, the authors observed that humans rely greatly on shape information and holistic features. Otherwise, colour and texture-based features are almost disregarded by humans; (3) finally, the authors give evidence that the positive human identification on such extremely degraded data might be unreliable, whereas negative identification might constitute an interesting alternative for such cases."

- id: "RobustPeriocular"
  title: "Robust periocular recognition by fusing sparse representations of color and geometry information"
  authors: "Juan C. Moreno, V. B. Surya Prasath, Gil Santos, Hugo Proença"
  venue: "Springer Journal of Signal Processing Systems"
  year: 2015
  status: "published"
  publication_type: "journal"
  doi: "10.1007/s11265-015-1023-3"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/SparseFusion_JSPS.pdf"
  thumbnail: "/assets/publications/paper-82.png"
  tags:
    - "Periocular Recognition"
    - "Sparse Representation"
    - "Color"
    - "Geometry"
  abstract: "In this paper, we propose a re-weighted elastic net (REN) model for biometric recognition. The new model is applied to data separated into geometric and color spatial components. The geometric information is extracted using a fast cartoon - texture decomposition model based on a dual formulation of the total variation norm allowing us to carry information about the overall geometry of images. Color components are defined using linear and nonlinear color spaces, namely the red-green-blue (RGB), chromaticity- brightness (CB) and hue-saturation-value (HSV). Next, according to a Bayesian fusion-scheme, sparse representations for classification purposes are obtained. The scheme is numerically solved using a gradient projection (GP) algo- rithm. In the empirical validation of the proposed model, we have chosen the periocular region, which is an emerging trait known for its robustness against low quality data. Our results were obtained in the publicly available FRGC and UBIRIS.v2 data sets and show consistent improvements in recognition effectiveness when compared to related state- of-the-art techniques."

- id: "PeriocularExpressions"
  title: "Periocular Recognition: How Much Facial Expressions Affect Performance?"
  authors: "Elisa Barroso, Gil Santos, Luís Cardoso, Chandrashekhar Padole, Hugo Proença"
  venue: "Springer Pattern Analysis and Applications"
  year: 2015
  status: "published"
  publication_type: "journal"
  doi: "10.1007/s10044-015-0493-z"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/PeriocularExpressions_PAA.pdf"
  thumbnail: "/assets/publications/paper-83.png"
  tags:
    - "Periocular Recognition"
    - "Facial Expressions"
    - "Biometric Performance"
  abstract: "Using information near the human eye to per- form biometric recognition has been gaining popularity. Previous works in this area, designated periocular recognition, show remarkably low error rates and particularly high robustness when data are acquired under less con- trolled conditions. In this field, one factor that remains to be studied is the effect of facial expressions on recognition performance, as expressions change the textural/shape information inside the periocular region. We have collected a multisession dataset whose single variation is the subjects' facial expressions and analyzed the corresponding variations in performance, using the state-of-the-art peri- ocular recognition strategy. The effectiveness attained by different strategies to handle the effects of facial expressions was compared: (1) single-sample enrolment; (2) multisample enrolment, and (3) multisample enrolment with facial expression recognition, with results also vali- dated in the well-known Cohn–Kanade AU-Coded Expression dataset. Finally, the role of each type of facial expression in the biometrics menagerie effect is discussed."

- id: "AperiodicFeature"
  title: "Aperiodic Feature Representation for Gait Recognition in Cross-view Scenarios for Unconstrained Biometrics"
  authors: "Chandrashekhar Padole, Hugo Proença"
  venue: "Springer Pattern Analysis and Applications"
  year: 2015
  status: "published"
  publication_type: "journal"
  doi: "10.1007/s10044-015-0468-0"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Gait_PAA.pdf"
  thumbnail: "/assets/publications/paper-81.png"
  tags:
    - "Gait Recognition"
    - "Feature Representation"
    - "Cross-view Scenarios"
    - "Unconstrained Biometrics"
  abstract: "The state-of-the-art gait recognition algorithms require a gait cycle estimation before the feature extraction and are classified as periodic algorithms. Their effective- ness substantially decreases due to errors in detecting gait cycles, which are likely to occur in data acquired in non- controlled conditions. Hence, the main contributions of this paper are: (1) propose an aperiodic gait recognition strategy, where features are extracted without the concept of gait cycle, in case of multi-view scenario; (2) propose the fusion of the different feature subspaces of aperiodic feature representations at score level in cross-view scenarios. The experiments were performed with widely known CASIA Gait database B, which enabled us to draw the following major conclusions, (1) for multi-view scenarios, features extracted from gait sequences of varying length have as much discriminating power as traditional periodic features; (2) for cross-view scenarios, we observed an average improvement of 22 % over the error rates of state-of- the-art algorithms, due to the proposed fusion scheme."

- id: "HumanRecognitionUnconstrained"
  title: "Human Recognition in Unconstrained Environments Using Computer Vision, Pattern Recognition and Machine Learning Methods for Biometrics"
  authors: "Maria De Marsico, Michele Nappi, Hugo Proença"
  venue: "Springer-Verlag book series, Communications Engineering/ Computer Vision"
  year: 2016
  status: "published"
  publication_type: "book"
  isbn: "978-0-08-100705-1"
  thumbnail: "/assets/publications/paper-128.png"
  tags:
    - "Human Recognition"
    - "Unconstrained Environments"
    - "Biometrics"
    - "Computer Vision"
  abstract: ""

- id: "BackgroundSubtraction"
  title: "Evaluation of Background Subtraction Algorithms for Human Visual Surveillance"
  authors: "João C. Neves, Kamila Wysoczanska, Hugo Proença"
  venue: "Proceedings of the International Conference on Signal and Image Processing Applications – ICSIPA 2015"
  year: 2015
  status: "published"
  publication_type: "conference"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ICSIPA15.pdf"
  thumbnail: "/assets/publications/paper-41.png"
  tags:
    - "Background Subtraction"
    - "Visual Surveillance"
    - "Human Detection"
  abstract: "The fully automated surveillance of human beings remains an open problem, particularly for in-the-wild scenarios, i.e., for complex backgrounds and under uncontrolled lighting conditions. Background Subtraction (BGS) is typically the first phase of the processing chain of such type of systems and holds the feasibility of all the subsequent phases. Hence, it is particularly important to perceive the relative effectiveness of BGS, with respect to the kind of environment. This paper gives an objective evaluation of the state-of-the-art BGS algorithms on unconstrained outdoor environments. When compared to similar published works, the major novelties are two-fold: 1) the focus is put on scenes populated by human beings; and 2) an objective measure of the wildness of environments is proposed, that strongly correlates to BGS performance, and enables to perceive the algorithms' robustness with respect to the environment complexity. As main conclusions, we observed that the SOBS algorithm outperforms the remaining methods. Nevertheless, its performance leads to conclude that BGS in unconstrained environments is still an open problem."

- id: "IrisBitFragility"
  title: "Iris Recognition: What's Beyond Bit Fragility?"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2015
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2014.2371691"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BitFragility.pdf"
  thumbnail: "/assets/publications/paper-80.png"
  tags:
    - "Iris Recognition"
    - "Bit Fragility"
    - "Bit Discriminability"
    - "Multi-spectral Data"
  abstract: "The concept of fragility of some bits in the iris codes regards exclusively their within-class variation, i.e., the probability that they take different values in templates computed from different images of the same iris. This paper extends that concept, by noticing that a similar phenomenon occurs for the between-classes comparisons, i.e., some bits have higher probability than others of assuming a predominant value, which was observed for near-infrared and (in a more evident way) for visible wavelength data. Accordingly, we propose a new measure (bit discriminability) that takes into account both the within-class and between-classes variabilities, and has roots in the Fisher discriminant. Based on the bit discriminability, we compare the usefulness of the different regions of the iris for biometric recognition, with respect to multi-spectral data and to different filters parameterizations. Finally, we measure the amount of information lost in codes quantization, which gives insight to further research on iris matching strategies that consider both phase and magnitude. Albeit augmenting the computational burden of recognition, such kind of strategies will consistently improve performance, particularly in poor-quality data."

- id: "HighResFacesOutdoor"
  title: "Acquiring High-resolution Face Images in Outdoor Environments: A master-slave Calibration Algorithm"
  authors: "João C. Neves, Juan C. Moreno, Silvio Barra, Hugo Proença"
  venue: "Proceedings of the IEEE Seventh International Conference on Biometrics: Theory, Applications and Systems – BTAS 2015"
  year: 2015
  status: "published"
  publication_type: "conference"
  doi: "10.1109/BTAS.2015.7358744"
  pdf: ""
  thumbnail: "/assets/publications/paper-39.png"
  tags:
    - "Face Recognition"
    - "Surveillance"
    - "PTZ Camera"
    - "Master-slave Calibration"
  abstract: "Facial recognition at-a-distance in surveillance scenarios remains an open problem, particularly due to the small number of pixels representing the facial region. The use of pan-tilt-zoom (PTZ) cameras has been advocated to solve this problem, however, the existing approaches either rely on rough approximations or additional constraints to estimate the mapping between image coordinates and pan-tilt parameters. In this paper, we aim at extending PTZ-assisted facial recognition to surveillance scenarios by proposing a master-slave calibration algorithm capable of accurately estimating pan-tilt parameters without depending on additional constraints. Our approach exploits geometric cues to automatically estimate subjects height and thus determine their 3D position. Experimental results show that the presented algorithm is able to acquire high-resolution face im- ages at a distance ranging from 5 to 40 meters with high success rate. Additionally, we certify the applicability of the aforementioned algorithm to biometric recognition through a face recognition test, comprising 20 probe subjects and 13,020 gallery subjects."

- id: "QuisCampi"
  title: "Quis-Campi: Extending In The Wild Biometric Recognition to Surveillance Environments"
  authors: "Gil Santos, João C. Neves, Sílvio Filipe, Emanuel Grancho, Silvio Barra, Fabio Narducci, Hugo Proença"
  venue: "Proceedings of the 18th International Conference on Image Analysis and Processing - ICIAP 2015"
  year: 2015
  status: "published"
  publication_type: "conference"
  doi: "10.1007/978-3-319-23222-5_8"
  pdf: "http://di.ubi.pt/~hugomcp/doc/ICIAP15.pdf"
  thumbnail: "/assets/publications/paper-40.png"
  tags:
    - "Biometric Recognition"
    - "Surveillance"
    - "In-the-Wild"
    - "Human Detection"
    - "Tracking"
  abstract: "Efforts in biometrics are being held into extending robust recognition techniques to in the wild scenarios. Nonetheless, and despite being a very attractive goal, human identification in the surveillance con- text remains an open problem. In this paper, we introduce a novel bio- metric system – Quis-Campi – that effectively bridges the gap between surveillance and biometric recognition while having a minimum amount of operational restrictions. We propose a fully automated surveillance sys- tem for human recognition purposes, attained by combining human detection and tracking, further enhanced by a PTZ camera that delivers data with enough quality to perform biometric recognition. Along with the system concept, implementation details for both hardware and software modules are provided, as well as preliminary results over a real scenario."

- id: "BiometricSurveillanceSurvey"
  title: "Biometric Recognition in Surveillance Scenarios: A Survey"
  authors: "João C. Neves, Hugo Proença"
  venue: "Springer Artificial Intelligence Review"
  year: 2016
  status: "published"
  publication_type: "journal"
  doi: "10.1007/s10462-016-9474-x"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BiometricsSurveillance_Survey.pdf"
  thumbnail: "/assets/publications/paper-87.png"
  tags:
    - "Biometric Recognition"
    - "Surveillance"
    - "Survey"
    - "Unconstrained Environments"
  abstract: "Interest in the security of individuals has increased in recent years. This increase has in turn led to much wider deployment of surveillance cameras worldwide, and consequently, automated surveillance systems research has received more attention from the scientific community than before. Concurrently, biometrics research has become more popular as well, and it is supported by the increasing number of approaches devised to address specific degradation factors of unconstrained environments. Despite these recent efforts, no automated surveillance system that performs reliable biometric recognition in such an environment has become available. Nevertheless, recent developments in human motion analysis and biometric recognition suggest that both can be combined to develop a fully automated system. As such, this paper reviews recent advances in both areas, with a special focus on surveillance scenarios. When compared to previous studies, we highlight two distinct features, i.e., (1) our emphasis is on approaches that are devised to work in unconstrained environments and surveillance scenarios; and (2) biometric recognition is the final goal of the surveillance system, as opposed to behavior analysis, anomaly detection or action recognition."

- id: "IrisVisibleWavelengths"
  title: "Iris Recognition in Visible Wavelengths and Unconstrained Conditions."
  authors: "Hugo Proença"
  venue: "Handbook of Iris Recognition (2nd edition)"
  year: 2016
  status: "published"
  publication_type: "book_chapter"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Hand_1.pdf"
  thumbnail: "/assets/publications/paper-5.png"
  tags:
    - "Iris Recognition"
    - "Visible Wavelength"
    - "Unconstrained Conditions"
    - "Periocular Recognition"
  abstract: "One of the most challenging goals in biometrics research is the development of recognition systems to work in unconstrained environments and without assuming the subjects' willingness to be recognised. This has led to the concept of non-cooperative recognition, which broaden the application of biometrics to forensics / criminal seek domains. In this scope, one active research topic seeks to use as main trait the ocular region acquired at visible wavelengths, from moving targets and large distances. Under these conditions, performing reliable recognition is extremely difficult, because such real-world data have features that are notoriously different from those obtained in the classical constrained setups of currently deployed recognition systems. This chapter discusses the feasibility of iris / ocular biometric recognition: it starts by comparing the main properties of near-infrared and visible wavelength ocular data, and stresses the main difficulties behind the ac- curate segmentation of all components in the eye vicinity. Next, it summarises the most relevant research conducted in the scope of visible wavelength iris recognition and relates it to the concept of periocular recognition, which is an attempt to augment classes separability by using - apart from the iris - information from the surroundings of the eye. Finally, the current challenges in this topic and some directions for further research are discussed."

- id: "IrisBiometricIndexing"
  title: "Iris Biometric Indexing"
  authors: "Hugo Proença, João C. Neves"
  venue: "Iris and Periocular Biometric Recognition"
  year: 2016
  status: "published"
  publication_type: "book_chapter"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BC_II.pdf"
  thumbnail: "/assets/publications/paper-6.png"
  tags:
    - "Iris Recognition"
    - "Biometric Indexing"
    - "Retrieval"
  abstract: "Indexing / retrieving sets of iris biometric signatures has been a topic of increasing popularity, mostly due to the deployment of iris recognition systems in nationwide scale scenarios. In these conditions, for each identification attempt, there might exist hundreds of millions of enrolled identities and is unrealistic to match the probe against all gallery elements in a reasonable amount of time. Hence, the idea of indexing / retrieval is - upon receiving one sample - to find in a quick way a sub-set of elements in the database that most probably contains the identity of interest, i.e., the one corresponding to the probe. Most of the state-of-the-art strategies to index iris biometric signatures were devised to decision environments with a clear separation between genuine and impostor matching scores. However, if iris recognition systems work in low quality data, the resulting decision environments are poorly separable, with a significant overlap between the distributions of both matching scores. This chapter summarises the state-of-the-art in terms of iris bio- metric indexing / retrieval and focuses in an indexing / retrieval method for such low quality data and operates at the code level, i.e., after the signature encoding process. Gallery codes are decomposed at multiple scales, and using the most reliable components of each scale, their position in a n-ary tree is determined. During retrieval, the probe is decomposed similarly, and the distances to multi-scale centroids are used to penalize paths in the tree. At the end, only a subset of branches is traversed up to the last level."

- id: "VisibleWavelengthIrisPeriocular"
  title: "Visible-wavelength Iris/Periocular Imaging and Recognition in Surveillance Environments"
  authors: "Hugo Proença, João C. Neves"
  venue: "Elsevier Image and Vision Computing"
  year: 2016
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.imavis.2016.03.015"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/PeriocularImagingSurveillance.pdf"
  thumbnail: "/assets/publications/paper-88.png"
  tags:
    - "Visual Surveillance"
    - "Iris Recognition"
    - "Periocular Recognition"
    - "Visible Wavelength"
  abstract: "Visual surveillance cameras have been massively deployed in public urban environments over the recent years, as a crime prevention and law enforcement solution. This fact raised the interest in developing automata to infer useful information from such crowded scenes (from abnormal behavior detection to human identification). In order to cover wide outdoor areas, one interesting possibility is to combine wide- angle and pan–tilt–zoom (PTZ) cameras in a master–slave configuration. The use of fish-eye lenses allows the master camera to maximize the coverage area while the PTZ acts as a foveal sensor, providing high- resolution images of the interest regions. This paper addresses the feasibility of using this type of data acquisition paradigm for imaging iris/periocular data with enough discriminating power to be used for biometric recognition purposes."

- id: "BiometricInTheWild"
  title: "Biometric Recognition in-the-Wild"
  authors: "Hugo Proença, Mark Nixon, Michele Nappi"
  venue: "IEEE Intelligent Systems, Trends and Controversies"
  year: 2016
  status: "published"
  publication_type: "special_issue"
  thumbnail: "/assets/publications/paper-121.png"
  tags:
    - "Biometric Recognition"
    - "In-the-Wild"
    - "Unconstrained Environments"

- id: "FusingVantagePoint"
  title: "Fusing Vantage Point Trees and Linear Discriminants for Fast Feature Classification"
  authors: "Hugo Proença, João C. Neves"
  venue: "Springer Journal of Classification"
  year: 2017
  status: "published"
  publication_type: "journal"
  doi: "10.1007/s00357-017-9223-0"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/VPC.pdf"
  thumbnail: "/assets/publications/paper-84.png"
  tags:
    - "Classification"
    - "Nearest Neighbor"
    - "Linear Discriminant"
    - "Vantage-Point trees"
  abstract: "This paper describes a classification strategy that can be regarded as a more general form of nearest-neighbor classification. It fuses the concepts of nearest neighbor, linear discriminant and Vantage-Point trees, yielding an efficient indexing data structure and classification algorithm. In the learning phase, we define a set of disjoint subspaces of reduced complexity that can be separated by linear discriminants, ending up with an ensemble of simple (weak) classifiers that work locally. In classification, the closest centroids to the query determine the set of classifiers considered, which responses are weighted. The algorithm was experimentally validated in datasets widely used in the field, attaining error rates that are favourably compara- ble to the state-of-the-art classification techniques. Lastly, the proposed solution has a set of interesting properties for a broad range of applications: 1) it is deterministic; 2) it classifies in time approximately logarithmic with respect to the size of the learning set, being far more efficient than nearest neighbor classification in terms of computational cost; and 3) it keeps the generalization ability of simple models."

- id: "MicheII"
  title: "Results from MICHE II - Mobile Iris CHallenge Evaluation II."
  authors: "Maria De Marsico, Michele Nappi, Hugo Proença"
  venue: "Elsevier Pattern Recognition Letters"
  year: 2017
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.patrec.2016.12.013"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ResultsMICHE2.pdf"
  thumbnail: "/assets/publications/paper-90.png"
  tags:
    - "Mobile Biometrics"
    - "Iris Recognition"
    - "MICHE"
  abstract: "Mobile biometrics represent the new frontier of authentication. The most appealing feature of mobile devices is the wide availability and the presence of more and more reliable sensors for capturing bio- metric traits, e.g., cameras and accelerometers. Moreover, they more and more often store personal and sensitive data, that need to be protected. Doing this on the same device using biometrics to enforce secu- rity seems a natural solution. This makes this research topic attracting and generally promising. However, the growing interest for related applications is counterbalanced by still present limitations, especially for some traits. Acquisition and computation resources are nowadays widely available, but they are not al- ways sufficient to allow a reliable recognition result. Most of all, the way capture is expected to be carried out, i.e., by the user him/herself in uncontrolled conditions and without an expert assistance, can heavily affect the quality of samples and, as a consequence, the accuracy of recognition. Among the biometric traits raising the interest of researchers, iris plays an important role. Mobile Iris CHallenge Evaluation II (MICHE II) competition provided a testbed to assess the progress of mobile iris recognition, as well as its limitations still to overcome. This paper presents the results of the competition and the analysis of achieved performance, that takes into account both proposals submitted for the competition section launched at the 2016 edition of the International Conference on Pattern Recognition (ICPR), as well as proposals submitted for this special issue."

- id: "MicheIICPR"
  title: "Mobile Iris CHallenge Evaluation II: results from the ICPR competition"
  authors: "Modesto Castrillon, Maria De Marsico, Michele Nappi, Fabio Narducci, Hugo Proença"
  venue: "Proceedings of the International Conference on Pattern Recognition – ICPR 2016"
  year: 2016
  status: "published"
  publication_type: "conference"
  doi: "10.1109/ICPR.2016.7899624"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/icpr2016.pdf"
  thumbnail: "/assets/publications/paper-43.png"
  tags:
    - "Mobile Biometrics"
    - "Iris Recognition"
    - "MICHE"
  abstract: "The growing interest for mobile biometrics stems from the increasing need to secure personal data and services, which are often stored or accessed from there. Modern user mobile devices, with acquisition and computation resources to support related operations, are nowadays widely available. This makes this research topic very attracting and promising. Iris recognition plays a major role in this scenario. However, mo- bile biometrics still suffer from some hindering fac- tors. The resolution of captured images and the computational power are not comparable to desktop systems yet. Furthermore, the acquisition setting is generally uncontrolled, with users who are not that expert to autonomously generate biometric samples of sufficient quality. Mobile Iris CHallenge Evaluation aims at providing a testbed to assess the progress of mobile iris recognition, and to evaluate the extent of its present limitations. This paper presents the results of the competition launched at the 2016 edition of the International Conference on Pattern Recognition (ICPR)."

- id: "JointHeadPose"
  title: "Joint Head Pose/Soft Label Estimation for Human Recognition In-The-Wild"
  authors: "Hugo Proença, João C. Neves, Silvio Barra, Tiago Marques, Juan C. Moreno"
  venue: "IEEE Transactions on Pattern Analysis and Machine Intelligence"
  year: 2016
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TPAMI.2016.2522441"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/SoftBiometrics.pdf"
  thumbnail: "/assets/publications/paper-86.png"
  tags:
    - "Soft Biometrics"
    - "Head Pose Estimation"
    - "Human Recognition"
    - "In-the-Wild"
  abstract: "Soft biometrics have been emerging to complement other traits and are particularly useful for poor quality data. In this paper, we propose an efficient algorithm to estimate human head poses and to infer soft biometric labels based on the 3D morphology of the human head. Starting by considering a set of pose hypotheses, we use a learning set of head shapes synthesized from anthropometric surveys to derive a set of 3D head centroids that constitutes a metric space. Next, representing queries by sets of 2D head landmarks, we use projective geometry techniques to rank efficiently the joint 3D head centroids / pose hypotheses according to their likelihood of matching each query. The rationale is that the most likely hypotheses are sufficiently close to the query, so a good solution can be found by convex energy minimization techniques. Once a solution has been found, the 3D head centroid and the query are assumed to have similar morphology, yielding the soft label. Our experiments point toward the usefulness of the proposed solution, which can improve the effectiveness of face recognizers and can also be used as a privacy-preserving solution for biometric recognition in public environments."

- id: "ICB-RW"
  title: "ICB-RW 2016: International Challenge on Biometric Recognition in the Wild"
  authors: "João C. Neves, Hugo Proença"
  venue: "Proceedings of the 9th IAPR International Conference on Biometrics - ICB 2016"
  year: 2016
  status: "published"
  publication_type: "conference"
  doi: "10.1109/ICB.2016.7550066"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ICB16.pdf"
  thumbnail: "/assets/publications/paper-42.png"
  tags:
    - "Biometric Recognition"
    - "Wild Conditions"
    - "Surveillance"
  abstract: "Biometric recognition in totally wild conditions, such as the observed in visual surveillance scenarios has not been achieved yet. The ICB-RW competition was promoted to support this endeavor, being the first biometric challenge carried out in data that realistically result from surveillance scenarios. The competition relied on an innovative master- slave surveillance system for the acquisition of face imagery at-a-distance and on-the-move. This paper describes the competition details and reports the performance achieved by the participants algorithms."

- id: "SoftBiometricsHair"
  title: "Soft Biometrics: Globally Coherent Solutions for Hair Segmentation and Style Recognition based on Hierarchical MRFs"
  authors: "Hugo Proença, João C. Neves"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2017
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2017.2680246"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/HairAnalysis_TIFS.pdf"
  thumbnail: "/assets/publications/tifs.jpg"
  tags:
    - "Soft Biometrics"
    - "Hair Segmentation"
    - "Hair Style Recognition"
    - "Markov Random Fields"
  abstract: "Markov Random Fields (MRFs) are a popular tool in many computer vision problems and faithfully model a broad range of local dependencies. However, rooted in the Hammersley-Clifford theorem, they face serious difficulties in enforcing the global coherence of the solutions without using too high order cliques that reduce the computational effectiveness of the inference phase. Having this problem in mind, we describe a multi-layered (hierarchical) architecture for MRFs that is based exclusively in pairwise connections and typically produces globally coherent solutions, with 1) one layer working at the local (pixel) level, modelling the interactions between adjacent image patches; and 2) a complementary layer working at the object (hypothesis) level pushing toward globally consistent solutions. During optimization, both layers interact into an equilibrium state, that not only segments the data, but also classifies it. The proposed MRF architecture is particularly suitable for problems that deal with biological data (e.g., biometrics), where the reasonability of the solutions can be objectively measured. As test case, we considered the problem of hair / facial hair segmentation and labelling, which are soft biometric labels useful for human recognition in-the-wild. We observed performance levels close to the state-of-the-art at a much lower computational cost, both in the segmentation and classification (labelling) tasks."

- id: "MICHEInsights"
  title: "Insights into the results of MICHE I - Mobile Iris CHallenge Evaluation"
  authors: "Maria De Marsico, Michele Nappi, Fabio Narducci, Hugo Proença"
  venue: "Elsevier Pattern Recognition"
  year: 2017
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.patcog.2017.08.028"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/MICHEInsights.pdf"
  thumbnail: "/assets/publications/prl.jpg"
  tags:
    - "Iris Recognition"
    - "Mobile Biometrics"
    - "Challenge Evaluation"
    - "Performance Analysis"
  abstract: "Mobile biometrics technologies are nowadays the new frontier for secure use of data and services, and are considered particularly important due to the massive use of handheld devices in the entire world. Among the biometric traits with potential to be used in mobile settings, the iris/ocular region is a natural candidate, even considering that further advances in the technology are required to meet the operational requirements of such ambitious environments. Aiming at promoting these advances, we organized the Mobile Iris Challenge Evaluation (MICHE)-I contest. This paper presents a comparison of the performance of the participant methods by various Figures of Merit (FoMs). A particular attention is devoted to the identification of the image covariates that are likely to cause a decrease in the performance levels of the compared algorithms. Among these factors, interoperability among different devices plays an important role. The methods (or parts of them) implemented by the analyzed approaches are classified into segmentation (S), which was the main target of MICHE-I, and recognition (R). The paper reports both the results observed for either S or R, and also for different recombinations (S+R) of such methods. Last but not least, we also present the results obtained by multi-classifier strategies."

- id: "IRINA"
  title: "IRINA: Iris Recognition (even) in Innacurately Segmented Data"
  authors: "Hugo Proença, João C. Neves"
  venue: "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition - CVPR 2017"
  year: 2017
  status: "published"
  publication_type: "conference"
  doi: "10.1109/CVPR.2017.714"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/CVPR2017.pdf"
  thumbnail: "/assets/publications/cvf.jpg"
  tags:
    - "Iris Recognition"
    - "Segmentation Robustness"
    - "Biometrics"
    - "Image Registration"
  abstract: "The effectiveness of current iris recognition systems depends on the accurate segmentation and parameterisation of the iris boundaries, as failures at this point misalign the coefficients of the biometric signatures. This paper describes IRINA, an algorithm for Iris Recognition that is robust against INAccurately segmented samples, which makes it a good candidate to work in poor-quality data. The process is based in the concept of 'corresponding' patch between pairs of images, that is used to estimate the posterior probabilities that patches regard the same biological region, even in case of segmentation errors and non-linear texture deformations. Such information enables to infer a free-form deformation field (2D registration vectors) between images, whose first and second-order statistics provide effective biometric discriminating power. Extensive experiments were carried out in four datasets (CASIA-IrisV3-Lamp, CASIA-IrisV4-Lamp, CASIA-IrisV4-Thousand and WVU) and show that IRINA not only achieves state-of-the-art performance in good quality data, but also handles effectively severe segmentation errors and large differences in pupillary dilation / constriction."

- id: "QUISCAMPI"
  title: "QUIS-CAMPI: An Annotated Multi-biometrics Data Feed From Surveillance Scenarios"
  authors: "João C. Neves, Juan C. Moreno, Hugo Proença"
  venue: "IET Biometrics"
  year: 2017
  status: "published"
  publication_type: "journal"
  doi: "10.1049/iet-bmt.2016.0178"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/QUISCAMPI_IET.pdf"
  thumbnail: "/assets/publications/ietbiometrics.jpg"
  tags:
    - "Multi-biometrics"
    - "Surveillance"
    - "Data Feed"
    - "Outdoor Recognition"
  abstract: "The accuracy of biometric recognition in unconstrained scenarios has been a major concern for a large number of researchers. Despite such efforts, no system can recognize in a fully automated manner human beings in totally wild conditions, such as in surveillance environments. In this context, several sets of degraded data have been made available to the research community, where the reported performance by state-of-the-art algorithms is already saturated, suggesting that these sets do not reflect faithfully the conditions in such hard settings. To this end, we introduce the QUIS-CAMPI data feed, comprising samples automatically acquired by an outdoor visual surveillance system, with subjects on-the-move and at-a-distance (up to 50 m). Also, we supply a high-quality set of enrollment data. When compared to similar data sources, the major novelties of QUIS-CAMPI are: 1) biometric samples are acquired in a fully automatic way; 2) it is an open dataset, i.e., the number of probe images and enrolled subjects grow on a daily basis; and 3) it contains multi-biometric traits. The ensemble properties of QUIS-CAMPI ensure that the data span a representative set of covariate factors of real-world scenarios, making it a valuable tool for developing and benchmarking biometric recognition algorithms capable of working in unconstrained scenarios."

- id: "ExploitingDataRedundancy"
  title: "Exploiting Data Redundancy for Error Detection in Degraded Biometric Signatures Resulting From in the Wild Environments"
  authors: "João C. Neves, Hugo Proença"
  venue: "Proceedings of the 2nd International Workshop on Biometrics in the Wild, 12th IEEE Conference on Automatic Face and Gesture Recognition – FG 2017"
  year: 2017
  status: "published"
  publication_type: "conference"
  doi: "10.1109/FG.2017.122"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/fg2017.pdf"
  thumbnail: "/assets/publications/ieeexplore.jpg"
  tags:
    - "Error Detection"
    - "Biometric Signatures"
    - "Markov Random Field"
    - "Feature Correlation"
  abstract: "An error-correcting code (ECC) is a process of adding redundant data to a message, such that it can be recovered by a receiver even if a number of errors are introduced in transmission. Inspired by the principles of ECC, we introduce a method capable of detecting degraded features in biometric signatures by exploiting feature correlation. The main novelty is that, unlike existing biometric cryptosystems, the proposed method works directly on the biometric signature. Our approach performs a redundancy analysis of non-degraded data to build an undirected graphical model (Markov Random Field), whose energy minimization determines the sequence of degraded components of the biometric sample. Experiments carried out in different biometric traits ascertain the improvements attained when disregarding degraded features during the matching phase. Also, we stress that the proposed method is general enough to work in different classification methods, such as CNNs."

- id: "DeepPRWIS"
  title: "Deep-PRWIS: Periocular Recognition Without the Iris and Sclera Using Deep Learning Frameworks"
  authors: "Hugo Proença, João C. Neves"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2018
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2017.2771230"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Deep-PRWIS.pdf"
  thumbnail: "/assets/publications/tifs.jpg"
  tags:
    - "Periocular Recognition"
    - "Deep Learning"
    - "Data Augmentation"
    - "Biometrics"
  abstract: "This work is based on a disruptive hypothesis for periocular biometrics: in visible-light data, the recognition performance is optimized when the components inside the ocular globe (the iris and the sclera) are simply discarded, and the recogniser's response is exclusively based in information from the surroundings of the eye. As major novelty, we describe a processing chain based on convolution neural networks (CNNs) that defines the regions-of-interest in the input data that should be privileged in an implicit way, i.e., without masking out any areas in the learning/test samples. By using an ocular segmentation algorithm exclusively in the learning data, we separate the ocular from the periocular parts. Then, we produce a large set of 'multi-class' artificial samples, by interchanging the periocular and ocular parts from different subjects. These samples are used for data augmentation purposes and feed the learning phase of the CNN, always considering as label the ID of the periocular part. This way, for every periocular region, the CNN receives multiple samples of different ocular classes, forcing it to conclude that such regions should not be considered in its response. During the test phase, samples are provided without any segmentation mask and the network naturally disregards the ocular components, which contributes for improvements in performance. Our experiments were carried out in full versions of two widely known data sets (UBIRIS.v2 and FRGC) and show that the proposed method consistently advances the state-of-the-art performance in the closed-world setting, reducing the EERs in about 82% (UBIRIS.v2) and 85% (FRGC) and improving the Rank-1 over 41% (UBIRIS.v2) and 12% (FRGC)."

- id: "IEEEIntelligentSystems"
  title: "IEEE Intelligent Systems: Trends and Controversies"
  authors: "Hugo Proença, Mark Nixon, Michele Nappi"
  venue: "IEEE Intelligent Systems"
  year: 2018
  status: "published"
  publication_type: "journal"
  doi: "10.1109/MIS.2018.033001416"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/mex201803.issue.pdf"
  thumbnail: "/assets/publications/is.jpg"
  tags:
    - "Biometric Recognition"
    - "Surveillance"
    - "Trends and Controversies"
    - "Special Issue"
  abstract: "Performing covert biometric recognition in surveillance environments has been regarded as a 'grand' challenge, considering the adversity of the conditions where recognition should be carried out (e.g., poor resolution, bad lighting, off-pose and partially occluded data). This special issue compiles a group of approaches to this problem."

- id: "OcularBiometricDatasets"
  title: "Experiments with Ocular Biometric Datasets: A Practitioner's Guideline"
  authors: "Zahid Akhtar, Gautam Kumar, Sambit Bakshi, Hugo Proença"
  venue: "IT Professional"
  year: 2018
  status: "published"
  publication_type: "journal"
  doi: "10.1109/MITP.2018.032501748"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ITProfessional_Akhtar.pdf" 
  thumbnail: "/assets/publications/itprofessional.jpg"
  tags:
    - "Ocular Biometrics"
    - "Databases"
    - "Guidelines"
    - "Experimental Protocols"
  abstract: "Ocular biometrics is the imaging and use of features extracted from the eyes regions for personal recognition. Ocular biometrics is a promising research field owing to factors such as recognition at a distance and suitability for recognition with regular RGB cameras, especially in visible spectrum on mobile devices. To ensure that ocular biometric academic researches have a positive impact on future technological developments, this paper provides a review of ocular databases available in literature, diversities among these databases, design and parameters consideration issues during acquisition of database and selection of appropriate database for experimentation. Open issues and future research directions are also discussed to identify the path forward."

- id: "LeopardCannotChange"
  title: "\"A Leopard Cannot Change Its Spots\": Improving Face Recognition Using 3D-based Caricatures"
  authors: "João C. Neves, Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2018
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2018.2846617"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Leopard_TIFS.pdf"
  thumbnail: "/assets/publications/tifs.jpg"
  tags:
    - "Face Recognition"
    - "3D Caricatures"
    - "Deep Learning"
    - "Biometrics"
  abstract: "Caricatures refer to a representation of a person in which the distinctive features are deliberately exaggerated, with several studies showing that humans perform better at recognizing people from caricatures than using original images. Inspired by this observation, this paper introduces the first fully automated caricature-based face recognition approach capable of working with data acquired in the wild. Our approach leverages the 3D face structure from a single 2D image and compares it to a reference model for obtaining a compact representation of face features deviations. This descriptor is subsequently deformed using a 'measure locally, weight globally' strategy to resemble the caricature drawing process. The deformed deviations are incorporated in the 3D model using the Laplacian mesh deformation algorithm, and the 2D face caricature image is obtained by projecting the deformed model in the original camera-view. To demonstrate the advantages of caricature-based face recognition, we train the VGG-Face network from scratch using either original face images (baseline) or caricatured images, and use these models for extracting face descriptors from the LFW, IJB-A and MegaFace datasets. The experiments show an increase in the recognition accuracy when using caricatures rather than original images. Moreover, our approach achieves competitive results with state-of-the-art face recognition methods, even without explicitly tuning the network for any of the evaluation sets."

- id: "VisualSurveillanceBiometrics2"
  title: "Visual Surveillance and Biometrics: Practices, Challenges, and Possibilities"
  authors: "Sambit Bakshi, Guodong Guo, Hugo Proença, Massimo Tistarelli"
  venue: "IEEE Access"
  year: 2018
  status: "published"
  publication_type: "special issue"
  tags:
    - "Visual Surveillance"
    - "Biometrics"
    - "Special Issue"
    - "Challenges"

- id: "Mastermind"
  title: "A Reminiscence of \"Mastermind\": Iris/Periocular Biometrics by \"In-Set\" CNN Iterative Analysis"
  authors: "Hugo Proença, João C. Neves"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2019
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2018.2883853"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Mastermind_TIFS.pdf"
  thumbnail: "/assets/publications/tifs.jpg"
  tags:
    - "Iris Recognition"
    - "Periocular Biometrics"
    - "Convolutional Neural Networks"
    - "Iterative Analysis"
  abstract: "Convolutional neural networks (CNNs) have emerged as the most popular classification models in biometrics research. Under the discriminative paradigm of pattern recognition, CNNs are used typically in one of two ways: 1) verification mode ('are samples from the same person?'), where pairs of images are provided to the network to distinguish between genuine and impostor instances; and 2) identification mode ('whom is this sample from?'), where appropriate feature representations that map images to identities are found. This paper postulates a novel mode for using CNNs in biometric identification, by learning models that answer to the question 'is the query's identity among this set?'. The insight is a reminiscence of the classical Mastermind game: by iteratively analysing the network responses when multiple random samples of k gallery elements are compared to the query, we obtain weakly correlated matching scores that - altogether - provide solid cues to infer the most likely identity. In this setting, identification is regarded as a variable selection and regularization problem, with sparse linear regression techniques being used to infer the matching probability with respect to each gallery identity. As main strength, this strategy is highly robust to outlier matching scores, which are known to be a primary error source in biometric recognition."

- id: "CrossSpectralOcular"
  title: "Deep representations for cross-spectral ocular biometrics"
  authors: "Luiz A. Zanlorensi, Diego R. Lucio, Alceu S. Britto Jr., Hugo Proença, David Menotti"
  venue: "IET Biometrics"
  year: 2019
  status: "published"
  publication_type: "journal"
  doi: "10.1049/iet-bmt.2019.0116"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Deep_IET.pdf"
  thumbnail: "/assets/publications/ietbiometrics.jpg"
  tags:
    - "Cross-spectral Biometrics"
    - "Ocular Recognition"
    - "Deep Learning"
    - "Convolutional Neural Networks"
  abstract: "One of the major challenges in ocular biometrics is the cross-spectral scenario, i.e., how to match images acquired in different wavelengths (typically visible (VIS) against near-infrared (NIR)). This article designs and extensively evaluates cross-spectral ocular verification methods, for both the closed and open-world settings, using well known deep learning representations based on the iris and periocular regions. Using as inputs the bounding boxes of non-normalized iris/periocular regions, we fine-tune Convolutional Neural Network (CNN) models (based either on VGG16 or ResNet-50 architectures), originally trained for face recognition. Based on the experiments carried out in two publicly available cross-spectral ocular databases, we report results for intra-spectral and cross-spectral scenarios, with the best performance being observed when fusing ResNet-50 deep representations from both the periocular and iris regions. When compared to the state-of-the-art, we observed that the proposed solution consistently reduces the Equal Error Rate (EER) values by 90% / 93% / 96% and 61% / 77% / 83% on the cross-spectral scenario and in the PolyU Bi-spectral and Cross-eye-cross-spectral datasets."

- id: "MICHECompetitions"
  title: "MICHE competitions: a realistic experience with uncontrolled eye region acquisition"
  authors: "Silvio Barra, Maria De Marsico, Hugo Proença, Michele Nappi"
  venue: "Selfie Biometrics, Springer Verlag book series"
  year: 2019
  status: "published"
  publication_type: "book chapter"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BC_MICHE.pdf"
  tags:
    - "MICHE Competition"
    - "Eye Region Acquisition"
    - "Uncontrolled Environments"
    - "Mobile Biometrics"
  abstract: "Any user in the world that has to access a protected service or location, or that simply wants to protect its owned devices, has to struggle with assuring a secure access to them. This is a first aspect that characterizes self-handled authentication strategies. Actually, the use of special signs, objects or passphrases goes back to the very origins of human communities. Watchwords asked by sentinels, or the 5-pointed pentagon tattooed on the palm of members of the Pythagorean school are examples of a kind of authentication often seen in the literature. The first attempt to use computer support for authentication is represented by passwords, that first appeared at the Massachusetts Institute of Technology in the mid-1960s, where a massive compatible time-sharing computer (CTSS) was used to pioneer many of the milestones of computing, including password-based authentication. In those times, a single password was sufficient to access one's virtual space and files, which afterall were the only resources to protect. Afterwards and beyond any forecasting, computers massively entered every-day life, with Internet allowing the creation of an increasing number of remote services of various kinds."

- id: "NovelInsightsOcular"
  title: "Novel Insights on Ocular Biometrics"
  authors: "Sambit Bakshi, Abhijit Das, Maria De Marsico, Hugo Proença"
  venue: "Elsevier Image and Vision Computing"
  year: 2019
  status: "published"
  publication_type: "special issue"
  tags:
    - "Ocular Biometrics"
    - "Iris Recognition"
    - "Periocular Recognition"
    - "Special Issue"

- id: "MasterSlaveArchitectures"
  title: "Biometric Recognition in Surveillance Environments Using Master-Slave Architectures"
  authors: "Hugo Proença, João C. Neves"
  venue: "Proceedings of the 31st Conference on Graphics, Patterns and Images- SIBGRAPI 2018"
  year: 2018
  status: "published"
  publication_type: "conference"
  doi: "10.1109/SIBGRAPI.2018.00068"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/SIBGRAPI2018.pdf"
  thumbnail: "/assets/publications/ieeexplore.jpg"
  tags:
    - "Biometric Recognition"
    - "Surveillance"
    - "Master-Slave Architecture"
    - "PTZ Camera"
  abstract: "The number of visual surveillance systems deployed worldwide has been growing astoundingly. As a result, attempts have been made to increase the levels of automated analysis of such systems, towards the reliable recognition of human beings in fully covert conditions. Among other possibilities, master-slave architectures can be used to acquire high resolution data of subjects heads from large distances, with enough resolution to perform face recognition. This paper/tutorial provides a comprehensive overview of the major phases behind the development of a recognition system working in outdoor surveillance scenarios, describing frameworks and methods to: 1) use coupled wide view and Pan-Tilt-Zoom (PTZ) imaging devices in surveillance settings, with a wide-view camera covering the whole scene, while a synchronized PTZ device collects high-resolution data from the head region; 2) use soft biometric information (e.g., body metrology and gait) for pruning the set of potential identities for each query; and 3) faithfully balance ethics/privacy and safety/security issues in this kind of systems."


- id: "RegionBasedCNN"
  title: "Region-Based CNNs for Pedestrian Gender Recognition in Visual Surveillance Environments"
  authors: "Ehsan Yaghoubi, Pendar Alirezazadeh, Eduardo Assunção, João C. Neves, Hugo Proença"
  venue: "Proceedings of the 18th International Conference of the Biometrics Special Interest Group – BIOSIG 2019"
  year: 2019
  status: "published"
  publication_type: "conference"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/biosig2019_ehsan.pdf"
  thumbnail: "/assets/publications/springer.jpg"
  tags:
    - "Gender Recognition"
    - "Visual Surveillance"
    - "Region-Based CNN"
    - "Soft Biometrics"
  abstract: "Inferring soft biometric labels in totally uncontrolled outdoor environments, such as surveillance scenarios, remains a challenge due to the low resolution of data and its covariates that might seriously compromise performance (e.g., occlusions and subjects pose). In this kind of data, even state-of-the-art deep-learning frameworks (such as ResNet) working in a holistic way, attain relatively poor performance, which was the main motivation for the work described in this paper. In particular, having noticed the main effect of the subjects' 'pose' factor, in this paper we describe a method that uses the body keypoints to estimate the subjects pose and define a set of regions of interest (e.g., head, torso, and legs). This information is used to learn appropriate classification models, specialized in different poses/body parts, which contributes to solid improvements in performance. This conclusion is supported by the experiments we conducted in multiple real-world outdoor scenarios, using the data acquired from advertising panels placed in crowded urban environments."

- id: "VisualSurveillanceBiometrics"
  title: "Visual Surveillance and Biometrics: Practices, Challenges, and Possibilities"
  authors: "Sambit Bakshi, Guodong Guo, Hugo Proença, Massimo Tistarelli"
  venue: "IEEE Access"
  year: 2019
  status: "published"
  publication_type: "journal"
  doi: "10.1109/ACCESS.2019.2940175"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/IEEE_Access_SI_2019.pdf"
  thumbnail: "/assets/publications/ieeeaccess.jpg"
  tags:
    - "Visual Surveillance"
    - "Biometrics"
    - "Security Systems"
    - "Privacy"
  abstract: "Visual surveillance is the latest paradigm for social security through machine intelligence. It includes the use of visual data captured by infrared sensors or visible-light cameras mounted in cars, corridors, traffic signals etc. Visual surveillance facilitates the classification of human behavior, crowd activity, and gesture analysis to achieve application-specific objectives. Biometrics is the science of uniquely identifying or verifying an individual among a set of people by exploring the user's physiological or behavioral characteristics. Due to their ease of use in many application scenarios (including time attendance systems, border control, access control for high security, etc.), biometric systems are currently being introduced in many everyday activities. In the past, some solutions developed for visual surveillance systems have also been applied for biometric identification. Recently, various research efforts have been devoted to merge these two technologies, especially for adverse and covert scenarios. This Special Section, 'Visual Surveillance and Biometrics: Practices, Challenges, and Possibilities,' serves as a cross-platform to cover the recent advances at the intersection of 'visual surveillance' and 'biometrics.' It contains 20 cutting-edge research articles by leading researchers from more than fifteen countries, discussing the current challenges and possible solutions in both fields."

- id: "SegmentationlessIris"
  title: "Segmentation-less and Non-holistic Deep-Learning Framework for Iris Recognition"
  authors: "Hugo Proença, João C. Neves"
  venue: "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition 'Bias Estimation in Face Analytics' Workshop, – CVPRW 2019"
  year: 2019
  status: "published"
  publication_type: "conference"
  doi: "10.1109/CVPRW.2019.00283"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/CVPRW19.pdf"
  thumbnail: "/assets/publications/cvf.jpg"
  tags:
    - "Iris Recognition"
    - "Segmentation-less"
    - "Deep Learning"
    - "Biometrics"
  abstract: "Driven by the pioneer iris biometrics approach, the most relevant recognition methods published over the years are 'phase-based', and segment/normalize the iris to obtain dimensionless representations of the data that attenuate the differences in scale, translation, rotation and pupillary dilation. In this paper we present a recognition method that dispenses the iris segmentation, noise detection and normalization phases, and is agnostic to the levels of pupillary dilation, while maintaining state-of-the-art performance. Based on deep-learning classification models, we analyze the displacements between biologically corresponding patches in pairs of iris images, to discriminate between genuine and impostor comparisons. Such corresponding patches are firstly learned in the normalized representations of the irises - the domain where they are optimally distinguishable - but are remapped into a segmentation-less polar coordinate system that uniquely requires iris detection. In recognition time, samples are only converted into this segmentation-less coordinate system, where matching is performed. In the experiments, we considered the challenging open-world setting, and used three well known data sets (CASIA-4-Lamp, CASIA-4-Thousand and WVU), concluding positively about the effectiveness of the proposed algorithm, particularly in cases where accurately segmenting the iris is a challenge."

- id: "FaceGenderID"
  title: "FaceGenderID: Exploiting Gender Information in DCNNs Face Recognition Systems"
  authors: "Marta Blásquez, Aythami Morales, Ester Gonzalez, João C. Neves, Hugo Proença, Rúben Vera-Rodriguez"
  venue: "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition 'Biometrics' Workshop – CVPRW 2019"
  year: 2019
  status: "published"
  publication_type: "conference"
  doi: "10.1109/CVPRW.2019.00278"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/cvprw_2019.pdf"
  thumbnail: "/assets/publications/cvf.jpg"
  tags:
    - "Face Recognition"
    - "Gender Bias"
    - "DCNNs"
    - "Biometrics"
  abstract: "This paper addresses the effect of gender as a covariate in face verification systems. Even though pre-trained models based on Deep Convolutional Neural Networks (DCNNs), such as VGG-Face or ResNet-50, achieve very high performance, they are trained on very large datasets comprising millions of images, which have biases regarding demographic aspects like the gender and the ethnicity among others. In this work, we first analyse the separate performance of these state-of-the-art models for males and females. We observe a gap between face verification performances obtained by both gender classes. These results suggest that features obtained by biased models are affected by the gender covariate. We propose a gender-dependent training approach to improve the feature representation for both genders, and develop both: i) gender specific DCNNs models, and ii) a gender balanced DCNNs model. Our results show significant and consistent improvements in face verification performance for both genders, individually and in general with our proposed approach. Finally, we announce the availability (at GitHub) of the FaceGenderID DCNNs models proposed in this work, which can support further experiments on this topic."

- id: "HumanAttributeRecognition"
  title: "Human Attribute Recognition: A Comprehensive Survey"
  authors: "Ehsan Yaghoubi, Farhad Khezeli, Diana Borza, SV Aruna Kumar, João C. Neves, Hugo Proença"
  venue: "MDPI Applied Sciences"
  year: 2020
  status: "published"
  publication_type: "journal"
  doi: "10.3390/app10165608"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Ehsan_MDPI_AS.pdf"
  thumbnail: "/assets/publications/as.jpg"
  tags:
    - "Human Attribute Recognition"
    - "Survey"
    - "Computer Vision"
    - "Pattern Recognition"
  abstract: "Human Attribute Recognition (HAR) is a highly active research field in computer vision and pattern recognition domains with various applications such as surveillance or fashion. Several approaches have been proposed to tackle the particular challenges in HAR. However, these approaches have dramatically changed over the last decade, mainly due to the improvements brought by deep learning solutions. To provide insights for future algorithm design and dataset collections, in this survey, (1) we provide an in-depth analysis of existing HAR techniques, concerning the advances proposed to address the HAR's main challenges; (2) we provide a comprehensive discussion over the publicly available datasets for the development and evaluation of novel HAR approaches; (3) we outline the applications and typical evaluation metrics used in the HAR context."

- id: "AttentionPedestrian"
  title: "An Attention-Based Deep Learning Model for Multiple Pedestrian Attributes Recognition"
  authors: "Ehsan Yaghoubi, Diana Borza, João C. Neves, SV Aruna Kumar, Hugo Proença"
  venue: "Elsevier Image and Vision Computing"
  year: 2020
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.imavis.2020.103981"
  thumbnail: "/assets/publications/ivc.jpg"
  tags:
    - "Pedestrian Attributes Recognition"
    - "Attention Mechanism"
    - "Deep Learning"
    - "Multi-task Learning"
  abstract: "The automatic characterization of pedestrians in surveillance footage is a tough challenge, particularly when the data is extremely diverse with cluttered backgrounds, and subjects are captured from varying distances, under multiple poses, with partial occlusion. Having observed that the state-of-the-art performance is still unsatisfactory, this paper provides a novel solution to the problem, with two-fold contributions: 1) considering the strong semantic correlation between the different full-body attributes, we propose a multi-task deep model that uses an element-wise multiplication layer to extract more comprehensive feature representations. In practice, this layer serves as a filter to remove irrelevant background features, and is particularly important to handle complex, cluttered data; and 2) we introduce a weighted-sum term to the loss function that not only relativizes the contribution of each task but also is crucial for performance improvement in multiple-attribute inference settings. Our experiments were performed on two well-known datasets (RAP and PETA) and point for the superiority of the proposed method with respect to the state-of-the-art."

- id: "GANprintR"
  title: "GANprintR: Improved Fakes and Evaluation of the State of the Art in Face Manipulation Detection"
  authors: "João C. Neves, Ruben Tolosana, Ruben Vera-Rodriguez, Vasco Lopes, Hugo Proença, Julian Fierrez"
  venue: "IEEE Journal of Selected Topics in Signal Processing"
  year: 2020
  status: "published"
  publication_type: "journal"
  doi: "10.1109/JSTSP.2020.3007250"
  thumbnail: "/assets/publications/paper-130.png"
  tags:
    - "Face Manipulation Detection"
    - "GAN Fingerprints"
    - "Deep Learning"
    - "Digital Forensics"
  abstract: "The availability of large-scale facial databases, together with the remarkable progresses of deep learning technologies, in particular Generative Adversarial Networks (GANs), have led to the generation of extremely realistic fake facial content, raising obvious concerns about the potential for misuse. Such concerns have fostered the research on manipulation detection methods that, contrary to humans, have already achieved astonishing results in various scenarios. This chapter is focused on the analysis of GAN fingerprints in face image synthesis. In particular, it covers an in-depth literature analysis of state-of-the-art detection approaches for the entire face synthesis manipulation. It also describes a recent approach to spoof fake detectors based on a GAN-fingerprint Removal autoencoder (GANprintR). A thorough experimental framework is included in the chapter, highlighting (i) the potential of GANprintR to spoof fake detectors, and (ii) the poor generalisation capability of current fake detectors."

- id: "IbPRIAEditorial"
  title: "Editorial for special section at Pattern Recognition Letters - IbPRIA 2019"
  authors: "Manuel J. Marin-Jimenez, Aythami Morales, Julian Fierrez, Antonio Pertusa, Hugo Proença, J. Salvador Sanchez"
  venue: "Elsevier Pattern Recognition Letters"
  year: 2020
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.patrec.2020.03.024"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ibpria19_PRL.pdf"
  thumbnail: "/assets/publications/prl.jpg"
  tags:
    - "Editorial"
    - "Pattern Recognition"
    - "Image Analysis"
    - "Machine Learning"
  abstract: "Now in its 9th edition, IbPRIA has become a key research event in pattern recognition and image analysis in the Iberian Peninsula organized by the national IAPR associations for pattern recognition in Spain (AERFAI) and Portugal (APRP). Most of the research presented during the event, therefore, came from authors from Spain and Portugal. Out of the 401 authors who published in IbPRIA 2019, 29% were from Spain and 20% were from Portugal. More than 50% of the authors were from another 32 countries from all around the world, with high representation from countries like: Algeria, Brazil, Colombia, India, Italy, or Mexico. Our efforts to strengthen the bonds between the research conducted in the Iberian Peninsula and other countries was patent in the program, which emphasized interactive poster sessions, and included a special session dedicated to international research cooperation. IbPRIA 2019 received 137 submissions. The review process for IbPRIA 2019 was diligent and required careful consideration of more than 400 reviews from 100 reviewers who spent significant time and effort in reviewing the papers. In the end 99 papers were accepted, which is a 72% of acceptance. To form the final program 30 papers were selected for oral presentations (22% acceptance rate) and 69 as poster presentations. The program consisted of 7 oral sessions on the following topics: machine learning, image representation, image processing, biometrics, and document analysis. Three poster sessions included papers on all previous topics and also on the most important applications of nowadays technologies."

- id: "PoseSwitchCNN"
  title: "Pose Switch-Based Convolutional Neural Network for Clothing Analysis in Visual Surveillance Environments"
  authors: "Pendar Alirezazadeh, Ehsan Yaghoubi, Eduardo Assunção, João C. Neves, Hugo Proença"
  venue: "Proceedings of the 18th International Conference of the Biometrics Special Interest Group – BIOSIG 2019"
  year: 2019
  status: "published"
  publication_type: "conference"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/biosig2019_pendar.pdf"
  thumbnail: "/assets/publications/ieeexplore.jpg"
  tags:
    - "Clothing Analysis"
    - "Visual Surveillance"
    - "Pose Estimation"
    - "CNN"
  abstract: "Recognizing pedestrian clothing types and styles in outdoor scenes and totally uncontrolled conditions is appealing to emerging applications such as security, intelligent customer profile analysis and computer-aided fashion design. Recognition of clothing categories from videos remains a challenge, mainly due to the poor data resolution and the data covariates that compromise the effectiveness of automated image analysis techniques (e.g., poses, shadows and partial occlusions). While state-of-the-art methods typically analyze clothing attributes without paying attention to variation of human poses, here we claim for the importance of a feature representation derived from human poses to improve classification rate. Estimating the pose of pedestrians is important to fed guided features into recognizing system. In this paper, we introduce pose switch-based convolutional neural network for recognizing the types of clothes of pedestrians, using data acquired in crowded urban environments. In particular, we compare the effectiveness attained when using CNNs without respect to human poses variant, and assess the improvements in performance attained by pose feature extraction. The observed results enable us to conclude that pose information can improve the performance of clothing recognition system. We focus on the key role of pose information in pedestrian clothing analysis, which can be employed as an interesting topic for further works."

- id: "PatternRecognitionTrends"
  title: "New Trends on Pattern Recognition, Applications and Systems"
  authors: "Hugo Proença, João C. Neves"
  venue: "Applied Sciences"
  year: 2021
  status: "published"
  publication_type: "special issue"
  tags:
    - "Pattern Recognition"
    - "Special Issue"
    - "Applications"
    - "Systems"

- id: "FruitDiseasesClassification"
  title: "Decision-making support system for fruit diseases classification using Deep Learning"
  authors: "Eduardo Assunção, Catarina Diniz, Pedro D. Gaspar, Hugo Proença"
  venue: "Proceedings of the 2020 International Conference on Decision Aid Sciences and Application – DASA 2020"
  year: 2020
  status: "published"
  publication_type: "conference"
  doi: "10.1109/DASA51403.2020.9317219"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/DASA_2020.pdf"
  thumbnail: "/assets/publications/ieeexplore.jpg"
  tags:
    - "Fruit Disease Classification"
    - "Deep Learning"
    - "Computer Vision"
    - "Decision Support Systems"
  abstract: "Fruit diseases are a continuous hazard to farmers. By applying computer vision-based techniques, precision agriculture can support the farmers in the decision making for fruit disease control. Features extraction is an essential task for the computer vision pipeline. Nowadays, in general, feature extraction for fruit diseases are handcrafted. However, empirical results in different domains confirm that features learned by Convolutional neural networks (CNNs) provide significant improvements in accuracy over handcrafted features. CNNs have been applied in many computer vision tasks, replacing the hand-engineered models. In general, a large-scale image dataset is necessary for training a CNN. However, there are not many fruit disease images available to compose the dataset. We propose to train a tiny and efficient deep convolutional network developed to run in the mobile devices to classify healthy peach fruits and three peach diseases. Based on transfer learning techniques and data augmentation strategies, the proposed model achieves a Macroaverage F1-score of 0.96. The model does not misclassify any disease class. This achievement shows the potential of using small CNN models for fruit disease classification when having a small quantity of training data."

- id: "UPeriocular"
  title: "Unconstrained Periocular Recognition: Using Generative Deep Learning Frameworks for Attribute Normalization"
  authors: "Luiz A. Zanlorensi, Hugo Proença, David Menotti"
  venue: "Proceedings of the IEEE International Conference on Image Processing – ICIP 2020"
  year: 2020
  status: "published"
  publication_type: "conference"
  doi: "10.1109/ICIP40778.2020.9191251"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/icip2020.pdf"
  thumbnail: "/assets/publications/springer.jpg"
  tags:
    - "Periocular Recognition"
    - "Attribute Normalization"
    - "Generative Deep Learning"
    - "Unconstrained Environments"
  abstract: "Ocular biometric systems working in unconstrained environments usually face the problem of small within-class compactness caused by the multiple factors that jointly degrade the quality of the obtained data. In this work, we propose an attribute normalization strategy based on deep learning generative frameworks, that reduces the variability of the samples used in pairwise comparisons, without reducing their discriminability. The proposed method can be seen as a preprocessing step that contributes for data regularization and improves the recognition accuracy, being fully agnostic to the recognition strategy used. As proof of concept, we consider the 'eyeglasses' and 'gaze' factors, comparing the levels of performance of five different recognition methods with/without using the proposed normalization strategy. Also, we introduce a new dataset for unconstrained periocular recognition, composed of images acquired by mobile devices, particularly suited to perceive the impact of 'wearing eyeglasses' in recognition effectiveness. Our experiments were performed in two different datasets, and support the usefulness of our attribute normalization scheme to improve the recognition performance."

- id: "HairNet"
  title: "All-in-one \"HairNet\": A Deep Neural Model for Joint Hair Segmentation and Characterization"
  authors: "Diana Borza, Ehsan Yaghoubi, João C. Neves, Hugo Proença"
  venue: "Proceedings of the International Joint Conference on Biometrics – IJCB 2020"
  year: 2020
  status: "published"
  publication_type: "conference"
  doi: "10.1109/IJCB48548.2020.9304904"
  thumbnail: "/assets/publications/ieeexplore.jpg"
  tags:
    - "Hair Segmentation"
    - "Hair Characterization"
    - "Deep Learning"
    - "Soft Biometrics"
  abstract: "The hair appearance is among the most valuable soft biometric traits when performing human recognition at-a-distance. Even in degraded data, the hair's appearance is instinctively used by humans to distinguish between individuals. In this paper we propose a multi-task deep neural model capable of segmenting the hair region, while also inferring the hair color, shape and style, all from in-the-wild images. Our main contributions are two-fold: 1) the design of an all-in-one neural network, based on depth-wise separable convolutions to extract the features; and 2) the use convolutional feature masking layer as an attention mechanism that enforces the analysis only within the 'hair' regions. In a conceptual perspective, the strength of our model is that the segmentation mask is used by the other tasks to perceive - at feature-map level - only the regions relevant to the attribute characterization task. This paradigm allows the network to analyze features from non-rectangular areas of the input data, which is particularly important, considering the irregularity of hair regions. Our experiments showed that the proposed approach reaches a hair segmentation performance comparable to the state-of-the-art, having as main advantage the fact of performing multiple levels of analysis in a single-shot paradigm."

- id: "HumanActivityAnalysis"
  title: "Human Activity Analysis: Iterative Weak/Self-Supervised Learning Frameworks for Detecting Abnormal Events"
  authors: "Bruno Degardin, Hugo Proença"
  venue: "Proceedings of the International Joint Conference on Biometrics – IJCB 2020"
  year: 2020
  status: "published"
  publication_type: "conference"
  doi: "10.1109/IJCB48548.2020.9304905"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ijcb2020_degardin.pdf"
  thumbnail: "/assets/publications/ieeexplore.jpg"
  tags:
    - "Human Activity Analysis"
    - "Abnormal Events Detection"
    - "Self-Supervised Learning"
    - "Weak Supervision"
  abstract: "Having observed the unsatisfactory state-of-the-art performance in detecting abnormal events, this paper describes an iterative self-supervised learning method for such purpose. The proposed solution is composed of two experts that - at each step - find the most confidently classified instances to augment the amount of data available for the next iteration. Our contributions are four-fold: 1) we describe the iterative learning framework composed of experts working in the weak/self-supervised paradigms and providing learning data to each other, with the novel instances being filtered by a Bayesian framework; 2) upon Sultani et al.'s work, we suggest a novel term the loss function that spreads the scores in the unit interval and is important for the performance of the iterative framework; 3) we propose a late decision fusion scheme, in which an ensemble of Decision Trees learned from bootstrap samples fuses the scores of the top-3 methods, reducing the EER values about 20% over the state-of-the-art; and 4) we announce the 'Fights' dataset, fully annotated at the frame level, that can be freely used by the research community."

- id: "IterativeSelfSupervised"
  title: "Iterative Weak/Self-Supervised Classification Framework for Abnormal Events Detection"
  authors: "Bruno Degardin, Hugo Proença"
  venue: "Elsevier Pattern Recognition Letters"
  year: 2021
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.patrec.2021.01.031"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Events_PRL.pdf"
  thumbnail: "/assets/publications/prl.jpg"
  tags:
    - "Abnormal Events Detection"
    - "Weak Supervision"
    - "Self-Supervised Learning"
    - "Visual Surveillance"
  abstract: "The detection of abnormal events in surveillance footage remains a challenge and has been the scope of various research works. Having observed that the state-of-the-art performance is still unsatisfactory, this paper provides a novel solution to the problem, with four-fold contributions: 1) upon the work of Sultani et al., we introduce one iterative learning framework composed of two experts working in the weak and self-supervised paradigms and providing additional amounts of learning data to each other, where the novel instances at each iteration are filtered by a Bayesian framework that supports the iterative data augmentation task; 2) we describe a novel term that is added to the baseline loss to spread the scores in the unit interval, which is crucial for the performance of the iterative framework; 3) we propose a Random Forest ensemble that fuses at the score level the top performing methods and reduces the EER values about 20% over the state-of-the-art; and 4) we announce the availability of the 'UBI-Fights' dataset, fully annotated at the frame level, that can be freely used by the research community."

- id: "SSSPersonReID" 
  title: "SSS-PR: A Short Survey of Surveys in Person Re-identification"
  authors: "Ehsan Yaghoubi, SV Aruna Kumar, Hugo Proença"
  venue: "Elsevier Pattern Recognition Letters"
  year: 2021
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.patrec.2020.12.017"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/SSS-PR.pdf"
  thumbnail: "/assets/publications/prl.jpg"
  tags:
    - "Person Re-identification"
    - "Survey"
    - "Multi-dimensional Taxonomy"
  abstract: "Person re-identification (re-id) addresses the problem of whether 'a query image corresponds to an identity in the database' and is believed to play a fundamental role in security enforcement in the near future, particularly in crowded urban environments. Due to many possibilities in selecting appropriate model architectures, datasets, and settings, the performance reported by the state-of-the-art re-id methods oscillates significantly among the published surveys. Therefore, it is difficult to understand the mainstream trends and emerging research difficulties in person re-id. This paper proposes a multi-dimensional taxonomy to categorize the most relevant researches according to different perspectives and tries to unify the categorization of re-id methods and fill the gap between the recently published surveys. Furthermore, we discuss the open challenges with a focus on privacy concerns and the issues caused by the exponential increase in the number of re-id publications over the recent years. Finally, we discuss several challenging directions for future studies."

- id: "DeepAdversarialInterpretable"
  title: "A Deep Adversarial Framework for Visually Interpretable Biometric Recognition"
  authors: "João Brito, Hugo Proença"
  venue: "Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition 'Biometrics' Workshop – CVPRW 2021"
  year: 2021
  status: "published"
  publication_type: "conference"
  doi: "10.1109/CVPRW53098.2021.00161"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/cvprw2021.pdf"
  thumbnail: "/assets/publications/cvf.jpg"
  tags:
    - "Visual Interpretability"
    - "Biometric Recognition"
    - "Adversarial Generative Techniques"
    - "Periocular Recognition"
  abstract: "In the biometrics context, the ability to provide the reasoning behind a decision has been at the core of major research efforts. Explanations serve not only to increase the trust amongst the users of a system, but also to augment the system's overall accountability and transparency. In this work, we describe a periocular recognition framework that not only performs biometric recognition, but also provides visual representations of the features/regions that supported a decision. Being particularly designed to explain non-match ('impostors') decisions, our solution uses adversarial generative techniques to synthesise a large set of 'genuine' image pairs, from where the most similar elements with respect to a query are retrieved. Then, assuming the alignment between the query/retrieved pairs, the element-wise differences between the query and a weighted average of the retrieved elements yields a visual explanation of the regions in the query pair that would have to be different to transform it into a 'genuine' pair. Our quantitative and qualitative experiments validate the proposed solution, yielding recognition rates that are similar to the state-of-the-art, but - most importantly - also providing the visual explanations for every decision."

- id: "PDESTRE"
  title: "The P-DESTRE: A Fully Annotated Dataset for Pedestrian Detection, Tracking and Short/Long-term Re-Identification from Aerial Devices"
  authors: "SV Aruna Kumar, Ehsan Yaghoubi, Abhijit Das, B.S. Harish, Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2021
  status: "published" 
  publication_type: "journal"
  doi: "10.1109/TIFS.2020.3040881"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/PDESTRE.pdf"
  thumbnail: "/assets/publications/tifs.jpg"
  tags:
    - "Pedestrian Detection"
    - "Pedestrian Tracking"
    - "Re-identification"
    - "Unmanned Aerial Vehicles"
  abstract: "Over the years, unmanned aerial vehicles (UAVs) have been regarded as a potential solution to surveil public spaces, providing a cheap way for data collection, while covering large and difficult-to-reach areas. This kind of solutions can be particularly useful to detect, track and identify subjects of interest in crowds, for security/safety purposes. In this context, various datasets are publicly available, yet most of them are only suitable for evaluating detection, tracking and short-term re-identification techniques. This paper announces the free availability of the P-DESTRE dataset, the first of its kind to provide video/UAV-based data for pedestrian long-term re-identification research, with ID annotations consistent across data collected in different days. As a secondary contribution, we provide the results attained by the state-of-the-art pedestrian detection, tracking, short/long term re-identification techniques in well-known surveillance datasets, used as baselines for the corresponding effectiveness observed in the P-DESTRE data. This comparison highlights the discriminating characteristics of P-DESTRE with respect to similar sets. Finally, we identify the most problematic data degradation factors and co-variates for UAV-based automated data analysis, which should be considered in subsequent technologic/conceptual advances in this field."

- id: "QuadrupletLoss"
  title: "A Quadruplet Loss for Enforcing Semantically Coherent Embeddings in Multi-output Classification Problems"
  authors: "Hugo Proença, Ehsan Yaghoubi, Pendar Alirezazadeh"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2021
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2020.3023304"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Quadruplet.pdf"
  thumbnail: "/assets/publications/tifs.jpg"
  tags:
    - "Quadruplet Loss"
    - "Multi-output Classification"
    - "Feature Embeddings"
    - "Soft Biometrics"
  abstract: "This paper describes one objective function for learning semantically coherent feature embeddings in multi-output classification problems, i.e., when the response variables have dimension higher than one. Such coherent embeddings can be used simultaneously for different tasks, such as identity retrieval and soft biometrics labelling. We propose a generalization of the triplet loss that: 1) defines a metric that considers the number of agreeing labels between pairs of elements; 2) introduces the concept of similar classes, according to the values provided by the metric; and 3) disregards the notion of anchor, sampling four arbitrary elements at each time, from where two pairs are defined. The distances between elements in each pair are imposed according to their semantic similarity (i.e., the number of agreeing labels). Likewise the triplet loss, our proposal also privileges small distances between positive pairs. However, the key novelty is to additionally enforce that the distance between elements of any other pair corresponds inversely to their semantic similarity. The proposed loss yields embeddings with a strong correspondence between the classes centroids and their semantic descriptions. In practice, it is a natural choice to jointly infer coarse (soft biometrics) + fine (ID) labels, using simple rules such as k-neighbours. Also, in opposition to its triplet counterpart, the proposed loss appears to be agnostic with regard to demanding criteria for mining learning instances (such as the semi-hard pairs). Our experiments were carried out in five different datasets (BIODI, LFW, IJB-A, Megaface and PETA) and validate our assumptions, showing results that are comparable to the state-of-the-art in both the identity retrieval and soft biometrics labelling tasks."

- id: "HumanBehaviorAnalysis"
  title: "Human Behavior Analysis: A Survey on Action Recognition"
  authors: "Bruno Degardin, Hugo Proença"
  venue: "MDPI Applied Sciences"
  year: 2021
  status: "published"
  publication_type: "journal"
  doi: "10.3390/app11188324"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/AS_Degardin.pdf"
  thumbnail: "/assets/publications/As.jpg"
  tags:
    - "Human Behavior Analysis"
    - "Action Recognition"
    - "Survey"
    - "Computer Vision"
  abstract: "The visual recognition and understanding of human actions remain an active research domain of computer vision, being the scope of various research works over the last two decades. The problem is challenging due to its many interpersonal variations in appearance and motion dynamics between humans, without forgetting the environmental heterogeneity between different video images. This complexity splits the problem into two major categories: action classification, recognising the action being performed in the scene, and spatiotemporal action localisation, concerning recognising multiple localised human actions present in the scene. Previous surveys mainly focus on the evolution of this field, from handcrafted features to deep learning architectures. However, this survey presents an overview of both categories and respective evolution within each one, the guidelines that should be followed and the current benchmarks employed for performance comparison between the state- of-the-art methods."

- id: "OcularBiometricsEditorial"
  title: "Editorial to special issue on novel insights on ocular biometrics"
  authors: "Maria De Marsico, Hugo Proença, Sambit Bakshi, Abhijit Das"
  venue: "Elsevier Image and Vision Computing"
  year: 2021
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.imavis.2021.104227"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/IVC_SI.pdf"
  thumbnail: "/assets/publications/Ivc.jpg"
  tags:
    - "Ocular Biometrics"
    - "Periocular Recognition"
    - "Sclera Recognition"
    - "Editorial"
  abstract: "Ocular biometrics have a great potential to support biometric applications, due to the unique features of the ocular traits. Notwithstanding this, the related lines of research still present several open issues, which justify the ongoing research efforts. For instance, the relatively recent emergence of the periocular and sclera traits makes it worth recording the progresses in those areas. Furthermore, wider and deeper investigations regarding all the traits underlying the ocular region and the best way to combine them still needs to be thoroughly undertaken. This would not only improve the recognition robustness, but also make perceiving the potential of this kind of solutions in solving problems in the biometrics domain. Moreover, 'systems interpretability', 'weakly/partial supervised recognition' or 'forensics evidence and biometric recognition' add interest to an already rich field of research. This special issue aims at providing a platform to publish and record the recent research on ocular biometrics in order to push the state-of-the-art forward."

- id: "YouLookSoDifferent"
  title: "You Look So Different! Haven't I Seen You a Long Time Ago?"
  authors: "Ehsan Yaghoubi, Diana Borza, Bruno Degardin, Hugo Proença"
  venue: "Elsevier Image and Vision Computing"
  year: 2021
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.imavis.2021.104288"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/IVC_Ehsan_2021.pdf"
  thumbnail: "/assets/publications/ivc.jpg"
  tags:
    - "Person Re-identification"
    - "Long-term Recognition"
    - "Clothing-invariant Features"
    - "Deep Learning"
  abstract: "Person re-identification (re-id) aims to match a query identity (ID) to an element in a gallery set, composed of elements collected from multiple cameras. Most of the existing re-id methods assume the short-term setting, where the query/gallery samples share the clothing style. In this setting, the optimal feature representations are based in the visual appearance of clothes, which considerably drops the identification performance for long-term settings. Having this problem in mind, we propose a model that learns long-term representations of persons by ignoring any features previously learned by a short-term re-id model, which naturally makes it invariant to clothing styles. We start by synthesizing a data set in which we distort the most relevant biometric information (based in face, body shape, height, and weight cues), keeping the short-term cues (color and texture of clothes) unchanged. This way, while the original data contains both ID-related and other varying features, the synthesized representations are composed mostly of short-term attributes. Then, the key to obtaining stable long-term representations is to learn embeddings of the original data that maximize the dissimilarity with the previously inferred short-term embeddings. In practice, we use the synthetic data to learn a model that embeds the ID-unrelated features and then learn a second model from the original data, where long-term embeddings are obtained, keeping their independence with respect to the previously obtained ID-unrelated features. Our experiments were performed on three challenging cloth-changing sets (LTCC, PRCC, and NKUP) and the results support the effectiveness of the proposed method, for both short and long-term re-id settings."

- id: "PersonReID"
  title: "Person re-identification: Implicitly Defining the Receptive Fields of Deep Learning Classification Frameworks"
  authors: "Ehsan Yaghoubi, Diana Borza, SV Aruna Kumar, Hugo Proença"
  venue: "Elsevier Pattern Recognition Letters"
  year: 2021
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.patrec.2021.01.035"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/RF_PRL.pdf"
  thumbnail: "/assets/publications/prl.jpg"
  tags:
    - "Person Re-identification"
    - "Receptive Fields"
    - "Deep Learning"
    - "Classification"
  abstract: "The receptive fields of deep learning models determine the most significant regions of the input data for providing correct decisions. Up to now, the primary way to learn such receptive fields is to train the models upon masked data, which helps the networks to ignore any unwanted regions, but also has two major drawbacks: (1) it yields edge-sensitive decision processes; and (2) it augments considerably the computational cost of the inference phase. Having theses weaknesses in mind, this paper describes a solution for implicitly enhancing the inference of the networks' receptive fields, by creating synthetic learning data composed of interchanged segments considered apriori important or irrelevant for the network decision. In practice, we use a segmentation module to distinguish between the foreground (important) versus background (irrelevant) parts of each learning instance, and randomly swap segments between image pairs, while keeping the class label exclusively consistent with the label of the segments deemed important. This strategy typically drives the networks to interpret that the identity and clutter descriptions are not correlated. Moreover, the proposed solution has other interesting properties: (1) it is parameter-learning-free; (2) it fully preserves the label information; and (3) it is compatible with the data augmentation techniques typically used. In our empirical evaluation, we considered the person re-identification problem, and the well known RAP, Market1501 and MSMT-V2 datasets for two different settings (upper-body and full-body), having observed highly competitive results over the state-of-the-art."

- id: "MLExplainabilityPeriocular"
  title: "A short survey on machine learning explainability: an application to periocular recognition"
  authors: "João Brito, Hugo Proença"
  venue: "MDPI Electronics"
  year: 2021
  status: "published"
  publication_type: "journal"
  doi: "10.3390/electronics10151861"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Electronics_JBrito.pdf"
  thumbnail: "/assets/publications/mdpielectronics.jpg"
  tags:
    - "Machine Learning Explainability"
    - "Periocular Recognition"
    - "Visual Explanations"
    - "Interpretable AI"
  abstract: "Interpretability has made significant strides in recent years, enabling the formerly black-box models to reach new levels of transparency. These kinds of models can be particularly useful to broaden the applicability of machine learning-based systems to domains where—apart from the predictions—appropriate justifications are also required (e.g., forensics and medical image analysis). In this context, techniques that focus on visual explanations are of particular interest here, due to their ability to directly portray the reasons that support a given prediction. Therefore, in this document, we focus on presenting the core principles of interpretability and describing the main methods that deliver visual cues (including one that we designed for periocular recognition in particular). Based on these intuitions, the experiments performed show explanations that attempt to highlight the most important periocular components towards a non-match decision. Then, some particularly challenging scenarios are presented to naturally sustain our conclusions and thoughts regarding future directions."

- id: "RealTimeWeedControl"
  title: "Real-Time Weed Control Application Using a Jetson Nano Edge Device and a Spray Mechanism"
  authors: "Eduardo Assunção, Pedro D. Gaspar, Ricardo Mesquita, Maria P. Simões, Khadijeh Alibabaei, André Veiros, Hugo Proença"
  venue: "MDPI Remote Sensing"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.3390/rs14174217"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/rs_22.pdf"
  thumbnail: "/assets/publications/rs.jpg"
  tags:
    - "Deep Neural Networks"
    - "Edge Computing"
    - "Weed Control"
    - "Semantic Segmentation"
  abstract: "Portable devices play an essential role where edge computing is necessary and mobility is required (e.g., robots in agriculture within remote-sensing applications). With the increasing applications of deep neural networks (DNNs) and accelerators for edge devices, several methods and applications have been proposed for simultaneous crop and weed detection. Although preliminary studies have investigated the performance of inference time for semantic segmentation of crops and weeds in edge devices, performance degradation has not been evaluated in detail when the required optimization is applied to the model for operation in such edge devices. This paper investigates the relationship between model tuning hyperparameters to improve inference time and its effect on segmentation performance. The study was conducted using semantic segmentation model DeeplabV3 with a MobileNet backbone. Different datasets (Cityscapes, PASCAL and ADE20K) were analyzed for a transfer learning strategy. The results show that, when using a model hyperparameter depth multiplier (DM) of 0.5 and the TensorRT framework, segmentation performance mean intersection over union (mIOU) decreased by 14.7% compared to that of a DM of 1.0 and no TensorRT. However, inference time accelerated dramatically by a factor of 14.8. At an image resolution of 1296 × 966, segmentation performance of 64% mIOU and inference of 5.9 frames per second (FPS) was achieved in Jetson Nano's device. With an input image resolution of 513 × 513, and hyperparameters output stride OS = 32 and DM = 0.5, an inference time of 0.04 s was achieved resulting in 25 FPS. The results presented in this paper provide a deeper insight into how the performance of the semantic segmentation model of crops and weeds degrades when optimization is applied to adapt the model to run on edge devices. Lastly, an application is described for the semantic segmentation of weeds embedded in the edge device (Jetson Nano) and integrated with the robotic orchard. The results show good spraying accuracy and feasibility of the method."

- id: "FuzzyConsensus"
  title: "A Fuzzy Consensus Clustering Algorithm for MRI Brain Tissue Segmentation"
  authors: "SV Aruna Kumar, Ehsan Yaghoubi, Hugo Proença"
  venue: "Applied Sciences"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.3390/app12157385"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/applsci-12-07385.pdf"
  thumbnail: "/assets/publications/as.jpg"
  tags:
    - "Brain Tissue Segmentation"
    - "Fuzzy Clustering"
    - "MRI"
    - "Machine Learning"
  abstract: "Brain tissue segmentation is an important component of the clinical diagnosis of brain diseases using multi-modal magnetic resonance imaging (MR). Brain tissue segmentation has been developed by many unsupervised methods in the literature. The most commonly used unsupervised methods are K-Means, Expectation-Maximization, and Fuzzy Clustering. Fuzzy clustering methods offer considerable benefits compared with the aforementioned methods as they are capable of handling brain images that are complex, largely uncertain, and imprecise. However, this approach suffers from the intrinsic noise and intensity inhomogeneity (IIH) in the data resulting from the acquisition process. To resolve these issues, we propose a fuzzy consensus clustering algorithm that defines a membership function resulting from a voting schema to cluster the pixels. In particular, we first pre-process the MRI data and employ several segmentation techniques based on traditional fuzzy sets and intuitionistic sets. Then, we adopted a voting schema to fuse the results of the applied clustering methods. Finally, to evaluate the proposed method, we used the well-known performance measures (boundary measure, overlap measure, and volume measure) on two publicly available datasets (OASIS and IBSR18). The experimental results show the superior performance of the proposed method in comparison with the recent state of the art. The performance of the proposed method is also presented using a real-world Autism Spectrum Disorder Detection problem with better accuracy compared to other existing methods."

- id: "ICPR25th"
  title: "25th ICPR—Real‐time Visual Surveillance as‐a‐Service (VSaaS) for smart security solutions"
  authors: "Michele Nappi, Hugo Proença, Guodong Guo, Sambit Bakshi"
  venue: "IET Biometrics"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.1049/bme2.12089"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ICPR_2022.pdf"
  thumbnail: "/assets/publications/ietbiometrics.jpg"
  tags:
    - "Visual Surveillance"
    - "Real-time Processing"
    - "Security Solutions"
  abstract: "With the advent of ever‐fast computing, real‐time processing of visual data has been gaining importance in the field of surveillance. Also, automated decision‐making by visual surveillance systems has been contributing to a huge leap in the capability of such systems, and of course their relevance in social security. This special issue aimed to discuss cloud‐based architectures of surveillance frameworks as a service. Such systems, especially when deployed to work in real‐time, are required to be fast, efficient, and sustainable with a varying load of visual data. Four papers were selected for inclusion in this special issue."


- id: "YinYangNet"
  title: "YinYang-Net: Complementing Face and Body Information for Wild Gender Recognition"
  authors: "Tiago Roxo, Hugo Proença"
  venue: "IEEE Access"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.1109/ACCESS.2022.3157857"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Tiago_Roxo_IEEEAccess.pdf"
  thumbnail: "/assets/publications/paper-133.png"
  tags:
    - "Gender Recognition"
    - "Soft Biometrics"
    - "Face and Body Information"
    - "Wild Conditions"
  abstract: "Soft biometrics inference in surveillance scenarios is a topic of interest for various applications, particularly in security-related areas. However, soft biometric analysis is not extensively reported in wild conditions. In particular, previous works on gender recognition report their results in face datasets, with relatively good image quality and frontal poses. Given the uncertainty of the availability of the facial region in wild conditions, we consider that these methods are not adequate for surveillance settings. To overcome these limitations, we: 1) present frontal and wild face versions of three well-known surveillance datasets; and 2) propose YinYang-Net (YY-Net), a model that effectively and dynamically complements facial and body information, which makes it suitable for gender recognition in wild conditions. The frontal and wild face datasets derive from widely used Pedestrian Attribute Recognition (PAR) sets (PETA, PA-100K, and RAP), using a pose-based approach to filter the frontal samples and facial regions. This approach retrieves the facial region of images with varying image/subject conditions, where the state-of-the-art face detectors often fail. YY-Net combines facial and body information through a learnable fusion matrix and a channel-attention sub-network, focusing on the most influential body parts according to the specific image/subject features. We compare it with five PAR methods, consistently obtaining state-of-the-art results on gender recognition, and reducing the prediction errors by up to 24% in frontal samples. The announced PAR datasets versions and YY-Net serve as the basis for wild soft biometrics classification and are available in here."

- id: "UUNet"
  title: "The UU-Net: Reversible Face De-Identification for Visual Surveillance Video Footage"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Circuits and Systems for Video Technology"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TCSVT.2021.3066054"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/UU-Net.pdf"
  thumbnail: "/assets/publications/tcsvt.jpg"
  tags:
    - "Face De-Identification"
    - "Visual Surveillance"
    - "Privacy"
    - "Reversible De-identification"
  abstract: "We propose a reversible face de-identification method for video surveillance data, where landmark-based techniques cannot be reliably used. Our solution generates a photorealistic de-identified stream that meets the data protection regulations and can be publicly released under minimal privacy concerns. Notably, such stream still encapsulates the information required to later reconstruct the original scene, which is useful for scenarios, such as crime investigation, where subjects identification is of most importance. Our learning process jointly optimizes two main components: 1) a public module, that receives the raw data and generates the de-identified stream; and 2) a private module, designed for security authorities, that receives the public stream and reconstructs the original data, disclosing the actual IDs of the subjects in a scene. The proposed solution is landmarks-free and uses a conditional generative adversarial network to obtain synthetic faces that preserve pose, lighting, background information and even facial expressions. Also, we keep full control over the set of soft facial attributes to be preserved/changed between the raw/de-identified data, which extends the range of applications for the proposed solution. Our experiments were conducted in three visual surveillance datasets (BIODI, MARS and P-DESTRE) plus one video face data set (YouTube Faces), showing highly encouraging results."

- id: "PeachesDetection"
  title: "Peaches detection using Deep Learning technique – A contribution to yield estimation, resources management and circular economy"
  authors: "Eduardo Assunção, Pedro D. Gaspar, Ricardo Mesquita, Maria Paula Simões, António Ramos, Hugo Proença, Pedro Inácio"
  venue: "MDPI Climate"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.3390/cli1010000"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/climate.pdf"
  thumbnail: "/assets/publications/paper-132.png"
  tags:
    - "Peaches Detection"
    - "Deep Learning"
    - "CNN"
    - "Yield Estimation"
  abstract: "The fruit detection is crucial for yield estimation and fruit picking system performance. Many state-of-art methods for fruit detection use convolutional neural network (CNN). This paper presents the results for peaches detection applying the framework Faster R-CNN in images captured in an outdoor orchard. Although this method has been used in other studies to detect fruits, there is no research works with peaches. Since the fruit colors, it sizes, it shape, tree branches, fruit bunches and the distribution in the tree are particular, the development of the fruit detection procedure is specific. The results show a large potential for using this method to detect this type of fruit. A detection accuracy of 0.90 using the metric average precision (AP) was achieved for the fruit detection. Precision agriculture applications such Deep Neural Networks (DNN) as proposed in this paper can help to mitigate climate change due to horticultural activities by accurate products prediction leading to improved resources management such as irrigation water, nutrients, herbicides, pesticides, as well as helping reducing food loss and waste by improved agricultural activities scheduling."

# - id: "KineticGAN"
#   title: "Generative Adversarial Graph Convolutional Networks for Human Action Synthesis"
#   authors: "Bruno Degardin, João C. Neves, Vasco Lopes, João Brito, Ehsan Yaghoubi, Hugo Proença"
#   venue: "Proceedings of the 2022 IEEE/CVF Winter Conference on Applications of Computer Vision - WACV 2022"
#   year: 2022
#   status: "published"
#   publication_type: "conference"
#   doi: "10.1109/WACV51458.2022.00281"
#   pdf: "http://www.di.ubi.pt/~hugomcp/doc/wacv21.pdf"
#   thumbnail: "/assets/publications/cvf.jpg"
#   tags:
#     - "Human Action Synthesis"
#     - "Generative Adversarial Networks"
#     - "Graph Convolutional Networks"
#   abstract: "Synthesising the spatial and temporal dynamics of the human body skeleton remains a challenging task, not only in terms of the quality of the generated shapes, but also of their diversity, particularly to synthesise realistic body movements of a specific action (action conditioning). In this paper, we propose Kinetic-GAN, a novel architecture that leverages the benefits of Generative Adversarial Networks and Graph Convolutional Networks to synthesise the kinetics of the human body. The proposed adversarial architecture can condition up to 120 different actions over local and global body movements while improving sample quality and diversity through latent space disentanglement and stochastic variations. Our experiments were carried out in three well-known datasets, where Kinetic-GAN notably surpasses the state-of-the-art methods in terms of distribution quality metrics while having the ability to synthesise more than one order of magnitude regarding the number of different actions."

- id: "REGINA"
  title: "REGINA - Reasoning Graph Convolutional Networks in Human Action Recognition"
  authors: "Bruno Degardin, Vasco Lopes, Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2021.3130437"
  pdf: "http://di.ubi.pt/~hugomcp/doc/degardin_tifs_2021.pdf"
  thumbnail: "/assets/publications/tifs.jpg"
  tags:
    - "Human Action Recognition"
    - "Graph Convolutional Networks"
    - "Skeleton-based Recognition"
  abstract: "It is known that the kinematics of the human body skeleton reveals valuable information in action recognition. Recently, modelling skeletons as spatio-temporal graphs with Graph Convolutional Networks (GCNs) has been reported to solidly advance the state-of-the-art performance. However, GCN-based approaches exclusively learn from raw skeleton data, and are expected to extract the inherent structural information on their own. This paper describes REGINA, introducing a novel way to REasoning Graph convolutional networks IN Human Action recognition. The rationale is to provide to the GCNs additional knowledge about the skeleton data, obtained by hand-crafted features, in order to facilitate the learning process, while guaranteeing that it remains fully trainable in an end-to-end manner. The challenge is to capture complementary information over the dynamics between consecutive frames, which is the key information extracted by state-of-the-art GCN techniques. Moreover, the proposed strategy can be easily integrated in the existing GCN-based methods, which we also regard positively. Our experiments were carried out in well known action recognition datasets and enabled to conclude that REGINA contributes for solid improvements in performance when incorporated to other GCN-based approaches, without any other adjustment regarding the original method."

- id: "HealthcareMonitoring"
  title: "Computer Vision & Biometrics in Healthcare Monitoring, Diagnosis and Treatment"
  authors: "Michele Nappi, Sambit Bakshi, Hugo Proença, Vittorio Murino"
  venue: "Elsevier Computer Vision and Image Understanding"
  year: 2021
  status: "published"
  publication_type: "special issue"
  tags:
    - "Computer Vision"
    - "Biometrics"
    - "Healthcare Monitoring"
    - "Diagnosis"

- id: "GANFingerprints2"
  title: "GAN Fingerprints in Face Image Synthesis"
  authors: "João C. Neves, Ruben Tolosana, Ruben Vera-Rodriguez, Vasco Lopes, Hugo Proença, Julian Fierrez"
  venue: "Springer-Verlag book series, Lecture Notes on Electrical Engineering"
  year: 2022
  status: "published"
  publication_type: "book chapter"
  doi: "10.1109/JSTSP.2020.3007250"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/paper-130.png"
  thumbnail: "/assets/publications/paper-130.png"
  tags:
    - "GAN Fingerprints"
    - "Face Image Synthesis"
    - "Fake Detection"
  abstract: "The availability of large-scale facial databases, together with the remarkable progresses of deep learning technologies, in particular Generative Adversarial Networks (GANs), have led to the generation of extremely realistic fake facial content, raising obvious concerns about the potential for misuse. Such concerns have fostered the research on manipulation detection methods that, contrary to humans, have already achieved astonishing results in various scenarios. This chapter is focused on the analysis of GAN fingerprints in face image synthesis. In particular, it covers an in-depth literature analysis of state-of-the-art detection approaches for the entire face synthesis manipulation. It also describes a recent approach to spoof fake detectors based on a GAN-fingerprint Removal autoencoder (GANprintR). A thorough experimental framework is included in the chapter, highlighting (i) the potential of GANprintR to spoof fake detectors, and (ii) the poor generalisation capability of current fake detectors."

- id: "GenderWild"
  title: "Is Gender \"In-the-Wild'' Inference Really a Solved Problem?"
  authors: "Tiago Roxo, Hugo Proença"
  venue: "IEEE Transactions on Biometrics, Behaviour and Identity Science"
  year: 2021
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TBIOM.2021.3100926"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/TBIOM_Tiago_Roxo.pdf"
  thumbnail: "/assets/publications/tbiom.jpg"
  tags:
    - "Gender Inference"
    - "Soft Biometrics"
    - "Wild Conditions"
    - "Feature Analysis"
  abstract: "Soft biometrics analysis is seen as an important research topic, given its relevance to various applications. However, even though it is frequently seen as a solved task, it can still be very hard to perform in wild conditions, under varying image conditions, uncooperative poses, and occlusions. Considering the gender trait as our topic of study, we report an extensive analysis of the feasibility of its inference regarding image (resolution, luminosity, and blurriness) and subject-based features (face and body keypoints confidence). Using three state-of-the-art datasets (PETA, PA-100K, RAP) and five Person Attribute Recognition models, we correlate feature analysis with gender inference accuracy using the Shapley value, enabling us to perceive the importance of each image/subject-based feature. Furthermore, we analyze face-based gender inference and assess the pose effect on it. Our results suggest that: 1) image-based features are more influential for low-quality data; 2) an increase in image quality translates into higher subject-based feature importance; 3) face-based gender inference accuracy correlates with image quality increase; and 4) subjects' frontal pose promotes an implicit attention towards the face. The reported results are seen as a basis for subsequent developments of inference approaches in uncontrolled outdoor environments, which typically correspond to visual surveillance conditions."

- id: "SuperResolutionSDE"
  title: "Super-resolution Using Stochastic Differential Equations and Potential Applications on Face Recognition"
  authors: "Marcelo Santos, Rayson Laroca, Rafael O. Ribeiro, João C. Neves, Hugo Proença, David Menotti"
  venue: "Proceedings of the 35th Conference on Graphics, Patterns and Images - SIBGRAPI 2022"
  year: 2022
  status: "published"
  publication_type: "conference"
  doi: "10.1109/SIBGRAPI.2022.000xx"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/sibgrapi_22.pdf"
  thumbnail: "/assets/publications/paper-137.png"
  tags:
    - "Super-resolution"
    - "Stochastic Differential Equations"
    - "Diffusion Models"
    - "Face Recognition"
    - "Image Enhancement"
  abstract: "Diffusion models have proven effective for various applications such as images, audio and graphs generation. Other important applications are image super-resolution and the solution of inverse problems. More recently, some works have used stochastic differential equations (SDEs) to generalize diffusion models to continuous time. In this work, we introduce SDE to generate super-resolution face images. To the best of our knowledge, this is the first time SDEs have been used for such an application. The proposed method provides promising peak signal-to-noise ratio (PSNR), structural similarity index measure (SSIM) and consistency than existing super-resolution methods based on diffusion models. We also demonstrated the potential applications of this method for the face recognition task. For this purpose, a generic facial feature extractor is used to compare the super-resolution images with the ground truth and superior results were obtained compared with other methods."

- id: "DeepGabor"
  title: "DeepGabor: A Learning-Based Framework to Augment IrisCodes Permanence"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2022.3214098"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/tifs_deep_gabor_22.pdf"
  thumbnail: "/assets/publications/paper-139.png"
  tags:
    - "Iris Recognition"
    - "IrisCode"
    - "Deep Learning"
    - "Gabor Filters"
    - "Biometrics"
  abstract: "For over three decades, the Gabor-based IrisCode approach has been acknowledged as the gold standard for iris recognition, mainly due to the high entropy and binary nature sgn() of its signatures. This method is highly effective in large scale environments (e.g., national ID applications), where millions of comparisons per second are required. However, it is known that non-linear deformations in the iris texture, with fibers vanishing/appearing in response to pupil dilation/contraction, often flip the signature coefficients, being the main cause for the increase of false rejections. This paper addresses this problem, describing a customised Deep Learning (DL) framework that: 1) virtually emulates the IrisCode feature encoding phase; while also 2) detects the deformations in the iris texture that may lead to bit flipping, and autonomously adapts the filter configurations for such cases. The proposed DL architecture seamlessly integrates the Gabor kernels that extract the IrisCode and a multi-scale texture analyzer, from where the biometric signatures yield. In this sense, it can be seen as an adaptive encoder that is fully compatible to the IrisCode approach, while increasing the permanence of the signatures. The experiments were conducted in two well known datasets (CASIA-Iris-Lamp and CASIA-Iris-Thousand) and showed a notorious decrease of the mean/standard deviation values of the genuines distribution, at expenses of only a marginal deterioration in the impostors scores. The resulting decision environments consistently reduce the levels of false rejections with respect to the baseline for most operating levels (e.g., over 50% at 1e−3 FAR values). The source code of the DeepGabor encoder is available at: https://github.com/hugomcp/DeepGabor."


- id: "RealTimeImageDetection"
  title: "Real-time Image Detection for Edge Device: A Peach Fruit Detection Application"
  authors: "Eduardo Assunção, Pedro D. Gaspar, Khadijeh Alibabaei, Maria P. Simões, Hugo Proença, Vasco N. G. J. Soares, João M. L. P. Caldeira"
  venue: "MDPI Future Internet"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.3390/fi14110323"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/mdpi_future_internet.pdf"
  thumbnail: "/assets/publications/paper-140.png"
  tags:
    - "Edge Computing"
    - "Fruit Detection"
    - "Precision Agriculture"
    - "Tensor Processing Unit"
    - "Real-time Detection"
  abstract: "Within the scope of precision agriculture, many applications have been developed to support decision-making and yield enhancement. Fruit detection has attracted considerable attention from researchers, and can be used offline. In contrast, some applications, such as robot vision in orchards, require computer vision models to run on edge devices while performing inference at high speed. In this area, most modern applications use an integrated graphics processing unit (GPU). In this work, we propose to use a Tensor Processing Unit (TPU) accelerator with the Raspberry Pi target device and the state-of-the-art, lightweight, and hardware-aware MobileDet detector model. Our contribution is to extend the possibilities of using accelerators (TPU) for edge devices in precision agriculture. The proposed method was evaluated in a novel dataset of peaches with three cultivars, which will be made available for further studies. The model achieved an average precision (AP) of 88.2% and a performance of 19.84 frame per second (FPS) at an image size of 640 × 480. The results obtained show that the TPU accelerator can be an excellent alternative for processing on the edge in precision agriculture."

- id: "SIBGRAPI2021"
  title: "Special issue on the Conference on Graphics, Patterns and Images - SIBGRAPI 2021"
  authors: "Hugo Proença, David Menotti, Afonso Paiva, Gladimir Baranoski"
  venue: "Elsevier Pattern Recognition Letters"
  year: 2023
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.patrec.2022.12.002"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/PRL_SIBGRAPI21.pdf"
  thumbnail: "/assets/publications/paper-141.png"
  tags:
    - "Special Issue"
    - "Graphics"
    - "Pattern Recognition"
    - "Image Processing"
    - "Computer Vision"
  abstract: ""

- id: "VisualTextualExplainability"
  title: "Visual and Textual Explainability for a Biometric Verification System based on Piecewise Facial Attribute Analysis"
  authors: "Lucia Cascone, Chiara Pero, Hugo Proença"
  venue: "Elsevier Image and Vision Computing"
  year: 2023
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.imavis.2023.104645"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/IVC_Lucia_Chiara.pdf"
  thumbnail: "/assets/publications/paper-142.png"
  tags:
    - "Explainable AI"
    - "Biometric Verification"
    - "Facial Attributes"
    - "Machine Learning"
    - "Image-Text Mapping"
  abstract: "The decisions behind the mechanics of a biometric verification system based on Machine Learning (ML) are difficult to comprehend. Although there is now well-established research in various fields of application, such as health or justice, the use of ML-based methods is accompanied by a lack of confidence that results in their limited use. The explainability of a ML system and the comprehension of what lies behind its prediction is one of the numerous characteristics that define 'trust' in these systems. Over the years, face-based biometric authentication has been the subject of extensive research in both academia and industry. However, existing biometric authentication systems still have problems regarding accuracy, robustness and, explainability. Still lacking in the literature is a comprehensive examination of the use of post-hoc explainability techniques for such systems. Cognitive neuroscience has always been interested in the method by which people perceive faces; local elements such as the nose, eyes, and mouth are critical to the perception and recognition of a face. In this work, starting from this assumption, we propose a framework of visual and textual explainability based on the parts of a face by analyzing them with respect to the facial attributes reported in the CelebA dataset. The primary objective is to be able to explain why two pictures of different subjects are distinct. This is done by sinthesizing pairs of images that illustrate how dissimilar the various parts of the face under investigation are and incisive and direct textual explanations of the distinguishing features are generated. A further study analyzes an interpretable mapping between the semantic space of the text and the space of the image."

- id: "AdaptiveSpatialTransformation"
  title: "Adaptive Spatial Transformation Networks for Periocular Recognition"
  authors: "Diana Borza, Ehsan Yaghoubi, Simone Frintrop, Hugo Proença"
  venue: "MDPI Sensors"
  year: 2023
  status: "published"
  publication_type: "journal"
  doi: "10.3390/s23052456"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Diana_Ehsan_Sensors_2023.pdf"
  thumbnail: "/assets/publications/paper-143.png"
  tags:
    - "Periocular Recognition"
    - "Deep Learning"
    - "Spatial Transformation"
    - "COVID-19"
    - "Biometrics"
  abstract: "Periocular recognition has emerged as a particularly valuable biometric identification method in challenging scenarios, where the acquired data is of poor quality. In this context, partially occluded faces (e.g., due to COVID-19 masks or in VR-applications where the face is not visible due to a head-mounted display) are particularly concerning, where facial recognition cannot be applicable. This work presents a periocular recognition framework based on deep learning architectures, that autonomously localize and analyze the most important areas in the periocular region, for recognition purposes. The main idea is to derive several parallel local branches from a neural network architecture, which in a semi-supervised manner learns the most discriminative areas in the feature map and solves the identification problem solely upon the corresponding cues. Here, each local branch learns a transformation matrix that allows for basic geometrical transformations (cropping and scaling), which is used to select a region of interest in the feature map, further analysed by a set of shared convolutional layers. Finally, the information extracted by the local branches and the main global branch is fused together for recognition. The experiments carried out on the challenging UBIRIS-v2 benchmark show that by integrating the proposed framework with various ResNet architectures, we consistently obtain an improvement in mAP of more than 4% over the 'vanilla' architecture. In addition, extensive ablation studies were performed to better understand the behavior of the network and how the spatial transformation and the local branches influence the overall performance of the model. The proposed method can be easily adapted to other computer vision problems, which is also regarded as one of its strengths."

- id: "WSRR"
  title: "WSRR: Weighted Rank-Relevance Sampling for Dense Text Retrieval"
  authors: "Kailash Hambarde"
  venue: "Proceedings of the 7th International Conference on Information and Communication Technology for Intelligent Systems"
  year: 2023
  status: "published"
  publication_type: "conference"
  doi: ""
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Hambarde_ICTIS_2023.pdf"
  thumbnail: "/assets/publications/paper-144.png"
  tags:
    - "Text Retrieval"
    - "Negative Sampling"
    - "Contrastive Learning"
    - "Information Retrieval"
    - "Natural Language Processing"
  abstract: "As in many other domains based in the contrastive learning paradigm, negative sampling is seen as a particular sensitive problem for appropriately training dense text retrieval models. For most cases, it is accepted that the existing techniques often suffer from the problem of uninformative or false negatives, which reduces the computational effectiveness of the learning phase and even reduces the probability of convergence of the whole process. Upon these limitations, in this paper we present a new approach for dense text retrieval (termed WRRS: Weighted Rank-Relevance Sampling) that addresses the limitations of current negative sampling strategies. WRRS assigns probabilities to negative samples based on their relevance scores and ranks, which consistently leads to improvements in retrieval performance. Under this perspective, WRRS offers a solution to uninformative or false negatives in traditional negative sampling techniques, which is seen as a valuable contribution to the field. Our empirical evaluation was carried out against the AR2 baseline on two well known datasets (NQ and MS Doc), pointing for consistent improvements over the SOTA performance."

- id: "SyPer"
  title: "SyPer: Synthetic Periocular Data for Quantized light-weight Recognition in the NIR and Visible Domains"
  authors: "Jan Niklas Kolf, Jurek Elliesen, Fadi Boutros, Hugo Proença, Naser Damer"
  venue: "Elsevier Image and Vision Computing"
  year: 2023
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.imavis.2023.104692"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Naser_IVC_2023.pdf"
  thumbnail: "/assets/publications/paper-145.png"
  tags:
    - "Periocular Recognition"
    - "Synthetic Data"
    - "Model Quantization"
    - "Near-Infrared"
    - "Edge Computing"
  abstract: "Deep-learning based periocular recognition systems typically use overparameterized deep neural networks associated with high computational costs and memory requirements. This is especially problematic for mobile and embedded devices in shared resource environments. To perform model quantization for lightweight periocular recognition in a privacy-aware manner, we propose and release SyPer, a synthetic dataset and generation model of periocular images. To enable this, we propose to perform the knowledge transfer in the quantization process on the embedding level and thus not identity-labeled data. This does not only allow the use of synthetic data for quantization, but it also successfully allows to perform the quantization on different domains to additionally boost the performance in new domains. In a variety of experiments on a diverse set of model backbones, we demonstrate the ability to build compact and accurate models through an embedding-level knowledge transfer using synthetic data. We also demonstrate very successfully the use of embedding-level knowledge transfer for near-infrared quantized models towards accurate and efficient periocular recognition on near-infrared images. The SyPer dataset, together with the evaluation protocol, the training code, and model checkpoints are made publicly available at https://github.com/jankolf/SyPe."

- id: "ATOM"
  title: "ATOM: Self-supervised Human Action Recognition using Atomic Motion Representation Learning"
  authors: "Bruno Degardin, Vasco Lopes, Hugo Proença"
  venue: "Elsevier Image and Vision Computing"
  year: 2023
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.imavis.2023.104750"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Degardin_IVC_ATOM_2023.pdf"
  thumbnail: "/assets/publications/paper-146.png"
  tags:
    - "Self-supervised Learning"
    - "Human Action Recognition"
    - "Skeleton-based Data"
    - "Motion Representation"
    - "Transfer Learning"
  abstract: "Self-supervised learning (SSL) is a promising method for gaining perception and common sense from unlabelled data. Existing approaches to analyzing human body skeletons address the problem similar to SSL models for image and video understanding, but pixel data is far more challenging than coordinates. This paper presents ATOM, an SSL model designed for skeleton-based data analysis. Unlike video-based SSL approaches, ATOM leverages atomic movements within skeleton actions to achieve a more fine-grained representation. The proposed architecture predicts the action order at the frame level, leading to improved perceptions and representations of each action. ATOM outperforms state-of-the-art approaches in two well-known datasets (NTU RGB+D and NTU-120 RGB+D), and its weight transferability enables performance improvements on supervised and semi-supervised tasks, up to 4.4% (3.3% p.p.) and 14.1% (6.3% p.p.), respectively, in Top-1 Accuracy."

- id: "InformationRetrievalAdvances"
  title: "Information Retrieval: Recent Advances and Beyond"
  authors: "Kailash Hambarde, Hugo Proença"
  venue: "IEEE Access"
  year: 2023
  status: "published"
  publication_type: "journal"
  doi: "10.1109/ACCESS.2023.3295776"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Survey_Information_Retrieval_2023.pdf"
  thumbnail: "/assets/publications/paper-148.png"
  tags:
    - "Information Retrieval"
    - "Survey"
    - "Literature Review"
    - "Search Models"
    - "Information Processing"
  abstract: "This paper provides an extensive and thorough overview of the models and techniques utilized in the first and second stages of the typical information retrieval processing chain. Our discussion encompasses the current state-of-the-art models, covering a wide range of methods and approaches in the field of information retrieval. We delve into the historical development of these models, analyze the key advancements and breakthroughs, and address the challenges and limitations faced by researchers and practitioners in the domain. By offering a comprehensive understanding of the field, this survey is a valuable resource for researchers, practitioners, and newcomers to the information retrieval domain, fostering knowledge growth, innovation, and the development of novel ideas and techniques."

- id: "AudioAnomalySpeech"
  title: "On Exploring Audio Anomaly in Speech"
  authors: "Tiago Roxo, Joana C. Costa, Pedro Inácio, Hugo Proença"
  venue: "Proceedings of the 2023 IEEE International Workshop on Information Forensics and Security (WIFS 2023)"
  year: 2023
  status: "published"
  publication_type: "conference"
  doi: "10.1109/WIFS58808.2023.10374734"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Tiago_WIFS_23.pdf"
  thumbnail: "/assets/publications/paper-150.png"
  tags:
    - "Audio Anomaly"
    - "Speech Analysis"
    - "Active Speaker Detection"
    - "Anomaly Detection"
    - "Anomaly Localization"
  abstract: "Existing anomaly detection works mainly focus on abnormal activities in image and video settings, while assessing audio manipulation, namely the presence of anomalous audio in speech, has not yet been explored. To overcome this limitation, we propose a setup in the context of Active Speaker Detection (ASD) by defining a methodology to perceive audio anomaly, assessing the performance of anomaly models, and establishing setup variations. This way, we evaluate models performance in identifying the presence of anomalies (detection) and localizing the timeframe where they occur (localization). To complement anomaly detection, we propose Anomaly Score (AS), a metric to assess anomaly localization that balances precision and mis-localization. Given the sequential nature of audio, we explore the performance of a density-based approach for video anomaly (CPD) and recurrent models (LSTM and RNN) on detecting and localizing audio anomalies. The results show that: 1) anomaly inclusion in talking portions increases models resilience toward anomaly localization; 2) CPD is superior in anomaly detection, while recurrent models perform better in anomaly localization; 3) anomaly with distinctive audio benefits precise anomaly localization; and 4) using original ASD audio is overall the best approach, relative to other processing approaches. The setup and experiments of this work serve as a baseline for future works on speech anomaly detection."

- id: "SuperResolutionDiffusion"
  title: "Defying Limits: Super-Resolution Refinement with Diffusion Guidance"
  authors: "Marcelo Santos, João C. Neves, Hugo Proença, David Menotti"
  venue: "Proceedings of the 19th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP 2024)"
  year: 2024
  status: "published"
  publication_type: "conference"
  doi: ""
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Marcelo_VISAPP_24.pdf"
  thumbnail: "/assets/publications/paper-149.png"
  tags:
    - "Super-Resolution"
    - "Diffusion Models"
    - "Facial Recognition"
    - "Stochastic Differential Equation"
    - "Image Enhancement"
  abstract: "Facial recognition has become widely applied across diverse environments. However, in unconstrained settings, face images often suffer from undesired effects such as low resolution, leading to a notable decline in recognition performance. The use of super-resolution (SR) algorithms is effective in supporting facial recognition in these cases. In the context of SR and image synthesis, diffusion models have consistently exhibited superior results. Moreover, diffusion models, as a whole, have garnered significant attention in recent years, surpassing the performance of traditional Generative Adversarial Networks (GANs) and achieving remarkable outcomes across various tasks. Additionally, by combining diffusion models with the gradient of a classifier, it becomes possible to generate data from a specific class. In this paper, we employ a diffusion model based on a Stochastic Differential Equation (SDE) to generate refined SR face images with an upsampling factor of 8× and 16× and address the challenges posed by unconstrained environments in facial recognition. The main contribution of our work lies in utilizing the gradient from a classifier to refine the SR results. This is performed by using soft biometrics such as gender and facial features to guide the SR process. To the best of our knowledge, this is the first time classifier guidance has been used to refine SR results of images from surveillance cameras. We conducted experiments on the CelebA and Quis-Campi datasets to evaluate our approach. The refined SR images exhibit enhanced details and improved visual quality. The quantitative performance is assessed using commonly used SR metrics as well as metrics from face recognition.The experimental results demonstrate the superior performance of our SR algorithm, surpassing other existing methods when applied to images from unconstrained scenarios."

- id: "ManufacturingEnergyEfficiency"
  title: "Advancing Manufacturing Energy Efficiency: The Role of AI and Web-Based Tools"
  authors: "Asmae Lamsaf, Pranita Samale, Hugo Proença, João C. Neves, Kailash Hambarde"
  venue: "Proceedings of the 2024 International Conference on Emerging Smart Computing & Informatics (ESCI 2024)"
  year: 2024
  status: "published"
  publication_type: "conference"
  doi: ""
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Asmae_ESCI_24.pdf"
  thumbnail: "/assets/publications/paper-151.png"
  tags:
    - "Manufacturing"
    - "Energy Efficiency"
    - "Artificial Intelligence"
    - "Web-Based Tools"
    - "Sustainability"
  abstract: "This paper introduces a web-based application that simplifies the data analysis processing chain by automating the analysis of arbitrary variables. In particular, our application allows users to easily upload and process data for the analysis of a target variable by exploiting machine learning and evolutionary algorithms for precise forecasting and optimization. We demonstrate the system's efficacy using a dataset from a textile company, where our application successfully predicted the target variables with a high level of R-squared of 0.78, using the best regression model. These results not only highlight its real-world applicability but also played an important role in enhancing sustainable manufacturing practices. This innovative application offers a significant step towards sustainable and efficient manufacturing, addressing the challenges of high energy consumption and environmental impact in the industry."



- id: "HumanReidentification"
  title: "Image-Based Human Re-identification: Which Covariates are Actually (the most) Important?"
  authors: "Kailash Hambarde, Hugo Proença"
  venue: "Elsevier Image and Vision Computing"
  year: 2024
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.imavis.2024.104917"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Kailash_IVC_2024.pdf"
  thumbnail: "/assets/publications/paper-152.png"
  tags:
    - "Human Re-identification"
    - "Biometric Menagerie"
    - "Covariates"
    - "Visual Surveillance"
    - "Bias Analysis"
  abstract: "Human re-identification (re-ID) is nowadays among the most popular topics in computer vision, due to the increasing importance given to safety/security in modern societies. Being expected to sun in totally uncontrolled data acquisition settings (e.g., visual surveillance) automated re-ID not only depends on various factors that may occur in non-controlled data acquisition settings, but - most importantly - performance varies with respect to different subject features (e.g., gender, height, ethnicity, clothing, and action being performed), which may result in highly biased and undesirable automata. While many efforts have been putted in increase the robustness of identification to uncontrolled settings, a systematic assessment of the actual variations in performance with respect to each subject feature remains to be done. Accordingly, the contributions of this paper are threefold: 1) we report the correlation between the performance of three state-of-the-art re-ID models and different subject features; 2) we discuss the most concerning features and report valuable insights about the roles of the various features in re-ID performance, which can be used to develop more effective and unbiased re-ID systems; and 3) we leverage the concept of biometric menagerie, in order to identify the groups of individuals that typically fall into the most common menagerie families (e.g., goats, lambs, and wolves). Our findings not only contribute to a better understanding of the factors affecting re-ID performance, but also may offer practical guidance for researchers and practitioners concerned on human re-identification development."


- id: "EmailClassification"
  title: "A novel and secured email classification and emotion detection using hybrid deep neural network"
  authors: "Parthiban Krishnamoorthya, Mithileysh Sathiyanarayanan, Hugo Proença"
  venue: "International Journal of Cognitive Computing in Engineering"
  year: 2024
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.ijcce.2024.01.002"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Krishnamoorthya_2024.pdf"
  thumbnail: "/assets/publications/paper-153.png"
  tags:
    - "Email Classification"
    - "Emotion Detection"
    - "Deep Neural Networks"
    - "Cloud Security"
    - "Hybrid Encryption"
  abstract: "Compared to other social media data, email data differs from it in various topic-specific ways, including extensive replies, formal language, significant length disparities, high levels of anomalies, and indirect linkages. In this paper, the creation of a potent and computationally effective classifier to categorize spam and ham email documents is proposed. To assess and validate spam texts, this paper employs a variety of data mining-based classification approaches. On the benchmark Enron dataset, which is open to the public, tests were run. The final 7 Enron datasets were created by combining the six different types of Enron datasets that we had acquired. We preprocess the dataset at an early stage to exclude any useless phrases. This method falls under several categories, including Logistic Regression (LR), Convolutional Neural Networks (CNN), Random Forests (RF), Recurrent Neural Networks (RNN), Long Short-Term Memory (LSTM), and suggested Deep Neural Networks (DNN). Using Bidirectional Long Short-Term Memory (BiLSTM), email documents may be screened for spam and labeled as such. In performance comparisons, DNN-BiLSTM outperforms other classifiers in terms of accuracy on all seven Enron datasets. In comparison to other machine learning classifiers, the findings demonstrate that DNN- BiLSTM and Convolutional Neural Networks can categorize spam with 96.39 % and 98.69 % accuracy, respectively. The report also covers the dangers of managing cloud data and the security problems that might occur. To safeguard data in the cloud while maintaining privacy, hybrid encryption is examined in this white paper. In the AES-Rabit hybrid encryption system, the symmetric session key exchange-based Rabit technique is combined with the benefits of the AES algorithm for faster data encryption."

- id: "AdversarialAttacksSurvey"
  title: "How Deep Learning Sees the World: A Survey on Adversarial Attacks & Defenses"
  authors: "Joana C. Costa, Tiago Roxo, Hugo Proença, Pedro Inácio"
  venue: "IEEE Access"
  year: 2024
  status: "published"
  publication_type: "journal"
  doi: "10.1109/ACCESS.2024.3395118"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/joana_survey_access_2024.pdf"
  thumbnail: "/assets/publications/paper-156.png"
  tags:
    - "Deep Learning"
    - "Adversarial Attacks"
    - "Adversarial Defenses"
    - "Neural Networks"
    - "Vision Transformers"
  abstract: "Deep Learning is currently used to perform multiple tasks, such as object recognition, face recognition, and natural language processing. However, Deep Neural Networks (DNNs) are vulnerable to perturbations that alter the network prediction (adversarial examples), raising concerns regarding its usage in critical areas, such as self-driving vehicles, malware detection, and healthcare. This paper compiles the most recent adversarial attacks, grouped by the attacker capacity, and modern defenses clustered by protection strategies. We also present the new advances regarding Vision Transformers, summarize the datasets and metrics used in the context of adversarial settings, and compare the state-of-the-art results under different attacks, finishing with the proposal of possible directions for future works."


- id: "PeriocularBiometrics"
  title: "Periocular Biometrics: A Modality for Unconstrained Scenarios"
  authors: "Fernando Alonso-Fernandez, Josef Bigun, Julian Fierrez, Naser Damer, Hugo Proença, Arun Ross"
  venue: "Computer"
  year: 2023
  status: "published"
  publication_type: "journal"
  doi: "10.1109/MC.2023.3298095"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Periocular_Computer_2023.pdf"
  thumbnail: "/assets/publications/paper-147.png"
  tags:
    - "Periocular Biometrics"
    - "Unconstrained Recognition"
    - "Ocular Region"
    - "Biometric Identification"
    - "COVID-19"
  abstract: "Periocular refers to the externally visible region of the face that surrounds the eye socket. This feature-rich area can provide accurate identification in unconstrained or uncooperative scenarios, where the iris or face modalities may not offer sufficient biometric cues due to factors such as partial occlusion or high subject-to-camera distance. The COVID-19 pandemic has further highlighted its importance, as the ocular region remained the only visible facial area even in controlled settings due to the widespread use of masks. This paper discusses the state of the art in periocular biometrics, presenting an overall framework encompassing its most significant research aspects, which include: (a) ocular definition, acquisition, and detection; (b) identity recognition, including combination with other modalities and use of various spectra; and (c) ocular soft-biometric analysis. Finally, we conclude by addressing current challenges and proposing future directions."

- id: "FabricDefectDataset"
  title: "A Novel Dataset for Fabric Defect Detection: Bridging Gaps in Anomaly Detection"
  authors: "Rui Carrilho, Kailash Hambarde, Hugo Proença"
  venue: "MDPI Applied Sciences"
  year: 2024
  status: "published"
  publication_type: "journal"
  doi: "10.3390/app14125298"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/carrilho_as_2024.pdf"
  thumbnail: "/assets/publications/paper-158.png"
  tags:
    - "Fabric Defect Detection"
    - "Anomaly Detection"
    - "Dataset"
    - "Textile Industry"
    - "Deep Learning"
  abstract: "Detecting anomalies in texture has become a significant concern across various industrial processes. One prevalent application of this is in inspecting patterned textures, especially in the domain of fabric defect detection, which is a commonly encountered scenario. This task entails dealing with a wide array of colours and textile varieties, spanning a broad spectrum of fabrics. Due to the extensive diversity in colours, textures, and defect characteristics, fabric defect detection presents a complex and formidable challenge within the realm of patterned texture inspection. While recent trends have seen a rise in the utilization of deep learning methods for anomaly detection, there still exist notable gaps in this field. In this paper, we introduce a novel dataset comprising a diverse selection of fabrics and defects from a textile company based in Portugal. Our contributions encompass the provision of this unique dataset and the evaluation of state-of-the-art (SOTA) methods performance on our dataset."

- id: "FabricDefectDetectionSurvey"
  title: "Towards Automated Fabric Defect Detection: A Survey of Recent Computer Vision Approaches"
  authors: "Rui Carrilho, Ehsan Yaghoubi, José Lindo, Kailash Hambarde, Hugo Proença"
  venue: "MDPI Electronics"
  year: 2024
  status: "published"
  publication_type: "journal"
  doi: "10.3390/electronics13183728"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/carrilho_electronics_2024.pdf"
  thumbnail: "/assets/publications/paper-161.png"
  tags:
    - "Fabric Defect Detection"
    - "Computer Vision"
    - "Textile Industry"
    - "Survey"
    - "Machine Learning"
  abstract: "Defect detection is a crucial part of the pipeline in many industries. In the textile industry, it is especially important, as it will affect the quality and price of the final product. However, it is mostly performed by human agents, who have been reported to have poor performance, along with a costly and time-consuming training process. As such, methods to automate the process have been increasingly explored throughout the last 20 years. While there are many traditional approaches to this problem, with the advent of deep learning, machine learning-based approaches now constitute the majority of all possible approaches. Other articles have explored traditional approaches and machine learning approaches in a more general way, detailing their evolution throughout time. In this review, we will summarize the most important advancements of the last 5 years, and focus mostly on machine learning-based approaches. We also outline the most promising avenues of research in the future."


- id: "VideoAnomalyDetection"
  title: "Video Anomaly Detection in Overlapping Data: The More Cameras, the Better?"
  authors: "Silas Santiago, José Everardo Maia, Hugo Proença"
  venue: "IEEE International Joint Conference on Biometrics (IJCB'24)"
  year: 2024
  status: "in press"
  publication_type: "conference"
  doi: ""
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/henrique_ijcb_2024.pdf"
  thumbnail: "/assets/publications/paper-160.png"
  tags:
    - "Video Anomaly Detection"
    - "Multi-camera Systems"
    - "Weakly Supervised Learning"
    - "Surveillance"
  abstract: "Video anomaly detection (VAD) has been densely explored in the last few years, mostly in single-camera scenarios. Despite significant advancements in this field, effectiveness is still seriously compromised in challenging environments (e.g., varying lighting conditions, under partial occlusions, and in crowded environments). For the sake of affordable data annotation, the most relevant methods assume the weakly supervised paradigm, where the label is available only at the video level (WS-VAD). Also, these methods are conventionally designed for single-camera mode and do not consider the multi-view information yielded from overlapping surveillance cameras, which is very common in practical scenarios. In this work, we started by systematically evaluating the WS-VAD performance that can be attained when different camera combinations are used as data sources. Interestingly, we observed that the rule 'the more cameras, the better' should not be assumed, as there were always particular subsets of cameras that consistently outperformed the remaining configurations. Upon these conclusions, we present a semi-automated procedure to identify the optimal camera sources based on the image features/characteristics (distance, pose, and lighting) each one is capturing. Extensive experiments were carried out in three overlapping multi-camera datasets, which suggest that 1) multi-camera schemes consistently outperform single-camera methods and - most interestingly - 2) the correlation between the data acquired by the different cameras severely impacts performance, turning the selection of cameras a crucial step in VAD. Our findings open an intriguing research topic about methods/algorithms that filter out/select the camera sources we should use in overlapping camera scenarios."


- id: "ZeroShotInterpretableHumanRecognition"
  title: "Towards Zero-Shot Interpretable Human Recognition: A 2D-3D Registration Framework"
  authors: "Henrique Jesus, Hugo Proença"
  venue: "IEEE International Joint Conference on Biometrics (IJCB'24)"
  year: 2024
  status: "in press"
  publication_type: "conference"
  doi: ""
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/henrique_ijcb_2024.pdf"
  thumbnail: "/assets/publications/paper-159.png"
  tags:
    - "Zero-Shot Learning"
    - "Human Recognition"
    - "2D-3D Registration"
    - "Interpretability"
    - "Synthetic Data"
  abstract: "Large vision models based in deep learning architectures have been consistently advancing the state-of-the-art in biometric recognition. However, three weaknesses are commonly reported for such kind of approaches: 1) their extreme demands in terms of learning data; 2) the difficulties in generalising between different domains; and 3) the lack of interpretability/explainability, with biometrics being of particular interest, as it is important to provide evidence able to be used for forensics/legal purposes (e.g., in courts). To the best of our knowledge, this paper describes the first recognition framework/strategy that aims at addressing the three weaknesses simultaneously. At first, it relies exclusively in synthetic samples for learning purposes. Instead of requiring a large amount and variety of samples for each subject, the idea is to exclusively enroll a 3D point cloud per identity. Then, using generative strategies, we synthesize a very large (potentially infinite) number of samples, containing all the desired covariates (poses, clothing, distances, perspectives, lighting, occlusions,...). Upon the synthesizing method used, it is possible to adapt precisely to different kind of domains, which accounts for generalization purposes. Such data are then used to learn a model that performs local registration between image pairs, establishing positive correspondences between body parts that are the key, not only to recognition (according to cardinality and distribution), but also to provide an interpretable description of the response (e.g.: 'both samples are from the same person, as they have similar facial shape, hair color and legs thickness')."




- id: "SqueezeExplanation"
  title: "How to Squeeze An Explanation Out of Your Model"
  authors: "Tiago Roxo, Joana C. Costa, Pedro Inácio, Hugo Proença"
  venue: "4th Workshop On Explainable & Interpretable Artificial Intelligence for Biometrics (xAI4Biometrics), European Conference on Computer Vision (ECCV)"
  year: 2024
  status: "published"
  publication_type: "conference"
  doi: ""
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/tiago_eccvw_2024.pdf"
  thumbnail: "/assets/publications/paper-163.png"
  tags:
    - "Interpretability"
    - "Explainable AI"
    - "Squeeze and Excitation"
    - "Biometrics"
    - "Attention Heatmaps"
  abstract: "Deep learning models are widely used nowadays for their reliability in performing various tasks. However, they do not typically provide the reasoning behind their decision, which is a significant drawback, particularly for more sensitive areas such as biometrics, security and healthcare. The most commonly used approaches to provide interpretability create visual attention heatmaps of regions of interest on an image based on models gradient backpropagation. Although this is a viable approach, current methods are targeted toward image settings and default/standard deep learning models, meaning that they require significant adaptations to work on video/multi-modal settings and custom architectures. This paper proposes an approach for interpretability that is model-agnostic, based on a novel use of the Squeeze and Excitation (SE) block that creates visual attention heatmaps. By including an SE block prior to the classification layer of any model, we are able to retrieve the most influential features via SE vector manipulation, one of the key components of the SE block. Our results show that this new SE-based interpretability can be applied to various models in image and video/multi-modal settings, namely biometrics of facial features with CelebA and behavioral biometrics using Active Speaker Detection datasets. Furthermore, our proposal does not compromise model performance toward the original task, and has competitive results with current interpretability approaches in state-of-the-art object datasets, highlighting its robustness to perform in varying data aside from the biometric context."

- id: "CuttingEdgeBiometrics"
  title: "Cutting-Edge Biometrics Research: Selected Best Papers From IJCB 2023"
  authors: "Anderson Rocha, Kevin Bowyer, Luisa Verdoliva, Zhen Lei, Hugo Proença"
  venue: "IEEE Transactions on Biometrics, Behaviour and Identity Science"
  year: 2024
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TBIOM.2024.3459108"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/IJCB2023_TBIOM.pdf"
  thumbnail: "/assets/publications/paper-164.png"
  tags:
    - "Biometrics"
    - "Special Issue"
    - "Research Overview"
    - "Conference Papers"
  abstract: "Welcome to the special issue of best-reviewed papers from the 2023 International Joint Conference on Biometrics (IJCB 2023), the premier forum for cutting-edge research and innovation in the field of biometrics. IJCB combines the previous two major biometrics conferences, the IEEE International Conference on Biometrics Theory, Applications, and Systems, and the IAPR International Conference on Biometrics. IJCB was made possible through a special agreement between the IEEE Biometrics Council and the IAPR Technical Committee on Biometrics (TC-4). As in the previous editions, the IJCB 2023 conference attracted high-quality submissions on a broad range of topics related to biometrics and supporting technologies. The conference received 199 papers, which underwent a rigorous peer-review procedure by the Program Chairs and 26 Area Chairs. More than 230 reviewers helped with the reviewing process. Ultimately, 72 (36.2%) of the highest-quality papers were accepted for presentation, out of which 30 (15.1%) were scheduled as orals and the remaining 42 (21.1%) as posters. Among the papers presented at the conference, selected authors of 13 papers with the best review ratings were invited to submit an extended version of their work to this special issue of the IEEE Transactions on Biometrics, Behavior, and Identity Science (TBIOM). The submissions in this special issue went through the normal peer review cycle at TBIOM, with revisions by the authors based on the reviews and a second round of reviews. One of the Guest Associate Editors recommended them for acceptance. We want to thank the authors and the reviewers for keeping to an ambitious timeline that enabled us to assemble this special issue promptly. We hope that you enjoy the papers in this special issue and that they will increase your interest in both IJCB and TBIOM."




- id: "CFC-ATE"
  title: "CFC-ATE: Causal Feature Construction via Average Treatment Effect"
  authors: "Asmae Lamsaf, João C. Neves, Hugo Proença"
  venue: "IEEE International Conference on Machine Learning and Applications (ICMLA'24)"
  year: 2024
  status: "in press"
  publication_type: "conference"
  doi: ""
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/asmae_icmla_2024.pdf"
  thumbnail: "/assets/publications/paper-162.png" #/assets/publications/paper-162.png
  tags:
    - "Causal Feature Construction"
    - "Average Treatment Effect"
    - "Dimensionality Reduction"
    - "Causal Discovery"
    - "Causal Inference"
  abstract: "Dimensionality reduction is a crucial step in data preprocessing, particularly for high-dimensional datasets, where the excessive number of features increases the risk of overfitting in machine learning models. Traditional dimensionality reduction methods rely on statistical associations or the relative position of the feature embeddings in the hyper-space to map original features to a compact subspace that preserves the most relevant information of the data. However, these methods fail to capture the causal relationships among variables during the transformation process, leading to a loss of structural coherence of the data in low-dimensional spaces. By employing causal discovery and causal inference, it is possible to simplify these problems, effectively merging critical features while reducing both complexity and dimensionality. Our paper introduces a novel approach, Causal Feature Construction via Average Treatment Effect (CFC-ATE), which leverages causal discovery and inference to create more interpretable and reliable features for predictive modeling. Our methodology consists of the following phases: i) leveraging the causal structure of data through the inference of the causal graph. ii) transforming features through the use of the average treatment effect conditioned on the causal structure of the data. The experiments on diverse real-world datasets and synthetic datasets demonstrate the effectiveness of CFC-ATE in improving model performance by comparing it with three methods of feature selection and three benchmark dimensionality reduction techniques."

- id: "WASD"
  title: "WASD: A Wilder Active Speaker Detection Dataset"
  authors: "Tiago Roxo, Joana C. Costa, Pedro Inácio, Hugo Proença"
  venue: "IEEE Transactions on Biometrics, Behaviour and Identity Science"
  year: 2024
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TBIOM.2024.3412821"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/tiago_wasd_2024.pdf"
  thumbnail: "/assets/publications/paper-157.png"
  tags:
    - "Active Speaker Detection"
    - "Dataset"
    - "Surveillance"
    - "Audio-Visual Processing"
    - "Body Features"
  abstract: "Current Active Speaker Detection (ASD) models achieve good results on cooperative settings with reliable face access using only sound and facial features, which is not suited for less constrained conditions. To demonstrate this limitation of current datasets, we propose a Wilder Active Speaker Detection (WASD) dataset, with increased difficulty by targeting the key components of current ASD: audio and face. Grouped into 5 categories, WASD contains incremental challenges for ASD with tactical impairment of audio and face data, and provides a new source for ASD via subject body annotations. To highlight the new challenges of WASD, we divide it into Easy (cooperative settings) and Hard (audio and/or face are specifically degraded) groups, and assess state-of-the-art models performance in WASD and in the most challenging available ASD dataset: AVA-ActiveSpeaker. The results show that: 1) AVAActiveSpeaker prepares models for cooperative settings but not wilder ones (surveillance); and 2) current ASD approaches can not reliably perform in wilder settings, even if trained with challenging data. To prove the importance of body for wild ASD, we propose a baseline that complements body with face and audio information that surpass state-of-the-art models, particularly in the most challenging settings. All contributions are available at https://github.com/Tiago-Roxo/WASD"

- id: "EarSketches"
  title: "Synthesizing Multilevel Abstraction Ear Sketches for Enhanced Biometric Recognition"
  authors: "David Freire-Obregón, Ziga Emersic, Blaz Meden, João C. Neves, Modesto Castrillon-Santana, Hugo Proença"
  venue: "Elsevier Image and Vision Computing"
  year: 2025
  status: "published"
  publication_type: "journal"
  doi: "10.1016/j.imavis.2025.105424"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Obregon_IVC.pdf"
  thumbnail: "/assets/publications/paper-166.png"
  tags:
    - "Biometric Recognition"
    - "Ear Sketches"
    - "Sketch Understanding"
    - "Triplet Loss"
    - "Abstraction Levels"
  abstract: "Sketch understanding is a significant challenge for general-purpose vision algorithms due to the sparse nature of this kind of drawing when compared to natural visual inputs and their semantic ambiguity, as sketches can evoke multiple interpretations simultaneously. Traditionally, research in sketch-based recognition has been predominantly focused on facial data, with particular emphasis on forensics/law enforcement applications. Our work takes a step forward by shifting the focus to ear images and considering the ''sketch-2-image'' matching problem with respect to the level of sketch abstraction. We introduce a novel adaptation of the well-known triplet loss, designed to fuse multiple abstraction levels of sketches during training. Here, the level of abstraction is inversely related to the number of strokes used to illustrate the ear, whereas the number of strokes used in the sketch is inversely correspondent to its abstraction level. Upon the experiments conducted in four well-known ear datasets, we observed a consistently higher performance of our proposal compared to the state-of-the-art. Finally, such results might easily be extended to other biometric traits, which is also positively regarded and raises an interesting research topic."

- id: "CausalityMLSurvey"
  title: "Causality, Machine Learning, and Feature Selection: A survey"
  authors: "Asmae Lamsaf, Rui Carrilho, João C. Neves, Hugo Proença"
  venue: "Sensors"
  year: 2025
  status: "published"
  publication_type: "journal"
  doi: "10.3390/s25082373"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Asmae_sensors_2025.pdf"
  thumbnail: "/assets/publications/paper-168.png"
  tags:
    - "Causality"
    - "Machine Learning"
    - "Feature Selection"
    - "Causal Discovery"
    - "Causal Inference"
  abstract: "Causality, which involves distinguishing between cause and effect, is essential for understanding complex relationships in data. This paper provides a review of causality in two key areas: causal discovery and causal inference. Causal discovery transforms data into graphical structures that illustrate how variables influence one another, while causal inference quantifies the impact of these variables on a target outcome. The models are more robust and accurate with the integration of causal reasoning into machine learning, improving applications like prediction and classification. We present various methods used in detecting causal relationships and how these can be applied in selecting or extracting relevant features, particularly from sensor datasets. When causality is used in feature selection, it supports applications like fault detection, anomaly detection, and predictive maintenance applications critical to the maintenance of complex systems. Traditional correlation-based methods of feature selection often overlook significant causal links, leading to incomplete insights. Our research highlights how integrating causality can be integrated and lead to stronger, deeper feature selection and ultimately enable better decision-making in machine learning tasks."

- id: "LaplacianQuantumGNN"
  title: "A Laplacian-based Quantum Graph Neural Network for Semi-Supervised Learning"
  authors: "Hamed Gholipour, Farid Bozorgnia, Kailash Hambarde, Hamzeh Mohammadigheymasi, Javier Mancilla, Andre Sequeira, João C. Neves, Hugo Proença"
  venue: "Springer Quantum Information Processing"
  year: 2025
  status: "published"
  publication_type: "journal"
  doi: "10.1007/s11128-025-04725-6"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Hamed_qip.pdf"
  thumbnail: "/assets/publications/paper-167.png"
  tags:
    - "Quantum Computing"
    - "Graph Neural Networks"
    - "Semi-Supervised Learning"
    - "Laplacian Methods"
    - "Entanglement Entropy"
  abstract: "Laplacian learning method is a well-established technique in classical graph-based semi-supervised learning, but its potential in the quantum domain remains largely unexplored. This study investigates the performance of the Laplacian-based Quantum Semi-Supervised Learning (QSSL) method across four benchmark datasets—Iris, Wine, Breast Cancer Wisconsin, and Heart Disease. Further analysis explores the impact of increasing qubit counts, revealing that adding more qubits to a quantum system doesn't always improve performance. The effectiveness of additional qubits depends on the quantum algorithm and how well it matches the dataset. Additionally, we examine the effects of varying entangling layers on entanglement entropy and test accuracy. The performance of Laplacian learning is highly dependent on the number of entangling layers, with optimal configurations varying across different datasets. Typically, moderate levels of entanglement offer the best balance between model complexity and generalization capabilities. These observations highlight the crucial need for precise hyperparameter tuning tailored to each dataset to achieve optimal performance in Laplacian learning methods."

- id: "IrisRecognitionBitFragility"
  title: "Iris Recognition: What's Beyond Bit Fragility?"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2015
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2014.2371691"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BitFragility.pdf"
  thumbnail: "/assets/publications/paper-80.png"
  tags:
    - "Iris Recognition"
    - "Bit Fragility"
    - "Biometrics"
  abstract: "The concept of fragility of some bits in the iris codes regards exclusively their within-class variation, i.e., the probability that they take different values in templates computed from different images of the same iris. This paper extends that concept, by noticing that a similar phenomenon occurs for the between-classes comparisons, i.e., some bits have higher probability than others of assuming a predominant value, which was observed for near-infrared and (in a more evident way) for visible wavelength data. Accordingly, we propose a new measure (bit discriminability) that takes into account both the within-class and between-classes variabilities, and has roots in the Fisher discriminant. Based on the bit discriminability, we compare the usefulness of the different regions of the iris for biometric recognition, with respect to multi-spectral data and to different filters parameterizations. Finally, we measure the amount of information lost in codes quantization, which gives insight to further research on iris matching strategies that consider both phase and magnitude. Albeit augmenting the computational burden of recognition, such kind of strategies will consistently improve performance, particularly in poor-quality data."

- id: "OcularBiometricsScoreLevel"
  title: "Ocular Biometrics by Score-Level Fusion of Disparate Experts"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Image Processing"
  year: 2014
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIP.2014.2361285"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Atomistic_TIP.pdf"
  thumbnail: "/assets/publications/paper-78.png"
  tags:
    - "Ocular Biometrics"
    - "Score-Level Fusion"
    - "Periocular Recognition"
  abstract: "The concept of periocular biometrics emerged to improve the robustness of iris recognition to degraded data. Being a relatively recent topic, most of the periocular recognition algorithms work in a holistic way, and apply a feature encoding / matching strategy without considering each biological component in the periocular area. This not only augments the correlation between the components in the resulting biometric signature, but also increases the sensitivity to particular data covariates. The main novelty in this paper is to propose a periocular recognition ensemble made of two disparate components: 1) one expert analyses the iris texture and exhaustively exploits the multi-spectral information in visible-light data; 2) another expert parameterises the shape of eyelids and defines a surrounding dimensionless region-of-interest, from where statistics of the eyelids, eyelashes and skin wrinkles / furrows are encoded. Both experts work on disjoint regions of the periocular area and meet three important properties: 1) they produce practically independent responses, which is behind the better performance of the ensemble when compared to the best individual recogniser; 2) they don't share particularly sensitivity to any image covariate, which accounts for augmenting the robustness against degraded data. Finally, it should be stressed that we disregard information in the periocular region that can be easily forged (e.g., shape of eyebrows), which constitutes an active anti-counterfeit measure. An empirical evaluation was conducted on two public data sets (FRGC and UBIRIS.v2), and points for consistent improvements in performance of the proposed ensemble over the state-of-the-art periocular recognition algorithms."

- id: "IrisBiometricsIndexing"
  title: "Iris Biometrics: Indexing and Retrieving Heavily Degraded Data"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2013
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2013.2283458"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/VWII_TIFS.pdf"
  thumbnail: "/assets/publications/paper-73.png"
  tags:
    - "Iris Recognition"
    - "Indexing"
    - "Biometrics"
    - "Degraded Data"
  abstract: "Most of the methods to index iris biometric signatures were designed for decision environments with a clear separation between genuine and impostor matching scores. However, in case of less controlled data acquisition, images will be degraded and the decision environments poorly separated. This paper proposes an indexing / retrieval method for degraded images and operates at the code level, making it compatible with different feature encoding strategies. Gallery codes are decomposed at multiple scales, and according to their most reliable components at each scale, the position in an n-ary tree determined. In retrieval, the probe is decomposed similarly, and the distances to multi-scale centroids are used to penalize paths in the tree. At the end, only a subset of the branches is traversed up to the last level. When compared to related strategies, the proposed method outperforms them on degraded data, particularly in the performance range most important for biometrics (hit rates above 0.95). Finally, according to the computational cost of the retrieval phase, the number of enrolled identities above which indexing is computationally cheaper than an exhaustive search is determined."

- id: "UBIRISv2"
  title: "The UBIRIS.v2: A Database of Visible Wavelength Iris Images Captured On-The-Move and At-A-Distance"
  authors: "Hugo Proença, Sílvio Filipe, Ricardo Santos, João Oliveira, Luís A. Alexandre"
  venue: "IEEE Transactions on Pattern Analysis and Machine Intelligence"
  year: 2010
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TPAMI.2009.66"
  pdf: "http://di.ubi.pt/~hugomcp/doc/UBIRISv2_IEEETPAMI.pdf"
  thumbnail: "/assets/publications/paper-62.png"
  tags:
    - "Iris Recognition"
    - "Database"
    - "Visible Wavelength"
    - "Biometrics"
  abstract: "The iris is regarded as one of the most useful traits for biometric recognition and the dissemination of nationwide iris-based recognition systems is imminent. However, currently deployed systems rely on heavy imaging constraints to capture near infrared images with enough quality. Also, all of the publicly available iris image databases contain data correspondent to such imaging constraints and therefore are exclusively suitable to evaluate methods thought to operate on these type of environments. The main purpose of this paper is to announce the availability of the UBIRIS.v2 database, a multisession iris images database which singularly contains data captured in the visible wavelength, at-a-distance (between four and eight meters) and on on-the-move. This database is freely available for researchers concerned about visible wavelength iris recognition and will be useful in accessing the feasibility and specifying the constraints of this type of biometric recognition."

- id: "IrisRecognitionSegmentation"
  title: "Iris Recognition: On the Segmentation of Degraded Images Acquired in the Visible Wavelength"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Pattern Analysis and Machine Intelligence"
  year: 2010
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TPAMI.2009.140"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/VWIS_IEEETPAMI.pdf"
  thumbnail: "/assets/publications/paper-63.png"
  tags:
    - "Iris Recognition"
    - "Image Segmentation"
    - "Visible Wavelength"
  abstract: "Iris recognition imaging constraints are receiving increasing attention. There are several proposals to develop systems that operate in the visible wavelength and in less constrained environments. These imaging conditions engender acquired noisy artefacts that lead to severely degraded images, making iris segmentation a major issue. Having observed that existing iris segmentation methods tend to fail in these challenging conditions, we present a segmentation method that can handle degraded images acquired in less constrained conditions. We offer the following contributions: 1) to consider the sclera the most easily distinguishable part of the eye in degraded images, 2) to propose a new type of feature that measures the proportion of sclera in each direction and is fundamental in segmenting the iris, and 3) to run the entire procedure in deterministically linear time in respect to the size of the image, making the procedure suitable for real-time applications."

- id: "NonCooperativeIris"
  title: "Toward Non-Cooperative Iris Recognition: A Classification Approach Using Multiple Signatures"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEEE Transactions on Pattern Analysis and Machine Intelligence"
  year: 2007
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TPAMI.2007.1016"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ProencaAlexandreMultipleSignaturesPAMI2007.pdf"
  thumbnail: "/assets/publications/paper-58.png"
  tags:
    - "Iris Recognition"
    - "Non-Cooperative"
    - "Classification"
    - "Multiple Signatures"
  abstract: "This paper focus on noncooperative iris recognition, i.e., the capture of iris images at large distances, under less controlled lighting conditions, and without active participation of the subjects. This increases the probability of capturing very heterogeneous images (regarding focus, contrast, or brightness) and with several noise factors (iris obstructions and reflections). Current iris recognition systems are unable to deal with noisy data and substantially increase their error rates, especially the false rejections, in these conditions. We propose an iris classification method that divides the segmented and normalized iris image into six regions, makes an independent feature extraction and comparison for each region, and combines each of the dissimilarity values through a classification rule. Experiments show a substantial decrease, higher than 40 percent, of the false rejection rates in the recognition of noisy iris images."


- id: "LeopardSpots"
  title: "A Leopard Cannot Change Its Spots: Improving Face Recognition Using 3D-based Caricatures"
  authors: "João C. Neves, Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2018
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2018.2846617"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Leopard_TIFS.pdf"
  thumbnail: "/assets/publications/paper-96.png"
  tags:
    - "Face Recognition"
    - "Caricatures"
    - "3D Modeling"
  abstract: "Caricatures refer to a representation of a person in which the distinctive features are deliberately exaggerated, with several studies showing that humans perform better at recognizing people from caricatures than using original images. Inspired by this observation, this paper introduces the first fully automated caricature-based face recognition approach capable of working with data acquired in the wild. Our approach leverages the 3D face structure from a single 2D image and compares it to a reference model for obtaining a compact representation of face features deviations. This descriptor is subsequently deformed using a 'measure locally, weight globally' strategy to resemble the caricature drawing process. The deformed deviations are incorporated in the 3D model using the Laplacian mesh deformation algorithm, and the 2D face caricature image is obtained by projecting the deformed model in the original camera-view. To demonstrate the advantages of caricature-based face recognition, we train the VGG-Face network from scratch using either original face images (baseline) or caricatured images, and use these models for extracting face descriptors from the LFW, IJB-A and MegaFace datasets. The experiments show an increase in the recognition accuracy when using caricatures rather than original images. Moreover, our approach achieves competitive results with state-of-the-art face recognition methods, even without explicitly tuning the network for any of the evaluation sets."

- id: "SoftBiometricsHair"
  title: "Soft Biometrics: Globally Coherent Solutions for Hair Segmentation and Style Recognition based on Hierarchical MRFs"
  authors: "Hugo Proença, João C. Neves"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2017
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2017.2680246"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/HairAnalysis_TIFS.pdf"
  thumbnail: "/assets/publications/paper-91.png"
  tags:
    - "Soft Biometrics"
    - "Hair Analysis"
    - "Markov Random Fields"
    - "Segmentation"
  abstract: "Markov Random Fields (MRFs) are a popular tool in many computer vision problems and faithfully model a broad range of local dependencies. However, rooted in the Hammersley-Clifford theorem, they face serious difficulties in enforcing the global coherence of the solutions without using too high order cliques that reduce the computational effectiveness of the inference phase. Having this problem in mind, we describe a multi-layered (hierarchical) architecture for MRFs that is based exclusively in pairwise connections and typically produces globally coherent solutions, with 1) one layer working at the local (pixel) level, modelling the interactions between adjacent image patches; and 2) a complementary layer working at the object (hypothesis) level pushing toward globally consistent solutions. During optimization, both layers interact into an equilibrium state, that not only segments the data, but also classifies it. The proposed MRF architecture is particularly suitable for problems that deal with biological data (e.g., biometrics), where the reasonability of the solutions can be objectively measured. As test case, we considered the problem of hair / facial hair segmentation and labelling, which are soft biometric labels useful for human recognition in-the-wild. We observed performance levels close to the state-of-the-art at a much lower computational cost, both in the segmentation and classification (labelling) tasks."

- id: "IRINA"
  title: "IRINA: Iris Recognition (even) in Innacurately Segmented Data"
  authors: "Hugo Proença, João C. Neves"
  venue: "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)"
  year: 2017
  status: "published"
  publication_type: "conference"
  doi: "10.1109/CVPR.2017.714"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/CVPR2017.pdf"
  thumbnail: "/assets/publications/paper-44.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Segmentation"
  abstract: "The effectiveness of current iris recognition systems depends on the accurate segmentation and parameterisation of the iris boundaries, as failures at this point misalign the coefficients of the biometric signatures. This paper describes IRINA, an algorithm for Iris Recognition that is robust against INAccurately segmented samples, which makes it a good candidate to work in poor-quality data. The process is based in the concept of 'corresponding' patch between pairs of images, that is used to estimate the posterior probabilities that patches regard the same biological region, even in case of segmentation errors and non-linear texture deformations. Such information enables to infer a free-form deformation field (2D registration vectors) between images, whose first and second-order statistics provide effective biometric discriminating power. Extensive experiments were carried out in four datasets (CASIA-IrisV3-Lamp, CASIA-IrisV4-Lamp, CASIA-IrisV4-Thousand and WVU) and show that IRINA not only achieves state-of-the-art performance in good quality data, but also handles effectively severe segmentation errors and large differences in pupillary dilation / constriction."

- id: "JointHeadPose"
  title: "Joint Head Pose/Soft Label Estimation for Human Recognition In-The-Wild"
  authors: "Hugo Proença, João C. Neves, Silvio Barra, Tiago Marques, Juan C. Moreno"
  venue: "IEEE Transactions on Pattern Analysis and Machine Intelligence"
  year: 2016
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TPAMI.2016.2522441"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/SoftBiometrics.pdf"
  thumbnail: "/assets/publications/paper-86.png"
  tags:
    - "Soft Biometrics"
    - "Head Pose Estimation"
    - "Human Recognition"
    - "3D Morphology"
  abstract: "Soft biometrics have been emerging to complement other traits and are particularly useful for poor quality data. In this paper, we propose an efficient algorithm to estimate human head poses and to infer soft biometric labels based on the 3D morphology of the human head. Starting by considering a set of pose hypotheses, we use a learning set of head shapes synthesized from anthropometric surveys to derive a set of 3D head centroids that constitutes a metric space. Next, representing queries by sets of 2D head landmarks, we use projective geometry techniques to rank efficiently the joint 3D head centroids / pose hypotheses according to their likelihood of matching each query. The rationale is that the most likely hypotheses are sufficiently close to the query, so a good solution can be found by convex energy minimization techniques. Once a solution has been found, the 3D head centroid and the query are assumed to have similar morphology, yielding the soft label. Our experiments point toward the usefulness of the proposed solution, which can improve the effectiveness of face recognizers and can also be used as a privacy-preserving solution for biometric recognition in public environments."

- id: "DeepPRWIS"
  title: "Deep-PRWIS: Periocular Recognition Without the Iris and Sclera Using Deep Learning Frameworks"
  authors: "Hugo Proença, João C. Neves"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2018
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2017.2771230"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Deep-PRWIS.pdf"
  thumbnail: "/assets/publications/tifs.jpg"
  tags:
    - "Periocular Recognition"
    - "Deep Learning"
    - "Biometrics"
    - "Ocular Recognition"
    - "Data Augmentation"
  abstract: "This work is based on a disruptive hypothesis for periocular biometrics: in visible-light data, the recognition performance is optimized when the components inside the ocular globe (the iris and the sclera) are simply discarded, and the recogniser's response is exclusively based in information from the surroundings of the eye. As major novelty, we describe a processing chain based on convolution neural networks (CNNs) that defines the regions-of-interest in the input data that should be privileged in an implicit way, i.e., without masking out any areas in the learning/test samples. By using an ocular segmentation algorithm exclusively in the learning data, we separate the ocular from the periocular parts. Then, we produce a large set of 'multi-class' artificial samples, by interchanging the periocular and ocular parts from different subjects. These samples are used for data augmentation purposes and feed the learning phase of the CNN, always considering as label the ID of the periocular part. This way, for every periocular region, the CNN receives multiple samples of different ocular classes, forcing it to conclude that such regions should not be considered in its response. During the test phase, samples are provided without any segmentation mask and the network naturally disregards the ocular components, which contributes for improvements in performance. Our experiments were carried out in full versions of two widely known data sets (UBIRIS.v2 and FRGC) and show that the proposed method consistently advances the state-of-the-art performance in the closed-world setting, reducing the EERs in about 82% (UBIRIS.v2) and 85% (FRGC) and improving the Rank-1 over 41% (UBIRIS.v2) and 12% (FRGC)."

- id: "QuadrupletLoss"
  title: "A Quadruplet Loss for Enforcing Semantically Coherent Embeddings in Multi-output Classification Problems"
  authors: "Hugo Proença, Ehsan Yaghoubi, Pendar Alirezazadeh"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2021
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2020.3023304"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Quadruplet.pdf"
  thumbnail: "/assets/publications/tifs.jpg"
  tags:
    - "Deep Learning"
    - "Multi-output Classification"
    - "Feature Embedding"
    - "Triplet Loss"
    - "Soft Biometrics"
  abstract: "This paper describes one objective function for learning semantically coherent feature embeddings in multi-output classification problems, i.e., when the response variables have dimension higher than one. Such coherent embeddings can be used simultaneously for different tasks, such as identity retrieval and soft biometrics labelling. We propose a generalization of the triplet loss that: 1) defines a metric that considers the number of agreeing labels between pairs of elements; 2) introduces the concept of similar classes, according to the values provided by the metric; and 3) disregards the notion of anchor, sampling four arbitrary elements at each time, from where two pairs are defined. The distances between elements in each pair are imposed according to their semantic similarity (i.e., the number of agreeing labels). Likewise the triplet loss, our proposal also privileges small distances between positive pairs. However, the key novelty is to additionally enforce that the distance between elements of any other pair corresponds inversely to their semantic similarity. The proposed loss yields embeddings with a strong correspondence between the classes centroids and their semantic descriptions. In practice, it is a natural choice to jointly infer coarse (soft biometrics) + fine (ID) labels, using simple rules such as k-neighbours. Also, in opposition to its triplet counterpart, the proposed loss appears to be agnostic with regard to demanding criteria for mining learning instances (such as the semi-hard pairs). Our experiments were carried out in five different datasets (BIODI, LFW, IJB-A, Megaface and PETA) and validate our assumptions, showing results that are comparable to the state-of-the-art in both the identity retrieval and soft biometrics labelling tasks."

- id: "REGINA"
  title: "REGINA - Reasoning Graph Convolutional Networks in Human Action Recognition"
  authors: "Bruno Degardin, Vasco Lopes, Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2021.3130437"
  pdf: "http://di.ubi.pt/~hugomcp/doc/degardin_tifs_2021.pdf"
  thumbnail: "/assets/publications/tifs.jpg"
  tags:
    - "Human Action Recognition"
    - "Graph Convolutional Networks"
    - "Skeleton-based Recognition"
    - "Reasoning"
    - "Feature Engineering"
  abstract: "It is known that the kinematics of the human body skeleton reveals valuable information in action recognition. Recently, modelling skeletons as spatio-temporal graphs with Graph Convolutional Networks (GCNs) has been reported to solidly advance the state-of-the-art performance. However, GCN-based approaches exclusively learn from raw skeleton data, and are expected to extract the inherent structural information on their own. This paper describes REGINA, introducing a novel way to REasoning Graph convolutional networks IN Human Action recognition. The rationale is to provide to the GCNs additional knowledge about the skeleton data, obtained by hand-crafted features, in order to facilitate the learning process, while guaranteeing that it remains fully trainable in an end-to-end manner. The challenge is to capture complementary information over the dynamics between consecutive frames, which is the key information extracted by state-of-the-art GCN techniques. Moreover, the proposed strategy can be easily integrated in the existing GCN-based methods, which we also regard positively. Our experiments were carried out in well known action recognition datasets and enabled to conclude that REGINA contributes for solid improvements in performance when incorporated to other GCN-based approaches, without any other adjustment regarding the original method. For reproducibility, the REGINA code and all the experiments carried out will be publicly available at https://github.com/DegardinBruno."
  code: "https://github.com/DegardinBruno"

- id: "KineticGAN"
  title: "Generative Adversarial Graph Convolutional Networks for Human Action Synthesis"
  authors: "Bruno Degardin, João C. Neves, Vasco Lopes, João Brito, Ehsan Yaghoubi, Hugo Proença"
  venue: "Proceedings of the 2022 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)"
  year: 2022
  status: "published"
  publication_type: "conference"
  doi: "10.1109/WACV51458.2022.00281"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/wacv21.pdf"
  thumbnail: "/assets/publications/cvf.jpg"
  tags:
    - "Human Action Synthesis"
    - "Graph Convolutional Networks"
    - "Generative Adversarial Networks"
    - "Action Recognition"
    - "Skeleton-based Animation"
  abstract: "Synthesising the spatial and temporal dynamics of the human body skeleton remains a challenging task, not only in terms of the quality of the generated shapes, but also of their diversity, particularly to synthesise realistic body movements of a specific action (action conditioning). In this paper, we propose Kinetic-GAN, a novel architecture that leverages the benefits of Generative Adversarial Networks and Graph Convolutional Networks to synthesise the kinetics of the human body. The proposed adversarial architecture can condition up to 120 different actions over local and global body movements while improving sample quality and diversity through latent space disentanglement and stochastic variations. Our experiments were carried out in three well-known datasets, where Kinetic-GAN notably surpasses the state-of-the-art methods in terms of distribution quality metrics while having the ability to synthesise more than one order of magnitude regarding the number of different actions. Our code and models are publicly available at https://github.com/DegardinBruno/Kinetic-GAN."
  code: "https://github.com/DegardinBruno/Kinetic-GAN"

- id: "UUNet"
  title: "The UU-Net: Reversible Face De-Identification for Visual Surveillance Video Footage"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Circuits and Systems for Video Technology"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TCSVT.2021.3066054"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/UUNet.pdf"
  thumbnail: "/assets/publications/tcsvt.jpg"
  tags:
    - "Face De-Identification"
    - "Visual Surveillance"
    - "Privacy Protection"
    - "Generative Adversarial Networks"
    - "Reversible Anonymization"
  abstract: "We propose a reversible face de-identification method for video surveillance data, where landmark-based techniques cannot be reliably used. Our solution generates a photorealistic de-identified stream that meets the data protection regulations and can be publicly released under minimal privacy concerns. Notably, such stream still encapsulates the information required to later reconstruct the original scene, which is useful for scenarios, such as crime investigation, where subjects identification is of most importance. Our learning process jointly optimizes two main components: 1) a public module, that receives the raw data and generates the de-identified stream; and 2) a private module, designed for security authorities, that receives the public stream and reconstructs the original data, disclosing the actual IDs of the subjects in a scene. The proposed solution is landmarks-free and uses a conditional generative adversarial network to obtain synthetic faces that preserve pose, lighting, background information and even facial expressions. Also, we keep full control over the set of soft facial attributes to be preserved/changed between the raw/de-identified data, which extends the range of applications for the proposed solution. Our experiments were conducted in three visual surveillance datasets (BIODI, MARS and P-DESTRE) plus one video face data set (YouTube Faces), showing highly encouraging results. The source code is available at https://github.com/hugomcp/uu-net."

- id: "DeepGabor"
  title: "DeepGabor: A Learning-Based Framework to Augment IrisCodes Permanence"
  authors: "Hugo Proença"
  venue: "IEEE Transactions on Information Forensics and Security"
  year: 2022
  status: "published"
  publication_type: "journal"
  doi: "10.1109/TIFS.2022.3214098"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/tifs_deep_gabor_22.pdf"
  thumbnail: "/assets/publications/tifs.jpg"
  tags:
    - "Iris Recognition"
    - "Deep Learning"
    - "Biometrics"
    - "Gabor Filters"
    - "IrisCode"
  abstract: "For over three decades, the Gabor-based IrisCode approach has been acknowledged as the gold standard for iris recognition, mainly due to the high entropy and binary nature sgn() of its signatures. This method is highly effective in large scale environments (e.g., national ID applications), where millions of comparisons per second are required. However, it is known that non-linear deformations in the iris texture, with fibers vanishing/appearing in response to pupil dilation/contraction, often flip the signature coefficients, being the main cause for the increase of false rejections. This paper addresses this problem, describing a customised Deep Learning (DL) framework that: 1) virtually emulates the IrisCode feature encoding phase; while also 2) detects the deformations in the iris texture that may lead to bit flipping, and autonomously adapts the filter configurations for such cases. The proposed DL architecture seamlessly integrates the Gabor kernels that extract the IrisCode and a multi-scale texture analyzer, from where the biometric signatures yield. In this sense, it can be seen as an adaptive encoder that is fully compatible to the IrisCode approach, while increasing the permanence of the signatures. The experiments were conducted in two well known datasets (CASIA-Iris-Lamp and CASIA-Iris-Thousand) and showed a notorious decrease of the mean/standard deviation values of the genuines distribution, at expenses of only a marginal deterioration in the impostors scores. The resulting decision environments consistently reduce the levels of false rejections with respect to the baseline for most operating levels (e.g., over 50% at 1e−3 FAR values). The source code of the DeepGabor encoder is available at: https://github.com/hugomcp/DeepGabor."


- id: "FakeItTillYouRecognizeIt"
  title: "Fake It Till You Recognize It: Quality Assessment for Human Action Generative Models"
  authors: "Bruno Degardin, Vasco Lopes, Hugo Proença"
  venue: "IEEE Transactions on Biometrics, Behaviour and Identity Science"
  year: 2024
  status: "in press"
  publication_type: "journal"
  doi: "10.1109/TBIOM.2024.3375453"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/Degardin_TBIOM_2024.pdf"
  thumbnail: "/assets/publications/tbiom.jpg"
  tags:
    - "Human Action Recognition"
    - "Generative Models"
    - "Quality Assessment"
    - "Skeleton-based Animation"
    - "Synthetic Data"
  abstract: "Skeleton-based generative modelling is an important research topic to mitigate the heavy annotation process. In this work, we explore the impact of synthetic data on skeleton-based action recognition alongside its evaluation methods for more precise quality extraction. We propose a novel iterative weakly-supervised learning generative strategy for synthesising high-quality human actions. We combine conditional generative models with Bayesian classifiers to select the highest-quality samples. As an essential factor, we designed a discriminator network that, together with a Bayesian classifier relies on the most realistic instances to augment the amount of data available for the next iteration without requiring standard cumbersome annotation processes. Additionally, as a key contribution to assessing the quality of samples, we propose a novel measure based on human kinematics instead of employing commonly used evaluation methods, which are heavily based on images. The rationale is to capture the intrinsic characteristics of human skeleton dynamics, thereby complementing model comparison and alleviating the need to manually select the best samples. Experiments were carried out over four benchmarks of two well-known datasets (NTU RGB+D and NTU-120 RGB+D), where both our framework and model assessment can notably enhance skeleton-based action recognition and generation models by synthesising high-quality and realistic human actions."


- id: "DeepLearningIrisSurvey"
  title: "Deep Learning for Iris Recognition: A Survey"
  authors: "Kien Nguyen, Hugo Proença, Fernando Alonso-Fernandez"
  venue: "ACM Computing Surveys"
  year: 2024
  status: "published"
  publication_type: "journal"
  doi: "10.1145/3651306"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/iris_survey.pdf"
  thumbnail: "/assets/publications/csur.jpg"
  tags:
    - "Deep Learning"
    - "Iris Recognition"
    - "Biometrics"
    - "Survey"
  abstract: "In this survey, we provide a comprehensive review of more than 200 papers, technical reports, and GitHub repositories published over the last 10 years on the recent developments of deep learning techniques for iris recognition, covering broad topics on algorithm designs, open-source tools, open challenges, and emerging research. First, we conduct a comprehensive analysis of deep learning techniques developed for two main sub-tasks in iris biometrics: segmentation and recognition. Second, we focus on deep learning techniques for the robustness of iris recognition systems against presentation attacks and via human-machine pairing. Third, we delve deep into deep learning techniques for forensic application, especially in post-mortem iris recognition. Fourth, we review open-source resources and tools in deep learning techniques for iris recognition. Finally, we highlight the technical challenges, emerging research trends, and outlook for the future of deep learning in iris recognition."

- id: "BIAS"
  title: "BIAS: A Body-based Interpretable Active Speaker Approach"
  authors: "Tiago Roxo, Joana C. Costa, Pedro Inácio, Hugo Proença"
  venue: "IEEE Transactions on Biometrics, Behaviour and Identity Science"
  year: 2025
  status: "in press"
  publication_type: "journal"
  doi: "10.1109/TBIOM.2024.3520030"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BIAS_TBIOM.pdf"
  thumbnail: "/assets/publications/tbiom.jpg"
  tags:
    - "Active Speaker Detection"
    - "Biometrics"
    - "Interpretable AI"
    - "Multimodal Learning"
  abstract: "State-of-the-art Active Speaker Detection (ASD) approaches heavily rely on audio and facial features to perform, which is not a sustainable approach in wild scenarios. Although these methods achieve good results in the standard AVA-ActiveSpeaker set, a recent wilder ASD dataset (WASD) showed the limitations of such models and raised the need for new approaches. As such, we propose BIAS, a model that, for the first time, combines audio, face, and body information, to accurately predict active speakers in varying/challenging conditions. Additionally, we design BIAS to provide interpretability by proposing a novel use for Squeeze-and-Excitation blocks, namely in attention heat-maps creation and feature importance assessment. For a full interpretability setup, we annotate an ASD-related actions dataset (ASD-Text) to fine-tune a ViT-GPT2 for text scene description to complement BIAS interpretability. The results show that BIAS is state-of-the-art in challenging conditions where body-based features are of utmost importance (Columbia, open settings, and WASD), and yields competitive results in AVAActiveSpeaker, where face is more influential than body for ASD. BIAS interpretability also shows the features/aspects more relevant towards ASD prediction in varying settings, making it a strong baseline for further developments in interpretable ASD models, and is available at https://github.com/Tiago-Roxo/BIAS."


- id: "FeatureQuality"
  title: "Iris Recognition: Measuring Feature's Quality for the Feature Selection in Unconstrained Image Capture Environments"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEEE Proceedings of the 2006 International Conference on Computational Intelligence for Homeland Security and Personal Safety (CIHSPS)"
  volume: 1
  pages: "35-40"
  location: "Alexandria, U.S.A."
  date: "October 16-17, 2006"
  year: 2006
  publication_type: "conference"
  doi: "10.1109/CIHSPS.2006.313298"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/CIHSPS06.pdf"
  thumbnail: "images/publication/paper-13.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Feature Selection"
    - "Image Quality"
  abstract: "Iris recognition is being increasingly used for several purposes. However, current iris recognition systems are unable to deal with noisy data and substantially increase their error rates, specially the false rejections in these conditions. Several proposals have been made to access image quality and to identify noisy regions in iris images. Based in these facts, in this paper we propose a method applicable in the feature extraction and comparison stages that measures the quality of each feature of the biometric signature and take account of this information to obtain the dissimilarity between iris signatures. Experiments led us to conclude that this method significantly decreases the error rates in the recognition of noisy iris images, resultant from the capturing in less constrained environments."

- id: "IrisSegmentationVisible"
  title: "Iris Recognition: A Method To Segment Visible Wavelength Iris Images Acquired On-The-Move and At-A-Distance"
  authors: "Hugo Proença"
  venue: "Springer Lecture Notes in Computer Science – ISVC 2008: 4th International Symposium on Visual Computing"
  volume: 1
  pages: "731-742"
  location: "Las Vegas, Nevada, U.S.A."
  date: "December 1-3, 2008"
  year: 2008
  publication_type: "conference"
  doi: "10.1007/978-3-540-89639-5_70"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ISVC08.pdf"
  thumbnail: "/assets/publications/paper-19.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Image Segmentation"
    - "Visible Wavelength"
  abstract: "The dramatic growth in practical applications for iris biometrics has been accompanied by many important developments in the underlying algorithms and techniques. Among others, one of the most active research areas concerns about the development of iris recognition systems less constrained to users, either increasing the image acquisition distances or the required lighting conditions. The main point of this paper is to give a process suitable for the automatic segmentation of iris images captured at the visible wavelength, on-the-move and within a large range of image acquisition distances (between 4 and 8 meters). Our experiments were performed on images of the UBIRIS.v2 database and show the robustness of the proposed method to handle the types of non-ideal images resultant of the aforementioned less constrained image acquisition conditions."

- id: "VisibleWavelengthIris"
  title: "On the Feasibility of the Visible Wavelength, At-A-Distance and On-The-Move Iris Recognition"
  authors: "Hugo Proença"
  venue: "Proceedings of the IEEE Symposium Series on Computational Intelligence in Biometrics: Theory, Algorithms, and Applications (CIBIM SSCI)"
  volume: 1
  pages: "9-15"
  location: "Nashville, Tennessee, U.S.A."
  date: "March 30 - April 2, 2009"
  year: 2009
  publication_type: "conference"
  doi: "10.1109/CIB.2009.4925680"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/CIBIM09.pdf"
  thumbnail: "/assets/publications/paper-20.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Visible Wavelength"
    - "Non-cooperative Recognition"
  abstract: "The dramatic growth in practical applications for iris biometrics has been accompanied by relevant developments in the underlying algorithms and techniques. Among others, one active research area concerns about the development of iris recognition systems less constrained to users, either increasing the imaging distances, simplifying the acquisition protocols or the required lighting conditions. In this paper we address the possibility of perform reliable recognition using visible wavelength images captured under high heterogeneous lighting conditions, with subjects at-a-distance (between 4 and 8 meters) and on-the-move. The feasibility of this extremely ambitious type of recognition is analyzed, its major obstacles and challenges discussed and some directions for forthcoming work pointed."

- id: "DentalXRay"
  title: "Dental X-Ray: A Data Set of Panoramic Dental Radiographs for Stomatologic Image Processing Purposes"
  authors: "João Oliveira, Hugo Proença"
  venue: "Taylor & Francis Proceedings of the II ECCOMAS Thematic Conference on Computational Vision and Medical Image Processing (VIPIMAGE)"
  location: "Porto, Portugal"
  date: "October 14-16, 2009"
  year: 2009
  publication_type: "conference"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ECCOMAS09.pdf"
  thumbnail: "/assets/publications/paper-21.png"
  tags:
    - "Medical Imaging"
    - "Dental Radiographs"
    - "Image Dataset"
    - "Image Processing"
  abstract: "This paper has two major purposes: at firstly, to announce the availability of a new data set of panoramic dental X-ray images. This data set contains 1392 images with varying types of noise, usually inherent to this kind of images. Furthermore, the number of teeth per image and their dental morphology were not constant. Secondly, we propose a method to approximate the panoramic images in bitewing images, which are the most common type of images used in the human identification and in the tooth segmentation for the diagnosis of dental diseases."

- id: "EvidenceFusion"
  title: "Biometric Recognition: When Is Evidence Fusion Advantageous?"
  authors: "Hugo Proença"
  venue: "Springer Lecture Notes in Computer Science – ISVC 2009: 5th International Symposium on Visual Computing"
  volume: "5876"
  part: "II"
  pages: "698-708"
  location: "Las Vegas, Nevada, U.S.A."
  date: "October 30 - November 2, 2009"
  year: 2009
  publication_type: "conference"
  doi: "10.1007/978-3-642-10520-3_66"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ISVC09.pdf"
  thumbnail: "/assets/publications/paper-23.png"
  tags:
    - "Biometrics"
    - "Evidence Fusion"
    - "Multimodal Recognition"
    - "Performance Analysis"
  abstract: "Having assessed the performance gains due to evidence fusion, previous works reported contradictory conclusions. For some, a consistent improvement is achieved, while others state that the fusion of a stronger and a weaker biometric expert tends to produce worst results than if the best expert was used individually. The main contribution of this paper is to assess when improvements in performance are actually achieved, regarding the individual performance of each expert. Starting from readily satisfied assumptions about the score distributions generated by a biometric system, we predict the performance of each of the individual experts and of the fused system. Then, we conclude about the performance gains in fusing evidence from multiple sources. Also, we parameterize an empirically obtained relationship between the individual performance of the fused experts that contributes to decide whether evidence fusion techniques are advantageous or not."

- id: "Interpolation"
  title: "On the Role of Interpolation in the Normalization of Non-Ideal Visible Wavelength Iris Images"
  authors: "Gil Santos, Hugo Proença"
  venue: "Proceedings of the 2009 International Conference on Computational Intelligence and Security (CIS)"
  volume: 1
  pages: "315-319"
  location: "Beijing, China"
  date: "December 11-14, 2009"
  year: 2009
  publication_type: "conference"
  doi: "10.1109/CIS.2009.113"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/cis09.pdf"
  thumbnail: "/assets/publications/paper-22.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Image Normalization"
    - "Interpolation Methods"
  abstract: "The growth in practical applications for iris bio- metrics has been accompanied by relevant developments in the underlying algorithms and techniques. Along with the research focused on near-infrared (NIR) cooperatively captured images, efforts are being made to minimize the trade-off between the quality of the captured data and the recognition accuracy on less constrained environments, where images are obtained at the visible wavelength, at increased distances, over simplified protocols and adverse lightning. This paper addresses the effect of the interpolation method, used in the iris normalization stage, in the overall recognition error rates. This effect is stressed for systems operating under less constrained image acquisition setups and protocols, due to higher variations in the amounts of captured data. Our experiments led us to conclude that the utility of the image interpolating methods is directly corresponding to the levels of noise that images contain."

- id: "IrisAliasing"
  title: "Iris Recognition: An Analysis of the Aliasing Problem in the Iris Normalization Stage"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEEE Proceedings of the 2006 International Conference on Computational Intelligence and Security (CIS)"
  volume: 2
  pages: "1771-1774"
  location: "Guangzhou, China"
  date: "November 3-6, 2006"
  year: 2006
  publication_type: "conference"
  doi: "10.1109/ICCIAS.2006.295366"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/CIS06.pdf"
  thumbnail: "/assets/publications/paper-12.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Image Processing"
    - "Aliasing"
  abstract: "Iris recognition has been increasingly used with very satisfactory results. Presently, the challenge consists in unconstrain the image capturing conditions and enable its application to domains where the subjects' cooperation is not expectable (e.g. criminal/terrorist seek, missing children). In this type of use, due to variations in the image capturing distance and in the lighting conditions that determine the size of the subjects' pupil, the area correspondent to the iris in the captured images will be highly varying too. In order to compensate this variation, common iris recognition proposals translate the segmented iris image to a double dimensionless pseudo-polar coordinate system, in a process known as the normalization stage, which can be regarded as a sampling of the original data with the inherent possibility of aliasing. In this paper we analyze the relationship between the size of the captured iris image and the overall recognition's accuracy. Further, we identify the threshold for the sampling rate of the iris normalization process above which the error rates significantly increase."

- id: "NICE"
  title: "The NICE.I: Noisy Iris Challenge Evaluation – Part I"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEEE Proceedings of the IEEE First International Conference on Biometrics: Theory, Applications and Systems (BTAS)"
  location: "Washington DC, U.S.A."
  date: "September 27-29, 2007"
  year: 2007
  publication_type: "conference"
  doi: "10.1109/BTAS.2007.4401910"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/BTAS07.pdf"
  thumbnail: "/assets/publications/paper-14.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Challenge Evaluation"
    - "Noisy Images"
  abstract: "This paper gives an overview of the NICE.I : Noisy Iris Challenge Evaluation - Part I contest. This contest differs from others in two fundamental points. First, instead of the complete iris recognition process, it exclusively evaluates the iris segmentation and noise detection stages, allowing the independent evaluation of one of the main recognition error sources. Second, it operates on highly noisy images that were captured to simulate less constrained imaging environments and constitute the second version of the UBIRIS database (UBIRIS.v2). Further details can be seen at the contest web site (http://nice1.di.ubi.pt)."

- id: "NonCooperative"
  title: "Toward Non-Cooperative Iris Recognition: A Classification Approach Using Multiple Signatures"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEEE Transactions on Pattern Analysis and Machine Intelligence"
  volume: 9
  issue: 4
  pages: "607-612"
  year: 2007
  publication_type: "journal"
  doi: "10.1109/TPAMI.2007.1016"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ProencaAlexandreMultipleSignaturesPAMI2007.pdf"
  thumbnail: "/assets/publications/paper-58.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Non-Cooperative Recognition"
    - "Multiple Signatures"
  abstract: "This paper focus on noncooperative iris recognition, i.e., the capture of iris images at large distances, under less controlled lighting conditions, and without active participation of the subjects. This increases the probability of capturing very heterogeneous images (regarding focus, contrast, or brightness) and with several noise factors (iris obstructions and reflections). Current iris recognition systems are unable to deal with noisy data and substantially increase their error rates, especially the false rejections, in these conditions. We propose an iris classification method that divides the segmented and normalized iris image into six regions, makes an independent feature extraction and comparison for each region, and combines each of the dissimilarity values through a classification rule. Experiments show a substantial decrease, higher than 40 percent, of the false rejection rates in the recognition of noisy iris images."

- id: "UBIRISv2"
  title: "The UBIRIS.v2: A Database of Visible Wavelength Iris Images Captured On-The-Move and At-A-Distance"
  authors: "Hugo Proença, Sílvio Filipe, Ricardo Santos, João Oliveira, Luís A. Alexandre"
  venue: "IEEE Transactions on Pattern Analysis and Machine Intelligence"
  volume: 32
  issue: 8
  pages: "1529-1535"
  year: 2010
  publication_type: "journal"
  doi: "10.1109/TPAMI.2009.66"
  pdf: "http://di.ubi.pt/~hugomcp/doc/UBIRISv2_IEEETPAMI.pdf"
  thumbnail: "/assets/publications/pami.jpg"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Image Database"
    - "Visible Wavelength"
  abstract: "This paper announces the availability of the UBIRIS.v2 database, a multisession iris images database which singularly contains data captured in the visible wavelength, at-a-distance (between four and eight meters) and on-the-move. This database is freely available for research purposes and will be useful to evaluate the feasibility of visible wavelength iris recognition in the aforementioned capturing conditions that significantly increase the probability of noise factors."


- id: "NoisyRegions"
  title: "A Method for the Identification of Noisy Regions in Normalized Iris Images"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEEE Proceedings of the 18th International Conference on Pattern Recognition (ICPR)"
  volume: 4
  pages: "405-408"
  location: "Hong Kong"
  date: "August 20-24, 2006"
  year: 2006
  publication_type: "conference"
  doi: "10.1109/ICPR.2006.100"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ICPR06.pdf"
  thumbnail: "/assets/publications/paper-11.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Image Processing"
    - "Noise Detection"
  abstract: "In this paper we propose a new method for the identification of noisy regions in normalized iris images. Starting from a normalized and dimensionless iris image in the polar coordinate system, our goal consists in the classification of every pixel as 'noise' or 'not noise'. This classification could be helpful in the posterior feature extraction or feature comparison stages regarding the construction of biometric iris signatures more robust to noise."


- id: "PupilSeg"
  title: "A Method for the Identification of Inaccuracies in the Pupil Segmentation"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEEE Proceedings of the First International Conference on Availability, Reliability and Security (AReS)"
  volume: 1
  pages: "227-230"
  location: "Vienna, Austria"
  date: "April 20-22, 2006"
  year: 2006
  publication_type: "conference"
  doi: "10.1109/ARES.2006.9"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ARES2006.pdf"
  thumbnail: "/assets/publications/paper-10.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Image Segmentation"
    - "Pupil Detection"
  abstract: "In this paper we analyze the relationship between the accuracy of the segmentation algorithm and the error rates of typical iris recognition systems. We selected 1000 images from the UBIRIS database that the segmentation algorithm can accurately segment and artificially introduced segmentation inaccuracies. We repeated the recognition tests and concluded about the strong relationship between the errors in the pupil segmentation and the overall false reject rate. Based on this fact, we propose a method to identify these inaccuracies."


- id: "IrisSeg"
  title: "Iris Segmentation Methodology for Non-Cooperative Recognition"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "IEE Proceedings of Image, Vision, Image & Signal Processing"
  volume: 153
  issue: 2
  pages: "199-205"
  year: 2006
  publication_type: "journal"
  doi: "10.1049/ip-vis:20050213"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ProencaAlexandreIrisSegmentationIEE.pdf"
  thumbnail: "/assets/publications/paper-57.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Image Segmentation"
    - "Non-Cooperative Recognition"
  abstract: "An overview of the iris image segmentation methodologies for biometric purposes is presented. The main focus is on the analysis of the ability of segmentation algorithms to process images with heterogeneous characteristics, simulating the dynamics of a non-cooperative environment. The accuracy of the four selected methodologies on the UBIRIS database is tested and, having concluded about their weak robustness when dealing with non-optimal images regarding focus, reflections, brightness or eyelid obstruction, the authors introduce a new and more robust iris image segmentation methodology. This new methodology could contribute to the aim of non-cooperative biometric iris recognition, where the ability to process this type of image is required." 

- id: "UBIRIS"
  title: "UBIRIS: a noisy iris image database"
  authors: "Hugo Proença, Luís A. Alexandre"
  venue: "Springer Lecture Notes in Computer Science – ICIAP 2005: 13th International Conference on Image Analysis and Processing"
  volume: 1
  pages: "970-977"
  location: "Cagliari, Italy"
  date: "September 6-8, 2005"
  year: 2005
  publication_type: "conference"
  doi: "10.1007/11553595_119"
  pdf: "http://www.di.ubi.pt/~hugomcp/doc/ubiris_iciap.pdf"
  thumbnail: "/assets/publications/paper-9.png"
  tags:
    - "Iris Recognition"
    - "Biometrics"
    - "Image Database"
    - "Noisy Images"
  abstract: "This paper presents a new iris database that contains images with noise. This is in contrast with the existing databases, that are noise free. UBIRIS is a tool for the development of robust iris recognition algorithms for biometric proposes. We present a detailed description of the many characteristics of UBIRIS and a comparison of several image segmentation approaches used in the current iris segmentation methods where it is evident their small tolerance to noisy images." 

- id: "MARCS"
  title: "MARCS: Multi-Agent Railway Control System"
  authors: "Hugo Proença, Eugénio Oliveira"
  venue: "MARCS: Multi-Agent Railway Control System. Springer Lecture Notes in Computer Science, Advances in Artificial Intelligence."
  year: 2004
  publication_type: "book_chapter"
  doi: "10.1007/978-3-540-30498-2_2"
  pdf: "/assets/papers/MARCS.png"
  code: "https://github.com/socia-lab/periocular-attention"
  thumbnail: "/assets/publications/MARCS.png"
  tags:
    - "Multi-Agent Systems"
    - "Railway Control"
    - "Machine Learning"
  abstract: "Previous research works have demonstrated that traffic control models based on the comparison between an historical archive of information and current traffic conditions tend to produce better results, usually by improving the system's proactivity behavior. Based on this assumption, we present in this paper MARCS - Multi-Agent Railway Control System, a multi-agent system for communications based trains traffic control. For this purpose we have developed a system infrastructure based on an architecture composed of two independent layers: 'Control' and 'Learning'. 'Control' layer is responsible for traffic supervision, regulation, security and fluidity, including three distinct agent types: 'Supervisor', 'Train' and 'Station'. The 'Learning' layer, using situations accumulated by the 'Control' layer, will infer rules that can improve traffic control processes, minimizing waiting time and stop orders sent for each train."
